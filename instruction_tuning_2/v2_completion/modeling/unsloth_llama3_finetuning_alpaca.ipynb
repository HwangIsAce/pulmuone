{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## unsloth_env_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 6)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# CUDA 장치의 주요 버전과 부 버전을 가져옵니다.\n",
    "major_version, minor_version = torch.cuda.get_device_capability()\n",
    "major_version, minor_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[unsloth]\n",
    "\n",
    "unsloth 패키지는 대형 언어 모델(LLM)인 Llama 3.1, Mistral, Phi 및 Gemma의 미세 조정을 기존 방법보다 2-5배 빠르게 하고 메모리 사용량을 80%까지 줄이는 데 사용되는 도구입니다. 이 패키지는 OpenAI의 Triton 언어로 작성된 커스텀 GPU 커널을 사용하여 성능을 최적화합니다. 이를 통해 정확도 손실 없이 효율적으로 모델을 훈련할 수 있습니다.\n",
    "\n",
    "주요 기능\n",
    "성능: 특정 경우에는 최대 30배 빠르게 미세 조정할 수 있으며, 메모리 사용량을 크게 줄여 더 큰 배치 크기와 효율적인 훈련이 가능합니다.\n",
    "호환성: NVIDIA, Intel, AMD 등 다양한 GPU를 지원합니다.\n",
    "메모리 최적화: 메모리 사용량을 줄이기 위해 수동 미분 및 체인 매트릭스 곱셈 최적화를 수행합니다.\n",
    "오픈 소스: 무료 오픈 소스 버전이 있으며, 프로 버전에서는 다중 GPU 지원 및 더 빠른 훈련 속도를 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Colab에서 torch 2.2.1을 사용하고 있으므로, 패키지 충돌을 방지하기 위해 별도로 설치해야 합니다.\n",
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "if major_version >= 8:\n",
    "    # 새로운 GPU(예: Ampere, Hopper GPUs - RTX 30xx, RTX 40xx, A100, H100, L40)에 사용하세요.\n",
    "    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n",
    "else:\n",
    "    # 오래된 GPU(예: V100, Tesla T4, RTX 20xx)에 사용하세요.\n",
    "    !pip install --no-deps xformers trl peft accelerate bitsandbytes\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaesung/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.43.3.\n",
      "   \\\\   /|    GPU: NVIDIA RTX A5000. Max memory: 23.677 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.1.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.22.post7+cu118. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.11it/s]\n",
      "beomi/Llama-3-Open-Ko-8B-Instruct-preview does not have a padding token! Will use pad_token = <|reserved_special_token_250|>.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from accelerate import PartialState\n",
    "\n",
    "device_string = PartialState().process_index\n",
    "\n",
    "max_seq_length = 4096  # 최대 시퀀스 길이를 설정합니다. 내부적으로 RoPE 스케일링을 자동으로 지원합니다!\n",
    "# 자동 감지를 위해 None을 사용합니다. Tesla T4, V100은 Float16, Ampere+는 Bfloat16을 사용하세요.\n",
    "dtype = None\n",
    "# 메모리 사용량을 줄이기 위해 4bit 양자화를 사용합니다. False일 수도 있습니다.\n",
    "load_in_4bit = True\n",
    "\n",
    "# 4배 빠른 다운로드와 메모리 부족 문제를 방지하기 위해 지원하는 4bit 사전 양자화 모델입니다.\n",
    "fourbit_models = [\n",
    "    \"unsloth/mistral-7b-bnb-4bit\",\n",
    "    \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n",
    "    \"unsloth/llama-2-7b-bnb-4bit\",\n",
    "    \"unsloth/gemma-7b-bnb-4bit\",\n",
    "    \"unsloth/gemma-7b-it-bnb-4bit\",  # Gemma 7b의 Instruct 버전\n",
    "    \"unsloth/gemma-2b-bnb-4bit\",\n",
    "    \"unsloth/gemma-2b-it-bnb-4bit\",  # Gemma 2b의 Instruct 버전\n",
    "    \"unsloth/llama-3-8b-bnb-4bit\",  # Llama-3 8B\n",
    "]  # 더 많은 모델은 https://huggingface.co/unsloth 에서 확인할 수 있습니다.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    # model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n",
    "    model_name=\"beomi/Llama-3-Open-Ko-8B-Instruct-preview\",  # 모델 이름을 설정합니다.\n",
    "    max_seq_length=max_seq_length,  # 최대 시퀀스 길이를 설정합니다.\n",
    "    dtype=dtype,  # 데이터 타입을 설정합니다.\n",
    "    load_in_4bit=load_in_4bit,  # 4bit 양자화 로드 여부를 설정합니다.\n",
    "    # token = \"hf_...\", # 게이트된 모델을 사용하는 경우 토큰을 사용하세요. 예: meta-llama/Llama-2-7b-hf,\n",
    "    device_map={'':device_string}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2024.8 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,  # 0보다 큰 어떤 숫자도 선택 가능! 8, 16, 32, 64, 128이 권장됩니다.\n",
    "    lora_alpha=32,  # LoRA 알파 값을 설정합니다.\n",
    "    lora_dropout=0.05,  # 드롭아웃을 지원합니다.\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],  # 타겟 모듈을 지정합니다.\n",
    "    bias=\"none\",  # 바이어스를 지원합니다.\n",
    "    # True 또는 \"unsloth\"를 사용하여 매우 긴 컨텍스트에 대해 VRAM을 30% 덜 사용하고, 2배 더 큰 배치 크기를 지원합니다.\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=123,  # 난수 상태를 설정합니다.\n",
    "    use_rslora=False,  # 순위 안정화 LoRA를 지원합니다.\n",
    "    loftq_config=None,  # LoftQ를 지원합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# EOS_TOKEN은 문장의 끝을 나타내는 토큰입니다. 이 토큰을 추가해야 합니다.\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "# AlpacaPrompt를 사용하여 지시사항을 포맷팅하는 함수입니다.\n",
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "\n",
    "# 주어진 예시들을 포맷팅하는 함수입니다.\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"QUESTION\"]  # 지시사항을 가져옵니다.\n",
    "    outputs = examples[\"ANSWER\"]  # 출력값을 가져옵니다.\n",
    "    texts = []  # 포맷팅된 텍스트를 저장할 리스트입니다.\n",
    "    for instruction, output in zip(instructions, outputs):\n",
    "        # EOS_TOKEN을 추가해야 합니다. 그렇지 않으면 생성이 무한히 진행될 수 있습니다.\n",
    "        text = alpaca_prompt.format(instruction, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\n",
    "        \"text\": texts,  # 포맷팅된 텍스트를 반환합니다.\n",
    "    }\n",
    "\n",
    "# JSONL 파일 로드 함수\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data\n",
    "\n",
    "# JSONL 파일 경로\n",
    "file_path = '/home/jaesung/jaesung/pulmuone/llama3_ft/completion/data/qa_pair_for_completion.jsonl'\n",
    "\n",
    "# JSONL 파일 로드\n",
    "data = load_jsonl(file_path)\n",
    "\n",
    "# pandas DataFrame으로 변환\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Dataset 객체로 변환\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# DatasetDict 객체로 결합\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['QUESTION', 'ANSWER', '__index_level_0__'],\n",
      "        num_rows: 6188\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['QUESTION', 'ANSWER', '__index_level_0__'],\n",
      "        num_rows: 1547\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_dict['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['QUESTION', 'ANSWER', '__index_level_0__'],\n",
       "    num_rows: 6188\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6188/6188 [00:00<00:00, 95087.61 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋에 formatting_prompts_func 함수를 적용합니다. 배치 처리를 활성화합니다.\n",
    "dataset = dataset.map(\n",
    "    formatting_prompts_func,\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaesung/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Map (num_proc=2): 100%|██████████| 6188/6188 [00:01<00:00, 3980.13 examples/s]\n",
      "Map (num_proc=2): 100%|██████████| 6188/6188 [00:01<00:00, 4056.90 examples/s]\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "from accelerate import notebook_launcher\n",
    "\n",
    "tokenizer.padding_side = \"right\"  # 토크나이저의 패딩을 오른쪽으로 설정합니다.\n",
    "\n",
    "# SFTTrainer를 사용하여 모델 학습 설정\n",
    "trainer = SFTTrainer(\n",
    "    model=model,  # 학습할 모델\n",
    "    tokenizer=tokenizer,  # 토크나이저\n",
    "    train_dataset=dataset,  # 학습 데이터셋\n",
    "    eval_dataset=dataset,\n",
    "    dataset_text_field=\"text\",  # 데이터셋에서 텍스트 필드의 이름\n",
    "    max_seq_length=max_seq_length,  # 최대 시퀀스 길이\n",
    "    dataset_num_proc=2,  # 데이터 처리에 사용할 프로세스 수\n",
    "    packing=False,  # 짧은 시퀀스에 대한 학습 속도를 5배 빠르게 할 수 있음,\n",
    "\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=2,  # 각 디바이스당 훈련 배치 크기\n",
    "        gradient_accumulation_steps=4,  # 그래디언트 누적 단계\n",
    "        warmup_steps=5,  # 웜업 스텝 수\n",
    "        num_train_epochs=3,  # 훈련 에폭 수\n",
    "        max_steps=60,  # 최대 스텝 수\n",
    "        do_eval=True,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        logging_steps=1,  # logging 스텝 수\n",
    "        learning_rate=2e-4,  # 학습률\n",
    "        fp16=not torch.cuda.is_bf16_supported(),  # fp16 사용 여부, bf16이 지원되지 않는 경우에만 사용\n",
    "        bf16=torch.cuda.is_bf16_supported(),  # bf16 사용 여부, bf16이 지원되는 경우에만 사용\n",
    "        optim=\"adamw_8bit\",  # 최적화 알고리즘\n",
    "        weight_decay=0.01,  # 가중치 감소\n",
    "        lr_scheduler_type=\"cosine\",  # 학습률 스케줄러 유형\n",
    "        seed=123,  # 랜덤 시드\n",
    "        output_dir=\"outputs\",  # 출력 디렉토리\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA RTX A5000. Max memory = 23.677 GB.\n",
      "5.605 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "# 현재 메모리 상태를 보여주는 코드\n",
    "gpu_stats = torch.cuda.get_device_properties(0)  # GPU 속성 가져오기\n",
    "start_gpu_memory = round(\n",
    "    torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3\n",
    ")  # 시작 시 예약된 GPU 메모리 계산\n",
    "max_memory = round(\n",
    "    gpu_stats.total_memory / 1024 / 1024 / 1024, 3\n",
    ")  # GPU의 최대 메모리 계산\n",
    "print(\n",
    "    f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\"\n",
    ")  # GPU 이름과 최대 메모리 출력\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")  # 예약된 메모리 양 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 6,188 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 60\n",
      " \"-____-\"     Number of trainable parameters = 41,943,040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 6:28:07, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.225300</td>\n",
       "      <td>3.267098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.395200</td>\n",
       "      <td>3.220932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.183000</td>\n",
       "      <td>2.973712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.120400</td>\n",
       "      <td>2.633710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.641500</td>\n",
       "      <td>2.306821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.182400</td>\n",
       "      <td>1.989435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.128000</td>\n",
       "      <td>1.796220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.847400</td>\n",
       "      <td>1.665852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.933600</td>\n",
       "      <td>1.543153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.268300</td>\n",
       "      <td>1.453811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.482600</td>\n",
       "      <td>1.388408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.252400</td>\n",
       "      <td>1.307403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.924900</td>\n",
       "      <td>1.251808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.308100</td>\n",
       "      <td>1.205552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.116700</td>\n",
       "      <td>1.169253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.022000</td>\n",
       "      <td>1.135152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.163300</td>\n",
       "      <td>1.102270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.287500</td>\n",
       "      <td>1.082758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.273700</td>\n",
       "      <td>1.065313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.995800</td>\n",
       "      <td>1.050187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.106400</td>\n",
       "      <td>1.037313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.148900</td>\n",
       "      <td>1.022293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.021600</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>0.987734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.985600</td>\n",
       "      <td>0.967688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.831300</td>\n",
       "      <td>0.942655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.836000</td>\n",
       "      <td>0.928385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.961100</td>\n",
       "      <td>0.923688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.912300</td>\n",
       "      <td>0.917695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.818600</td>\n",
       "      <td>0.903972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.015700</td>\n",
       "      <td>0.888329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.742300</td>\n",
       "      <td>0.875252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.812200</td>\n",
       "      <td>0.864460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.753800</td>\n",
       "      <td>0.851558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.972700</td>\n",
       "      <td>0.840160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.714500</td>\n",
       "      <td>0.833512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.691600</td>\n",
       "      <td>0.828458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.577800</td>\n",
       "      <td>0.822821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.769500</td>\n",
       "      <td>0.816924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.648800</td>\n",
       "      <td>0.813606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.744900</td>\n",
       "      <td>0.809428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.641700</td>\n",
       "      <td>0.806053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.701200</td>\n",
       "      <td>0.803074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.775100</td>\n",
       "      <td>0.799229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.799500</td>\n",
       "      <td>0.793352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.845300</td>\n",
       "      <td>0.787484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.761900</td>\n",
       "      <td>0.781389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.535600</td>\n",
       "      <td>0.776650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.700400</td>\n",
       "      <td>0.772826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.683400</td>\n",
       "      <td>0.769560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.864800</td>\n",
       "      <td>0.766783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.649100</td>\n",
       "      <td>0.764420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.851400</td>\n",
       "      <td>0.762499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.643200</td>\n",
       "      <td>0.761145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.789800</td>\n",
       "      <td>0.760026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.776600</td>\n",
       "      <td>0.759125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.810200</td>\n",
       "      <td>0.758613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.585300</td>\n",
       "      <td>0.758325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.782000</td>\n",
       "      <td>0.758154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.683700</td>\n",
       "      <td>0.758162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()  # 모델을 훈련시키고 통계를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23289.8592 seconds used for training.\n",
      "388.16 minutes used for training.\n",
      "Peak reserved memory = 14.389 GB.\n",
      "Peak reserved memory for training = 8.784 GB.\n",
      "Peak reserved memory % of max memory = 60.772 %.\n",
      "Peak reserved memory for training % of max memory = 37.099 %.\n"
     ]
    }
   ],
   "source": [
    "# 최종 메모리 및 시간 통계를 보여줍니다.\n",
    "used_memory = round(\n",
    "    torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3\n",
    ")  # 사용된 최대 메모리를 GB 단위로 계산합니다.\n",
    "used_memory_for_lora = round(\n",
    "    used_memory - start_gpu_memory, 3\n",
    ")  # LoRA를 위해 사용된 메모리를 GB 단위로 계산합니다.\n",
    "used_percentage = round(\n",
    "    used_memory / max_memory * 100, 3\n",
    ")  # 최대 메모리 대비 사용된 메모리의 비율을 계산합니다.\n",
    "lora_percentage = round(\n",
    "    used_memory_for_lora / max_memory * 100, 3\n",
    ")  # 최대 메모리 대비 LoRA를 위해 사용된 메모리의 비율을 계산합니다.\n",
    "print(\n",
    "    f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\"\n",
    ")  # 훈련에 사용된 시간을 초 단위로 출력합니다.\n",
    "print(\n",
    "    # 훈련에 사용된 시간을 분 단위로 출력합니다.\n",
    "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
    ")\n",
    "print(\n",
    "    f\"Peak reserved memory = {used_memory} GB.\"\n",
    ")  # 예약된 최대 메모리를 GB 단위로 출력합니다.\n",
    "print(\n",
    "    f\"Peak reserved memory for training = {used_memory_for_lora} GB.\"\n",
    ")  # 훈련을 위해 예약된 최대 메모리를 GB 단위로 출력합니다.\n",
    "print(\n",
    "    f\"Peak reserved memory % of max memory = {used_percentage} %.\"\n",
    ")  # 최대 메모리 대비 예약된 메모리의 비율을 출력합니다.\n",
    "print(\n",
    "    f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\"\n",
    ")  # 최대 메모리 대비 훈련을 위해 예약된 메모리의 비율을 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"beomi/Llama-3-Open-Ko-8B\"  # 병합을 수행할 베이스 모델\n",
    "huggingface_token = \"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\"  # HuggingFace 토큰\n",
    "huggingface_repo = \"Llama-3-Open-Ko-8B-Instruct-PM1-completion-v2-60\"  # 모델을 업로드할 repository\n",
    "save_method = (\n",
    "    \"merged_16bit\"  # \"merged_4bit\", \"merged_4bit_forced\", \"merged_16bit\", \"lora\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 32.95 out of 125.66 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 28/32 [00:00<00:00, 42.12it/s]We will save to Disk and not RAM now.\n",
      "100%|██████████| 32/32 [00:02<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving to organization with address passionMan/Llama-3-Open-Ko-8B-Instruct-PM1-completion-v2-60\n",
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
      "Unsloth: Saving to organization with address passionMan/Llama-3-Open-Ko-8B-Instruct-PM1-completion-v2-60\n",
      "Unsloth: Uploading all files... Please wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|          | 16.4k/4.98G [00:05<424:11:49, 3.26kB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|          | 98.3k/4.98G [00:05<56:40:41, 24.4kB/s] \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|          | 164k/4.98G [00:05<31:33:57, 43.8kB/s] \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|          | 295k/4.98G [00:05<14:54:25, 92.7kB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|          | 803k/4.98G [00:06<4:08:50, 333kB/s]  \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|          | 1.26M/4.98G [00:06<2:32:53, 542kB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|          | 2.87M/4.98G [00:06<55:20, 1.50MB/s] \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|          | 4.28M/4.98G [00:07<38:57, 2.13MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 5.69M/4.98G [00:07<30:10, 2.75MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 10.4M/4.98G [00:08<16:02, 5.16MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|          | 14.0M/4.98G [00:08<12:05, 6.84MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|          | 16.0M/4.98G [00:09<14:49, 5.58MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|          | 20.1M/4.98G [00:09<11:17, 7.31MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|          | 24.2M/4.98G [00:09<09:43, 8.49MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|          | 25.9M/4.98G [00:10<10:44, 7.68MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|          | 27.6M/4.98G [00:10<11:42, 7.04MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|          | 29.1M/4.98G [00:10<12:06, 6.81MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 32.0M/4.98G [00:11<13:24, 6.14MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 36.1M/4.98G [00:11<10:35, 7.77MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|          | 40.2M/4.98G [00:11<09:14, 8.90MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 41.8M/4.98G [00:12<10:49, 7.60MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 43.5M/4.98G [00:12<11:15, 7.30MB/s]\n",
      "model-00001-of-00004.safetensors:   1%|          | 46.5M/4.98G [00:12<10:21, 7.93MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 48.0M/4.98G [00:13<14:07, 5.82MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 52.2M/4.98G [00:13<10:47, 7.60MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|          | 56.2M/4.98G [00:13<09:23, 8.73MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|          | 57.8M/4.98G [00:14<10:28, 7.82MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 61.0M/4.98G [00:14<10:13, 8.01MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|▏         | 62.6M/4.98G [00:14<10:23, 7.88MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|▏         | 64.0M/4.98G [00:15<14:10, 5.77MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|▏         | 68.1M/4.98G [00:15<10:23, 7.87MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|▏         | 71.5M/4.98G [00:16<09:24, 8.69MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|▏         | 74.6M/4.98G [00:16<09:05, 8.98MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 77.6M/4.98G [00:16<08:53, 9.19MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 80.0M/4.98G [00:17<11:07, 7.33MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 84.1M/4.98G [00:17<09:19, 8.74MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 87.3M/4.98G [00:17<08:56, 9.11MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 93.7M/4.98G [00:18<08:32, 9.52MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 96.0M/4.98G [00:18<10:34, 7.69MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 100M/4.98G [00:19<09:01, 9.01MB/s] \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 103M/4.98G [00:19<08:41, 9.35MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 106M/4.98G [00:19<08:37, 9.41MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 110M/4.98G [00:20<08:21, 9.71MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 112M/4.98G [00:20<10:19, 7.85MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 116M/4.98G [00:21<08:52, 9.13MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 120M/4.98G [00:21<08:27, 9.57MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 123M/4.98G [00:21<08:27, 9.56MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 126M/4.98G [00:21<08:26, 9.58MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 128M/4.98G [00:22<10:43, 7.53MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 132M/4.98G [00:22<09:11, 8.78MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 136M/4.98G [00:23<08:14, 9.79MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 138M/4.98G [00:23<09:35, 8.41MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 140M/4.98G [00:23<10:49, 7.45MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 142M/4.98G [00:24<10:02, 8.02MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 144M/4.98G [00:24<13:09, 6.12MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 148M/4.98G [00:24<10:16, 7.83MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 152M/4.98G [00:25<09:07, 8.81MB/s]\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 155M/4.98G [00:25<08:52, 9.05MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 158M/4.98G [00:25<08:36, 9.33MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 160M/4.98G [00:26<11:15, 7.13MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 164M/4.98G [00:26<09:21, 8.56MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 167M/4.98G [00:27<08:51, 9.05MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 171M/4.98G [00:27<08:37, 9.29MB/s]\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 174M/4.98G [00:27<08:32, 9.37MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▎         | 176M/4.98G [00:28<10:36, 7.55MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▎         | 180M/4.98G [00:28<08:58, 8.91MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▎         | 184M/4.98G [00:28<08:33, 9.33MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▎         | 187M/4.98G [00:29<08:26, 9.47MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 190M/4.98G [00:29<08:14, 9.68MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 192M/4.98G [00:29<10:23, 7.67MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 196M/4.98G [00:30<08:49, 9.02MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 200M/4.98G [00:30<08:12, 9.70MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 204M/4.98G [00:30<07:45, 10.3MB/s]\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 207M/4.98G [00:31<07:46, 10.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 208M/4.98G [00:31<11:14, 7.07MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 212M/4.98G [00:32<09:18, 8.54MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 216M/4.98G [00:32<08:32, 9.29MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 219M/4.98G [00:32<08:19, 9.52MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 222M/4.98G [00:33<08:17, 9.56MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|▍         | 224M/4.98G [00:33<11:39, 6.80MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|▍         | 228M/4.98G [00:34<09:34, 8.27MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|▍         | 232M/4.98G [00:34<08:47, 8.99MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▍         | 235M/4.98G [00:34<08:20, 9.47MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▍         | 238M/4.98G [00:34<08:08, 9.70MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|▍         | 240M/4.98G [00:35<10:29, 7.52MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|▍         | 244M/4.98G [00:35<08:50, 8.93MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▍         | 248M/4.98G [00:36<08:01, 9.82MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▌         | 251M/4.98G [00:36<07:55, 9.94MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|▌         | 254M/4.98G [00:36<07:58, 9.86MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▌         | 256M/4.98G [00:37<10:18, 7.63MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▌         | 260M/4.98G [00:37<08:44, 8.99MB/s]\n",
      "model-00001-of-00004.safetensors:   5%|▌         | 264M/4.98G [00:37<08:19, 9.44MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▌         | 267M/4.98G [00:38<08:14, 9.52MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▌         | 270M/4.98G [00:38<08:09, 9.62MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|▌         | 272M/4.98G [00:38<10:23, 7.54MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 276M/4.98G [00:39<08:48, 8.90MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 280M/4.98G [00:39<08:23, 9.33MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 283M/4.98G [00:39<08:07, 9.63MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 286M/4.98G [00:40<08:07, 9.62MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 288M/4.98G [00:40<10:57, 7.13MB/s]\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 292M/4.98G [00:41<09:08, 8.54MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 296M/4.98G [00:41<08:33, 9.11MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 299M/4.98G [00:41<08:24, 9.27MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 302M/4.98G [00:42<08:22, 9.31MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 308M/4.98G [00:42<08:28, 9.18MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   6%|▋         | 312M/4.98G [00:43<07:53, 9.85MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▋         | 315M/4.98G [00:43<07:57, 9.77MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▋         | 318M/4.98G [00:43<07:57, 9.75MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▋         | 320M/4.98G [00:44<10:31, 7.37MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 324M/4.98G [00:44<08:50, 8.77MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 328M/4.98G [00:44<08:16, 9.35MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 331M/4.98G [00:45<08:13, 9.41MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 334M/4.98G [00:45<08:08, 9.50MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 336M/4.98G [00:46<09:48, 7.88MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 340M/4.98G [00:46<08:25, 9.17MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 344M/4.98G [00:46<07:59, 9.66MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 347M/4.98G [00:47<08:01, 9.61MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 350M/4.98G [00:47<08:02, 9.60MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 352M/4.98G [00:47<09:40, 7.97MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 356M/4.98G [00:48<08:18, 9.26MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 359M/4.98G [00:48<08:09, 9.43MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 362M/4.98G [00:48<08:07, 9.47MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 366M/4.98G [00:49<07:45, 9.90MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 368M/4.98G [00:49<10:14, 7.50MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 372M/4.98G [00:49<08:43, 8.80MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 375M/4.98G [00:50<08:29, 9.03MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 378M/4.98G [00:50<10:37, 7.21MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 384M/4.98G [00:51<09:52, 7.75MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 385M/4.98G [00:51<13:18, 5.75MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 388M/4.98G [00:52<10:48, 7.07MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 391M/4.98G [00:52<09:35, 7.97MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 395M/4.98G [00:52<08:53, 8.59MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 398M/4.98G [00:53<08:36, 8.86MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 400M/4.98G [00:56<32:06, 2.38MB/s]\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 404M/4.98G [00:56<22:09, 3.44MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 407M/4.98G [00:56<17:57, 4.24MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 410M/4.98G [00:57<14:55, 5.10MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 414M/4.98G [00:57<12:38, 6.02MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 416M/4.98G [00:58<12:53, 5.90MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 420M/4.98G [00:58<10:20, 7.35MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▊         | 423M/4.98G [00:58<09:34, 7.92MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   9%|▊         | 427M/4.98G [00:59<08:28, 8.94MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▊         | 430M/4.98G [00:59<08:10, 9.27MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   9%|▊         | 432M/4.98G [00:59<10:46, 7.03MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 436M/4.98G [01:00<09:02, 8.38MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 440M/4.98G [01:00<08:16, 9.13MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 443M/4.98G [01:00<08:01, 9.41MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 447M/4.98G [01:01<07:30, 10.1MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 448M/4.98G [01:01<10:20, 7.30MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 452M/4.98G [01:01<08:40, 8.69MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 456M/4.98G [01:02<08:09, 9.23MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 459M/4.98G [01:02<07:42, 9.76MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 463M/4.98G [01:02<07:25, 10.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 464M/4.98G [01:03<13:02, 5.76MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 468M/4.98G [01:04<10:32, 7.13MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 470M/4.98G [01:04<11:06, 6.76MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 473M/4.98G [01:04<10:09, 7.39MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 476M/4.98G [01:05<09:24, 7.97MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 479M/4.98G [01:05<08:57, 8.37MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 480M/4.98G [01:05<11:15, 6.65MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 484M/4.98G [01:06<09:04, 8.25MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 487M/4.98G [01:06<08:43, 8.57MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 490M/4.98G [01:06<08:26, 8.86MB/s]\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 493M/4.98G [01:07<08:18, 8.99MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 496M/4.98G [01:07<09:17, 8.04MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|█         | 500M/4.98G [01:07<08:04, 9.24MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|█         | 503M/4.98G [01:08<07:53, 9.44MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|█         | 507M/4.98G [01:08<07:45, 9.59MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|█         | 510M/4.98G [01:08<07:50, 9.50MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|█         | 512M/4.98G [01:09<09:48, 7.59MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|█         | 516M/4.98G [01:09<08:23, 8.86MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|█         | 519M/4.98G [01:09<08:13, 9.02MB/s]\n",
      "model-00001-of-00004.safetensors:  10%|█         | 522M/4.98G [01:10<08:05, 9.18MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 525M/4.98G [01:10<08:03, 9.21MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 528M/4.98G [01:11<09:01, 8.22MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 532M/4.98G [01:11<07:55, 9.34MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 535M/4.98G [01:11<07:41, 9.62MB/s]\n",
      "model-00001-of-00004.safetensors:  11%|█         | 538M/4.98G [01:12<07:43, 9.57MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|█         | 541M/4.98G [01:12<07:45, 9.52MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 544M/4.98G [01:12<09:45, 7.57MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 548M/4.98G [01:13<08:19, 8.86MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|█         | 551M/4.98G [01:13<08:07, 9.07MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 554M/4.98G [01:13<08:01, 9.18MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|█         | 557M/4.98G [01:14<07:55, 9.30MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|█▏        | 560M/4.98G [01:14<09:31, 7.73MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|█▏        | 564M/4.98G [01:15<08:10, 8.99MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█▏        | 567M/4.98G [01:15<07:49, 9.38MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█▏        | 571M/4.98G [01:15<07:36, 9.65MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 574M/4.98G [01:15<07:38, 9.60MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 576M/4.98G [01:16<09:42, 7.55MB/s]\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 580M/4.98G [01:16<08:19, 8.81MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 583M/4.98G [01:17<08:11, 8.94MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 586M/4.98G [01:17<08:02, 9.10MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 589M/4.98G [01:17<07:55, 9.22MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 592M/4.98G [01:18<09:01, 8.10MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 596M/4.98G [01:18<07:53, 9.25MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 599M/4.98G [01:18<07:39, 9.53MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 603M/4.98G [01:19<07:32, 9.66MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 606M/4.98G [01:19<07:35, 9.60MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 608M/4.98G [01:20<09:25, 7.73MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 612M/4.98G [01:20<08:04, 9.00MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 615M/4.98G [01:20<07:50, 9.28MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 619M/4.98G [01:21<07:36, 9.55MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 622M/4.98G [01:21<07:16, 9.98MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 624M/4.98G [01:21<09:23, 7.72MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 628M/4.98G [01:22<08:08, 8.90MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 632M/4.98G [01:22<07:46, 9.31MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 635M/4.98G [01:22<07:38, 9.48MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 638M/4.98G [01:23<07:29, 9.65MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 640M/4.98G [01:23<09:39, 7.49MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 644M/4.98G [01:23<08:13, 8.78MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 648M/4.98G [01:24<07:44, 9.31MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 651M/4.98G [01:24<07:34, 9.51MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 655M/4.98G [01:24<07:03, 10.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 656M/4.98G [01:25<09:48, 7.34MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 660M/4.98G [01:25<08:20, 8.63MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 663M/4.98G [01:26<09:57, 7.22MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 667M/4.98G [01:26<08:38, 8.32MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 669M/4.98G [01:27<10:17, 6.97MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▎        | 672M/4.98G [01:27<13:01, 5.51MB/s]\n",
      "model-00001-of-00004.safetensors:  14%|█▎        | 676M/4.98G [01:28<10:24, 6.89MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|█▎        | 678M/4.98G [01:28<10:56, 6.55MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|█▎        | 679M/4.98G [01:28<11:31, 6.21MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|█▎        | 681M/4.98G [01:29<12:02, 5.94MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|█▎        | 684M/4.98G [01:29<10:20, 6.92MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 685M/4.98G [01:29<11:05, 6.44MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 687M/4.98G [01:30<11:40, 6.13MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 688M/4.98G [01:30<15:42, 4.55MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 692M/4.98G [01:30<10:52, 6.57MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 694M/4.98G [01:31<11:35, 6.16MB/s]\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 695M/4.98G [01:31<11:59, 5.95MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 698M/4.98G [01:31<10:26, 6.83MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 700M/4.98G [01:32<11:04, 6.43MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 703M/4.98G [01:32<09:54, 7.19MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 704M/4.98G [01:33<15:36, 4.56MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 708M/4.98G [01:33<11:10, 6.37MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 710M/4.98G [01:33<11:40, 6.09MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 711M/4.98G [01:34<12:06, 5.87MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 714M/4.98G [01:34<10:22, 6.84MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 716M/4.98G [01:34<11:00, 6.45MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 719M/4.98G [01:35<09:38, 7.36MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 720M/4.98G [01:35<15:33, 4.56MB/s]\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 724M/4.98G [01:36<11:06, 6.38MB/s]\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 727M/4.98G [01:36<11:37, 6.09MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 730M/4.98G [01:37<10:07, 6.99MB/s]\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 735M/4.98G [01:37<09:40, 7.31MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 736M/4.98G [01:38<13:47, 5.12MB/s]\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 740M/4.98G [01:38<10:06, 6.99MB/s]\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 742M/4.98G [01:38<10:40, 6.61MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 743M/4.98G [01:39<11:18, 6.24MB/s]\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 747M/4.98G [01:39<09:23, 7.51MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 748M/4.98G [01:39<10:02, 7.02MB/s]\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 750M/4.98G [01:40<10:47, 6.52MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 752M/4.98G [01:40<12:43, 5.53MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 756M/4.98G [01:40<09:32, 7.37MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 758M/4.98G [01:41<10:16, 6.84MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 759M/4.98G [01:41<10:58, 6.41MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 762M/4.98G [01:41<09:35, 7.32MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 764M/4.98G [01:42<10:25, 6.74MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 767M/4.98G [01:42<09:15, 7.57MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 768M/4.98G [01:42<12:33, 5.58MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 774M/4.98G [01:43<10:25, 6.72MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 776M/4.98G [01:43<09:26, 7.42MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 778M/4.98G [01:44<10:08, 6.90MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 781M/4.98G [01:44<09:06, 7.67MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 783M/4.98G [01:44<09:56, 7.03MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 784M/4.98G [01:45<13:57, 5.01MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 788M/4.98G [01:46<12:24, 5.62MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 790M/4.98G [01:46<12:27, 5.60MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 793M/4.98G [01:46<10:02, 6.94MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 795M/4.98G [01:46<10:40, 6.53MB/s]\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 798M/4.98G [01:47<09:26, 7.38MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 800M/4.98G [01:47<10:10, 6.84MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 800M/4.98G [01:48<14:47, 4.70MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 804M/4.98G [01:48<10:40, 6.51MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 806M/4.98G [01:48<11:09, 6.23MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▋        | 811M/4.98G [01:49<09:52, 7.04MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▋        | 814M/4.98G [01:49<08:55, 7.77MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  16%|█▋        | 816M/4.98G [01:50<10:56, 6.34MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  16%|█▋        | 820M/4.98G [01:50<08:44, 7.92MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 822M/4.98G [01:50<09:12, 7.52MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 825M/4.98G [01:51<08:21, 8.27MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 828M/4.98G [01:51<08:00, 8.63MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 831M/4.98G [01:51<07:43, 8.94MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 832M/4.98G [01:52<11:19, 6.10MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 836M/4.98G [01:52<09:09, 7.54MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 839M/4.98G [01:52<08:37, 8.00MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 842M/4.98G [01:53<08:03, 8.55MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 845M/4.98G [01:53<07:40, 8.98MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 848M/4.98G [01:54<09:20, 7.36MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 852M/4.98G [01:54<08:01, 8.56MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 855M/4.98G [01:54<07:54, 8.68MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 858M/4.98G [01:55<07:43, 8.90MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 861M/4.98G [01:55<07:35, 9.04MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 864M/4.98G [01:55<07:28, 9.16MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 865M/4.98G [01:56<10:36, 6.46MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 868M/4.98G [01:56<09:18, 7.36MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 872M/4.98G [01:56<08:15, 8.29MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 875M/4.98G [01:57<07:52, 8.68MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 878M/4.98G [01:57<07:42, 8.87MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 880M/4.98G [01:57<08:57, 7.62MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 884M/4.98G [01:58<07:40, 8.88MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 887M/4.98G [01:58<09:26, 7.21MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 891M/4.98G [01:59<08:03, 8.46MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 893M/4.98G [01:59<08:49, 7.71MB/s]\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 895M/4.98G [01:59<08:21, 8.13MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 896M/4.98G [02:00<12:02, 5.65MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 900M/4.98G [02:00<09:27, 7.18MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 903M/4.98G [02:00<08:31, 7.97MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 906M/4.98G [02:01<08:00, 8.47MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 910M/4.98G [02:01<07:29, 9.05MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 912M/4.98G [02:02<09:31, 7.11MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 916M/4.98G [02:02<07:56, 8.52MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 920M/4.98G [02:02<07:27, 9.06MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▊        | 923M/4.98G [02:03<07:10, 9.42MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  19%|█▊        | 926M/4.98G [02:03<07:09, 9.43MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  19%|█▊        | 928M/4.98G [02:03<08:59, 7.50MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▊        | 932M/4.98G [02:04<07:37, 8.84MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 936M/4.98G [02:04<07:13, 9.32MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 939M/4.98G [02:04<07:13, 9.31MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 942M/4.98G [02:05<06:54, 9.72MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 944M/4.98G [02:05<08:39, 7.77MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 948M/4.98G [02:05<07:26, 9.02MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 952M/4.98G [02:06<07:02, 9.52MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 955M/4.98G [02:06<07:00, 9.56MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 958M/4.98G [02:06<06:55, 9.67MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 960M/4.98G [02:07<08:57, 7.47MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 964M/4.98G [02:07<07:36, 8.78MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 968M/4.98G [02:08<07:13, 9.26MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|█▉        | 971M/4.98G [02:08<06:58, 9.57MB/s]\n",
      "model-00001-of-00004.safetensors:  20%|█▉        | 974M/4.98G [02:08<06:53, 9.68MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|█▉        | 976M/4.98G [02:09<10:45, 6.20MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|█▉        | 980M/4.98G [02:09<08:49, 7.55MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|█▉        | 985M/4.98G [02:10<08:45, 7.60MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|█▉        | 988M/4.98G [02:10<08:10, 8.14MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|█▉        | 991M/4.98G [02:11<07:49, 8.50MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|█▉        | 992M/4.98G [02:11<10:14, 6.48MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|██        | 996M/4.98G [02:11<08:14, 8.05MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|██        | 998M/4.98G [02:12<08:26, 7.86MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|██        | 1.00G/4.98G [02:12<07:55, 8.35MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|██        | 1.00G/4.98G [02:12<07:36, 8.70MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|██        | 1.01G/4.98G [02:13<07:09, 9.24MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|██        | 1.01G/4.98G [02:13<10:10, 6.50MB/s]\n",
      "model-00001-of-00004.safetensors:  20%|██        | 1.01G/4.98G [02:13<08:50, 7.47MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|██        | 1.02G/4.98G [02:14<08:06, 8.15MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|██        | 1.02G/4.98G [02:14<08:11, 8.06MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.02G/4.98G [02:14<07:44, 8.51MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.02G/4.98G [02:15<07:25, 8.87MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.02G/4.98G [02:15<10:54, 6.04MB/s]\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.03G/4.98G [02:15<09:02, 7.29MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.03G/4.98G [02:16<08:12, 8.00MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.03G/4.98G [02:16<07:32, 8.70MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.04G/4.98G [02:16<07:16, 9.03MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.04G/4.98G [02:17<08:37, 7.60MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.04G/4.98G [02:17<07:21, 8.91MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.05G/4.98G [02:18<06:56, 9.42MB/s]\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.05G/4.98G [02:18<06:40, 9.80MB/s]\n",
      "model-00004-of-00004.safetensors: 100%|██████████| 1.17G/1.17G [02:18<00:00, 8.41MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.06G/4.98G [02:19<08:48, 7.41MB/s]\n",
      "model-00001-of-00004.safetensors:  21%|██▏       | 1.06G/4.98G [02:19<07:27, 8.75MB/s]\n",
      "model-00001-of-00004.safetensors:  21%|██▏       | 1.06G/4.98G [02:19<07:07, 9.15MB/s]\n",
      "model-00001-of-00004.safetensors:  21%|██▏       | 1.07G/4.98G [02:20<06:52, 9.48MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.07G/4.98G [02:20<08:12, 7.92MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.08G/4.98G [02:21<07:10, 9.05MB/s]\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.08G/4.98G [02:21<07:03, 9.21MB/s]\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.08G/4.98G [02:21<06:59, 9.28MB/s]\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.09G/4.98G [02:22<06:56, 9.34MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.09G/4.98G [02:23<07:12, 8.98MB/s]\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.10G/4.98G [02:23<06:56, 9.33MB/s]\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.10G/4.98G [02:23<06:53, 9.38MB/s]\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.10G/4.98G [02:24<06:47, 9.50MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.10G/4.98G [02:24<08:16, 7.80MB/s]\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.11G/4.98G [02:24<07:07, 9.05MB/s]\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.11G/4.98G [02:25<06:39, 9.67MB/s]\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.12G/4.98G [02:25<06:41, 9.62MB/s]\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.12G/4.98G [02:26<08:15, 7.78MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.12G/4.98G [02:26<07:07, 9.02MB/s]\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.13G/4.98G [02:26<07:30, 8.55MB/s]\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.13G/4.98G [02:27<07:16, 8.81MB/s]\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.13G/4.98G [02:27<07:04, 9.06MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.14G/4.98G [02:28<09:12, 6.96MB/s]\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.14G/4.98G [02:28<07:47, 8.21MB/s]\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.14G/4.98G [02:29<07:16, 8.78MB/s]\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.15G/4.98G [02:29<06:58, 9.14MB/s]\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.15G/4.98G [02:29<06:34, 9.70MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.16G/4.98G [02:30<07:23, 8.61MB/s]\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.16G/4.98G [02:30<06:58, 9.11MB/s]\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.16G/4.98G [02:31<06:41, 9.49MB/s]\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.17G/4.98G [02:31<06:42, 9.47MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.17G/4.98G [02:31<08:07, 7.81MB/s]\n",
      "model-00001-of-00004.safetensors:  24%|██▎       | 1.17G/4.98G [02:32<06:57, 9.11MB/s]\n",
      "model-00001-of-00004.safetensors:  24%|██▎       | 1.18G/4.98G [02:32<06:44, 9.38MB/s]\n",
      "model-00001-of-00004.safetensors:  24%|██▎       | 1.18G/4.98G [02:33<06:43, 9.42MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.18G/4.98G [02:33<08:10, 7.73MB/s]\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.19G/4.98G [02:34<07:01, 9.00MB/s]\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.19G/4.98G [02:34<06:48, 9.27MB/s]\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.19G/4.98G [02:34<06:28, 9.73MB/s]\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.20G/4.98G [02:34<06:31, 9.65MB/s]\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.20G/4.98G [02:35<07:59, 7.87MB/s]\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.20G/4.98G [02:35<06:52, 9.14MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.21G/4.98G [02:36<06:41, 9.39MB/s]\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.21G/4.98G [02:36<06:44, 9.31MB/s]\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.21G/4.98G [02:36<06:38, 9.45MB/s]\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.22G/4.98G [02:37<08:14, 7.61MB/s]\n",
      "model-00001-of-00004.safetensors:  25%|██▍       | 1.22G/4.98G [02:37<07:02, 8.89MB/s]\n",
      "model-00001-of-00004.safetensors:  25%|██▍       | 1.22G/4.98G [02:37<06:42, 9.33MB/s]\n",
      "model-00001-of-00004.safetensors:  25%|██▍       | 1.23G/4.98G [02:38<06:35, 9.47MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  25%|██▍       | 1.23G/4.98G [02:38<06:31, 9.57MB/s]\n",
      "model-00001-of-00004.safetensors:  25%|██▍       | 1.23G/4.98G [02:39<08:18, 7.51MB/s]\n",
      "model-00001-of-00004.safetensors:  25%|██▍       | 1.24G/4.98G [02:39<07:03, 8.83MB/s]\n",
      "model-00001-of-00004.safetensors:  25%|██▍       | 1.24G/4.98G [02:39<06:52, 9.06MB/s]\n",
      "model-00001-of-00004.safetensors:  25%|██▍       | 1.24G/4.98G [02:40<06:45, 9.20MB/s]\n",
      "model-00001-of-00004.safetensors:  25%|██▌       | 1.25G/4.98G [02:40<06:36, 9.40MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  25%|██▌       | 1.25G/4.98G [02:40<08:11, 7.59MB/s]\n",
      "model-00001-of-00004.safetensors:  25%|██▌       | 1.25G/4.98G [02:41<07:02, 8.82MB/s]\n",
      "model-00001-of-00004.safetensors:  25%|██▌       | 1.26G/4.98G [02:41<06:36, 9.38MB/s]\n",
      "model-00001-of-00004.safetensors:  25%|██▌       | 1.26G/4.98G [02:41<06:22, 9.71MB/s]\n",
      "model-00001-of-00004.safetensors:  25%|██▌       | 1.26G/4.98G [02:42<06:19, 9.79MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  25%|██▌       | 1.27G/4.98G [02:42<07:01, 8.80MB/s]\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.27G/4.98G [02:43<06:50, 9.04MB/s]\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.27G/4.98G [02:43<06:39, 9.26MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.28G/4.98G [02:43<06:32, 9.42MB/s]\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.28G/4.98G [02:44<08:13, 7.48MB/s]\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.28G/4.98G [02:44<06:59, 8.80MB/s]\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.29G/4.98G [02:45<06:30, 9.43MB/s]\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.29G/4.98G [02:45<06:30, 9.44MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.30G/4.98G [02:46<08:10, 7.50MB/s]\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.30G/4.98G [02:46<06:56, 8.82MB/s]\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.30G/4.98G [02:46<06:41, 9.15MB/s]\n",
      "model-00001-of-00004.safetensors:  26%|██▋       | 1.31G/4.98G [02:47<06:25, 9.53MB/s]\n",
      "model-00001-of-00004.safetensors:  26%|██▋       | 1.31G/4.98G [02:47<06:25, 9.51MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  26%|██▋       | 1.31G/4.98G [02:48<07:59, 7.65MB/s]\n",
      "model-00001-of-00004.safetensors:  26%|██▋       | 1.32G/4.98G [02:48<06:50, 8.91MB/s]\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.32G/4.98G [02:49<08:35, 7.10MB/s]\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.32G/4.98G [02:49<07:16, 8.37MB/s]\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.32G/4.98G [02:49<07:49, 7.77MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.33G/4.98G [02:50<10:04, 6.04MB/s]\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.33G/4.98G [02:50<08:09, 7.45MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.34G/4.98G [02:51<07:39, 7.93MB/s]\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.34G/4.98G [02:51<08:54, 6.81MB/s]\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.34G/4.98G [02:52<07:33, 8.02MB/s]\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.34G/4.98G [02:52<08:14, 7.35MB/s]\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.34G/4.98G [02:52<11:06, 5.45MB/s]\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.35G/4.98G [02:53<08:48, 6.86MB/s]\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.35G/4.98G [02:53<09:22, 6.45MB/s]\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.35G/4.98G [02:53<08:20, 7.25MB/s]\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.35G/4.98G [02:54<08:58, 6.73MB/s]\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.36G/4.98G [02:54<08:09, 7.39MB/s]\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.36G/4.98G [02:54<07:37, 7.90MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.36G/4.98G [02:55<10:49, 5.57MB/s]\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.36G/4.98G [02:55<08:47, 6.85MB/s]\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.37G/4.98G [02:55<09:02, 6.66MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.37G/4.98G [02:56<07:55, 7.59MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.37G/4.98G [02:56<08:36, 6.99MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.37G/4.98G [02:56<07:47, 7.71MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.38G/4.98G [02:57<08:53, 6.75MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.38G/4.98G [02:57<07:13, 8.30MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.38G/4.98G [02:57<07:57, 7.53MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.38G/4.98G [02:58<07:16, 8.23MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.39G/4.98G [02:58<06:55, 8.63MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.39G/4.98G [02:58<06:41, 8.94MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.39G/4.98G [02:59<09:13, 6.47MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.40G/4.98G [02:59<07:20, 8.13MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.40G/4.98G [03:00<07:28, 7.97MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.40G/4.98G [03:00<07:02, 8.45MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.41G/4.98G [03:00<06:43, 8.84MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.41G/4.98G [03:01<09:41, 6.14MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.41G/4.98G [03:01<07:38, 7.78MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.41G/4.98G [03:01<08:11, 7.24MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.42G/4.98G [03:02<07:27, 7.95MB/s]\n",
      "model-00001-of-00004.safetensors:  29%|██▊       | 1.42G/4.98G [03:02<07:02, 8.42MB/s]\n",
      "model-00001-of-00004.safetensors:  29%|██▊       | 1.42G/4.98G [03:02<06:43, 8.80MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  29%|██▊       | 1.42G/4.98G [03:03<09:36, 6.17MB/s]\n",
      "model-00001-of-00004.safetensors:  29%|██▊       | 1.43G/4.98G [03:03<07:33, 7.83MB/s]\n",
      "model-00001-of-00004.safetensors:  29%|██▊       | 1.43G/4.98G [03:03<07:59, 7.40MB/s]\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.43G/4.98G [03:04<07:16, 8.12MB/s]\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.44G/4.98G [03:04<06:53, 8.56MB/s]\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.44G/4.98G [03:04<06:40, 8.84MB/s]\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.44G/4.98G [03:05<09:03, 6.50MB/s]\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.44G/4.98G [03:05<07:27, 7.90MB/s]\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.45G/4.98G [03:05<08:10, 7.20MB/s]\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.45G/4.98G [03:06<07:14, 8.12MB/s]\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.45G/4.98G [03:06<06:47, 8.65MB/s]\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.45G/4.98G [03:06<07:22, 7.96MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.46G/4.98G [03:07<09:08, 6.42MB/s]\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.46G/4.98G [03:07<07:18, 8.02MB/s]\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.46G/4.98G [03:08<07:57, 7.37MB/s]\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.46G/4.98G [03:08<07:22, 7.94MB/s]\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.47G/4.98G [03:08<06:51, 8.52MB/s]\n",
      "model-00001-of-00004.safetensors:  30%|██▉       | 1.47G/4.98G [03:09<06:37, 8.83MB/s]\n",
      "model-00001-of-00004.safetensors:  30%|██▉       | 1.47G/4.98G [03:09<09:25, 6.20MB/s]\n",
      "model-00001-of-00004.safetensors:  30%|██▉       | 1.48G/4.98G [03:10<07:59, 7.30MB/s]\n",
      "model-00001-of-00004.safetensors:  30%|██▉       | 1.48G/4.98G [03:10<07:25, 7.85MB/s]\n",
      "model-00001-of-00004.safetensors:  30%|██▉       | 1.48G/4.98G [03:10<07:01, 8.29MB/s]\n",
      "model-00001-of-00004.safetensors:  30%|██▉       | 1.49G/4.98G [03:11<06:45, 8.60MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  30%|██▉       | 1.49G/4.98G [03:11<09:10, 6.33MB/s]\n",
      "model-00001-of-00004.safetensors:  30%|██▉       | 1.49G/4.98G [03:11<07:25, 7.82MB/s]\n",
      "model-00001-of-00004.safetensors:  30%|███       | 1.49G/4.98G [03:12<07:30, 7.73MB/s]\n",
      "model-00001-of-00004.safetensors:  30%|███       | 1.50G/4.98G [03:12<07:06, 8.15MB/s]\n",
      "model-00001-of-00004.safetensors:  30%|███       | 1.50G/4.98G [03:12<06:38, 8.72MB/s]\n",
      "model-00001-of-00004.safetensors:  30%|███       | 1.50G/4.98G [03:13<06:31, 8.87MB/s]\n",
      "model-00001-of-00004.safetensors:  30%|███       | 1.50G/4.98G [03:13<09:17, 6.22MB/s]\n",
      "model-00001-of-00004.safetensors:  30%|███       | 1.51G/4.98G [03:14<07:43, 7.48MB/s]\n",
      "model-00001-of-00004.safetensors:  30%|███       | 1.51G/4.98G [03:14<07:16, 7.94MB/s]\n",
      "model-00001-of-00004.safetensors:  30%|███       | 1.51G/4.98G [03:14<06:49, 8.46MB/s]\n",
      "model-00001-of-00004.safetensors:  30%|███       | 1.52G/4.98G [03:14<06:37, 8.70MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.52G/4.98G [03:15<09:00, 6.40MB/s]\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.53G/4.98G [03:16<07:44, 7.43MB/s]\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.53G/4.98G [03:16<07:14, 7.94MB/s]\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.53G/4.98G [03:16<06:52, 8.35MB/s]\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.53G/4.98G [03:17<06:37, 8.67MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.54G/4.98G [03:18<07:13, 7.93MB/s]\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.54G/4.98G [03:18<06:37, 8.64MB/s]\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.55G/4.98G [03:18<06:16, 9.10MB/s]\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.55G/4.98G [03:19<06:11, 9.22MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  31%|███▏      | 1.56G/4.98G [03:19<06:35, 8.65MB/s]\n",
      "model-00001-of-00004.safetensors:  31%|███▏      | 1.56G/4.98G [03:20<06:12, 9.18MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  31%|███▏      | 1.56G/4.98G [03:20<05:59, 9.51MB/s]\n",
      "model-00001-of-00004.safetensors:  31%|███▏      | 1.57G/4.98G [03:20<05:57, 9.53MB/s]\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.57G/4.98G [03:21<07:20, 7.74MB/s]\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.57G/4.98G [03:21<06:16, 9.04MB/s]\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.58G/4.98G [03:22<06:00, 9.43MB/s]\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.58G/4.98G [03:22<05:57, 9.49MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.58G/4.98G [03:23<07:29, 7.55MB/s]\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.59G/4.98G [03:23<06:22, 8.86MB/s]\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.59G/4.98G [03:23<06:05, 9.26MB/s]\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.59G/4.98G [03:24<05:52, 9.60MB/s]\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.60G/4.98G [03:24<05:48, 9.69MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.60G/4.98G [03:25<06:25, 8.76MB/s]\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.61G/4.98G [03:25<06:01, 9.33MB/s]\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.61G/4.98G [03:25<05:59, 9.36MB/s]\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.61G/4.98G [03:26<05:57, 9.40MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.62G/4.98G [03:26<07:18, 7.66MB/s]\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.62G/4.98G [03:27<06:14, 8.95MB/s]\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.62G/4.98G [03:27<06:08, 9.09MB/s]\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.62G/4.98G [03:27<08:59, 6.22MB/s]\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.63G/4.98G [03:28<07:14, 7.70MB/s]\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.63G/4.98G [03:29<09:43, 5.73MB/s]\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.64G/4.98G [03:29<07:30, 7.41MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.64G/4.98G [03:29<06:55, 8.03MB/s]\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.64G/4.98G [03:30<06:31, 8.53MB/s]\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.65G/4.98G [03:30<06:17, 8.83MB/s]\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.65G/4.98G [03:30<07:24, 7.49MB/s]\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.65G/4.98G [03:31<06:18, 8.77MB/s]\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.66G/4.98G [03:31<05:56, 9.31MB/s]\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.66G/4.98G [03:31<05:45, 9.60MB/s]\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.66G/4.98G [03:32<05:42, 9.67MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  34%|███▎      | 1.67G/4.98G [03:32<06:07, 9.01MB/s]\n",
      "model-00001-of-00004.safetensors:  34%|███▎      | 1.67G/4.98G [03:33<05:52, 9.39MB/s]\n",
      "model-00001-of-00004.safetensors:  34%|███▎      | 1.67G/4.98G [03:33<05:41, 9.66MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  34%|███▎      | 1.68G/4.98G [03:33<05:32, 9.91MB/s]\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.68G/4.98G [03:34<07:16, 7.55MB/s]\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.68G/4.98G [03:34<06:10, 8.88MB/s]\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.69G/4.98G [03:35<05:54, 9.29MB/s]\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.69G/4.98G [03:35<05:37, 9.72MB/s]\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.69G/4.98G [03:35<05:38, 9.70MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.70G/4.98G [03:36<07:22, 7.41MB/s]\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.70G/4.98G [03:36<06:07, 8.92MB/s]\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.71G/4.98G [03:37<05:53, 9.24MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.71G/4.98G [03:37<05:50, 9.31MB/s]\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.71G/4.98G [03:38<07:13, 7.53MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  35%|███▍      | 1.72G/4.98G [03:38<06:03, 8.96MB/s]\n",
      "model-00001-of-00004.safetensors:  35%|███▍      | 1.72G/4.98G [03:39<05:55, 9.15MB/s]\n",
      "model-00001-of-00004.safetensors:  35%|███▍      | 1.73G/4.98G [03:39<05:53, 9.19MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  35%|███▍      | 1.73G/4.98G [03:39<06:58, 7.77MB/s]\n",
      "model-00001-of-00004.safetensors:  35%|███▍      | 1.73G/4.98G [03:40<06:00, 9.01MB/s]\n",
      "model-00001-of-00004.safetensors:  35%|███▍      | 1.74G/4.98G [03:40<05:51, 9.22MB/s]\n",
      "model-00001-of-00004.safetensors:  35%|███▍      | 1.74G/4.98G [03:40<05:41, 9.47MB/s]\n",
      "model-00001-of-00004.safetensors:  35%|███▍      | 1.74G/4.98G [03:41<05:40, 9.51MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  35%|███▌      | 1.74G/4.98G [03:41<06:39, 8.09MB/s]\n",
      "model-00001-of-00004.safetensors:  35%|███▌      | 1.75G/4.98G [03:41<05:48, 9.26MB/s]\n",
      "model-00001-of-00004.safetensors:  35%|███▌      | 1.75G/4.98G [03:42<05:36, 9.57MB/s]\n",
      "model-00001-of-00004.safetensors:  35%|███▌      | 1.76G/4.98G [03:42<05:27, 9.83MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  35%|███▌      | 1.76G/4.98G [03:43<07:02, 7.61MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.77G/4.98G [03:44<05:48, 9.20MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.77G/4.98G [03:44<05:40, 9.41MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.78G/4.98G [03:45<07:06, 7.50MB/s]\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.78G/4.98G [03:45<06:02, 8.81MB/s]\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.78G/4.98G [03:45<05:41, 9.35MB/s]\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.79G/4.98G [03:46<05:35, 9.51MB/s]\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.79G/4.98G [03:46<06:45, 7.85MB/s]\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.80G/4.98G [03:47<05:51, 9.04MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.80G/4.98G [03:47<05:49, 9.10MB/s]\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.80G/4.98G [03:47<05:43, 9.24MB/s]\n",
      "model-00001-of-00004.safetensors:  36%|███▋      | 1.81G/4.98G [03:48<05:41, 9.28MB/s]\n",
      "model-00001-of-00004.safetensors:  36%|███▋      | 1.81G/4.98G [03:48<06:31, 8.09MB/s]\n",
      "model-00001-of-00004.safetensors:  36%|███▋      | 1.81G/4.98G [03:49<05:40, 9.29MB/s]\n",
      "model-00001-of-00004.safetensors:  36%|███▋      | 1.82G/4.98G [03:49<05:30, 9.57MB/s]\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.82G/4.98G [03:49<05:25, 9.69MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.82G/4.98G [03:50<05:22, 9.78MB/s]\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.82G/4.98G [03:50<06:41, 7.85MB/s]\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.83G/4.98G [03:50<05:45, 9.11MB/s]\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.83G/4.98G [03:51<05:29, 9.54MB/s]\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.83G/4.98G [03:51<05:29, 9.53MB/s]\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.84G/4.98G [03:51<05:24, 9.66MB/s]\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.84G/4.98G [03:52<06:31, 8.00MB/s]\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.84G/4.98G [03:52<05:39, 9.23MB/s]\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.85G/4.98G [03:52<05:21, 9.72MB/s]\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.85G/4.98G [03:53<05:10, 10.1MB/s]\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.85G/4.98G [03:53<05:09, 10.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.86G/4.98G [03:54<06:05, 8.53MB/s]\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.86G/4.98G [03:54<05:43, 9.07MB/s]\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.87G/4.98G [03:55<05:26, 9.53MB/s]\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.87G/4.98G [03:55<05:20, 9.70MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.87G/4.98G [03:55<07:04, 7.32MB/s]\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.88G/4.98G [03:56<05:58, 8.64MB/s]\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.88G/4.98G [03:56<05:30, 9.38MB/s]\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.88G/4.98G [03:56<05:23, 9.55MB/s]\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.89G/4.98G [03:57<05:02, 10.2MB/s]\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.89G/4.98G [03:57<06:58, 7.39MB/s]\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.89G/4.98G [03:58<08:27, 6.07MB/s]\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.90G/4.98G [03:58<06:50, 7.50MB/s]\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.90G/4.98G [03:59<07:20, 6.98MB/s]\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.90G/4.98G [03:59<06:45, 7.58MB/s]\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.90G/4.98G [04:00<08:11, 6.25MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.91G/4.98G [04:00<06:31, 7.83MB/s]\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.91G/4.98G [04:00<06:28, 7.88MB/s]\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.92G/4.98G [04:01<06:08, 8.30MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|███▊      | 1.92G/4.98G [04:01<05:55, 8.61MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  39%|███▊      | 1.92G/4.98G [04:02<07:42, 6.61MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|███▊      | 1.92G/4.98G [04:02<06:12, 8.20MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|███▊      | 1.93G/4.98G [04:02<05:51, 8.68MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.93G/4.98G [04:03<05:33, 9.14MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.93G/4.98G [04:03<05:27, 9.31MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.94G/4.98G [04:03<06:43, 7.53MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.94G/4.98G [04:04<05:44, 8.82MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.95G/4.98G [04:04<05:29, 9.20MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.95G/4.98G [04:05<05:22, 9.38MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.95G/4.98G [04:05<06:23, 7.88MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.96G/4.98G [04:05<05:31, 9.11MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.96G/4.98G [04:06<05:27, 9.20MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.96G/4.98G [04:06<05:18, 9.48MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.97G/4.98G [04:06<05:21, 9.38MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  40%|███▉      | 1.97G/4.98G [04:07<06:28, 7.75MB/s]\n",
      "model-00001-of-00004.safetensors:  40%|███▉      | 1.97G/4.98G [04:07<05:33, 9.01MB/s]\n",
      "model-00001-of-00004.safetensors:  40%|███▉      | 1.98G/4.98G [04:08<05:22, 9.32MB/s]\n",
      "model-00001-of-00004.safetensors:  40%|███▉      | 1.98G/4.98G [04:08<05:11, 9.64MB/s]\n",
      "model-00001-of-00004.safetensors:  40%|███▉      | 1.98G/4.98G [04:08<05:13, 9.55MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  40%|███▉      | 1.98G/4.98G [04:09<06:33, 7.60MB/s]\n",
      "model-00001-of-00004.safetensors:  40%|███▉      | 1.99G/4.98G [04:09<05:39, 8.81MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  40%|████      | 2.00G/4.98G [04:10<05:46, 8.61MB/s]\n",
      "model-00001-of-00004.safetensors:  40%|████      | 2.00G/4.98G [04:10<06:17, 7.88MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  40%|████      | 2.00G/4.98G [04:11<08:02, 6.16MB/s]\n",
      "model-00001-of-00004.safetensors:  40%|████      | 2.00G/4.98G [04:11<06:33, 7.55MB/s]\n",
      "model-00001-of-00004.safetensors:  40%|████      | 2.01G/4.98G [04:12<06:59, 7.08MB/s]\n",
      "model-00001-of-00004.safetensors:  40%|████      | 2.01G/4.98G [04:12<06:24, 7.72MB/s]\n",
      "model-00001-of-00004.safetensors:  40%|████      | 2.01G/4.98G [04:12<05:57, 8.29MB/s]\n",
      "model-00001-of-00004.safetensors:  40%|████      | 2.01G/4.98G [04:13<06:30, 7.59MB/s]\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.02G/4.98G [04:13<07:37, 6.47MB/s]\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.02G/4.98G [04:14<06:18, 7.80MB/s]\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.03G/4.98G [04:14<05:57, 8.26MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.03G/4.98G [04:14<05:43, 8.58MB/s]\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.03G/4.98G [04:15<05:33, 8.83MB/s]\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.03G/4.98G [04:15<07:44, 6.34MB/s]\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.04G/4.98G [04:15<06:14, 7.85MB/s]\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.04G/4.98G [04:16<06:43, 7.28MB/s]\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.04G/4.98G [04:16<06:12, 7.89MB/s]\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.04G/4.98G [04:16<05:54, 8.28MB/s]\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.05G/4.98G [04:17<05:40, 8.60MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.05G/4.98G [04:17<05:55, 8.23MB/s]\n",
      "model-00001-of-00004.safetensors:  41%|████▏     | 2.05G/4.98G [04:18<06:26, 7.57MB/s]\n",
      "model-00001-of-00004.safetensors:  41%|████▏     | 2.06G/4.98G [04:18<05:56, 8.18MB/s]\n",
      "model-00001-of-00004.safetensors:  41%|████▏     | 2.06G/4.98G [04:18<05:18, 9.17MB/s]\n",
      "model-00001-of-00004.safetensors:  41%|████▏     | 2.06G/4.98G [04:19<05:19, 9.11MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  41%|████▏     | 2.06G/4.98G [04:19<07:41, 6.31MB/s]\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.07G/4.98G [04:20<06:23, 7.59MB/s]\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.07G/4.98G [04:20<06:50, 7.08MB/s]\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.07G/4.98G [04:20<06:10, 7.85MB/s]\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.08G/4.98G [04:20<05:44, 8.42MB/s]\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.08G/4.98G [04:21<05:28, 8.82MB/s]\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.08G/4.98G [04:21<08:18, 5.81MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.08G/4.98G [04:22<07:58, 6.04MB/s]\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.09G/4.98G [04:22<07:03, 6.82MB/s]\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.09G/4.98G [04:23<06:22, 7.54MB/s]\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.09G/4.98G [04:23<05:54, 8.13MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.10G/4.98G [04:24<07:59, 6.00MB/s]\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.10G/4.98G [04:24<06:27, 7.42MB/s]\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.10G/4.98G [04:24<06:53, 6.95MB/s]\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.10G/4.98G [04:25<06:17, 7.61MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.11G/4.98G [04:25<05:28, 8.73MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.11G/4.98G [04:26<07:46, 6.14MB/s]\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.12G/4.98G [04:26<06:10, 7.72MB/s]\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.12G/4.98G [04:26<06:42, 7.10MB/s]\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.12G/4.98G [04:27<06:07, 7.78MB/s]\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.12G/4.98G [04:27<05:46, 8.24MB/s]\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.13G/4.98G [04:27<05:28, 8.68MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.13G/4.98G [04:28<07:30, 6.32MB/s]\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.13G/4.98G [04:28<05:59, 7.92MB/s]\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.13G/4.98G [04:28<05:44, 8.26MB/s]\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.14G/4.98G [04:29<05:29, 8.63MB/s]\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.14G/4.98G [04:29<05:16, 8.95MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.14G/4.98G [04:30<07:22, 6.40MB/s]\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.15G/4.98G [04:30<06:02, 7.81MB/s]\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.15G/4.98G [04:31<05:46, 8.15MB/s]\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.15G/4.98G [04:31<05:34, 8.44MB/s]\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.16G/4.98G [04:31<05:13, 8.99MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.16G/4.98G [04:32<07:13, 6.50MB/s]\n",
      "model-00001-of-00004.safetensors:  44%|████▎     | 2.17G/4.98G [04:33<05:38, 8.30MB/s]\n",
      "model-00001-of-00004.safetensors:  44%|████▎     | 2.17G/4.98G [04:33<05:18, 8.80MB/s]\n",
      "model-00001-of-00004.safetensors:  44%|████▎     | 2.17G/4.98G [04:33<05:08, 9.09MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  44%|████▎     | 2.18G/4.98G [04:34<06:14, 7.49MB/s]\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.18G/4.98G [04:34<05:18, 8.78MB/s]\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.18G/4.98G [04:34<05:05, 9.14MB/s]\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.19G/4.98G [04:35<04:53, 9.52MB/s]\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.19G/4.98G [04:35<04:54, 9.46MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.20G/4.98G [04:36<05:09, 8.97MB/s]\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.20G/4.98G [04:36<05:05, 9.10MB/s]\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.20G/4.98G [04:36<04:58, 9.30MB/s]\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.21G/4.98G [04:37<04:58, 9.27MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.21G/4.98G [04:38<04:55, 9.35MB/s]\n",
      "model-00001-of-00004.safetensors:  45%|████▍     | 2.22G/4.98G [04:38<04:47, 9.62MB/s]\n",
      "model-00001-of-00004.safetensors:  45%|████▍     | 2.22G/4.98G [04:38<04:45, 9.68MB/s]\n",
      "model-00001-of-00004.safetensors:  45%|████▍     | 2.22G/4.98G [04:38<04:45, 9.66MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  45%|████▍     | 2.22G/4.98G [04:39<06:03, 7.57MB/s]\n",
      "model-00001-of-00004.safetensors:  45%|████▍     | 2.23G/4.98G [04:39<05:10, 8.86MB/s]\n",
      "model-00001-of-00004.safetensors:  45%|████▍     | 2.23G/4.98G [04:40<05:03, 9.06MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  45%|████▍     | 2.23G/4.98G [04:40<06:21, 7.19MB/s]\n",
      "model-00001-of-00004.safetensors:  45%|████▌     | 2.24G/4.98G [04:41<05:54, 7.73MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  45%|████▌     | 2.24G/4.98G [04:41<07:42, 5.91MB/s]\n",
      "model-00001-of-00004.safetensors:  45%|████▌     | 2.24G/4.98G [04:42<06:25, 7.10MB/s]\n",
      "model-00001-of-00004.safetensors:  45%|████▌     | 2.25G/4.98G [04:42<06:48, 6.69MB/s]\n",
      "model-00001-of-00004.safetensors:  45%|████▌     | 2.25G/4.98G [04:42<05:41, 7.98MB/s]\n",
      "model-00001-of-00004.safetensors:  45%|████▌     | 2.25G/4.98G [04:43<05:23, 8.43MB/s]\n",
      "model-00001-of-00004.safetensors:  45%|████▌     | 2.26G/4.98G [04:43<05:05, 8.90MB/s]\n",
      "model-00001-of-00004.safetensors:  45%|████▌     | 2.26G/4.98G [04:43<07:12, 6.28MB/s]\n",
      "model-00001-of-00004.safetensors:  45%|████▌     | 2.26G/4.98G [04:44<06:03, 7.47MB/s]\n",
      "model-00001-of-00004.safetensors:  45%|████▌     | 2.26G/4.98G [04:44<05:25, 8.33MB/s]\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.27G/4.98G [04:44<05:04, 8.90MB/s]\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.27G/4.98G [04:45<04:52, 9.27MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.27G/4.98G [04:45<06:24, 7.04MB/s]\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.28G/4.98G [04:46<04:55, 9.14MB/s]\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.28G/4.98G [04:46<04:34, 9.82MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.29G/4.98G [04:46<04:35, 9.77MB/s]\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.29G/4.98G [04:47<05:55, 7.57MB/s]\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.29G/4.98G [04:47<05:01, 8.91MB/s]\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.30G/4.98G [04:48<04:45, 9.39MB/s]\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.30G/4.98G [04:48<04:34, 9.77MB/s]\n",
      "model-00001-of-00004.safetensors:  46%|████▋     | 2.30G/4.98G [04:48<04:35, 9.72MB/s]\n",
      "model-00001-of-00004.safetensors:  46%|████▋     | 2.30G/4.98G [04:49<06:10, 7.22MB/s]\n",
      "model-00001-of-00004.safetensors:  46%|████▋     | 2.31G/4.98G [04:49<05:09, 8.61MB/s]\n",
      "model-00001-of-00004.safetensors:  46%|████▋     | 2.31G/4.98G [04:49<05:02, 8.80MB/s]\n",
      "model-00001-of-00004.safetensors:  46%|████▋     | 2.31G/4.98G [04:50<04:56, 8.99MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.32G/4.98G [04:50<04:53, 9.07MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.32G/4.98G [04:50<04:50, 9.14MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.32G/4.98G [04:51<06:53, 6.42MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.32G/4.98G [04:51<05:59, 7.38MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.33G/4.98G [04:51<05:24, 8.16MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.33G/4.98G [04:52<05:08, 8.58MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.33G/4.98G [04:52<04:43, 9.31MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.34G/4.98G [04:53<05:58, 7.37MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.34G/4.98G [04:53<05:02, 8.70MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.34G/4.98G [04:53<04:47, 9.17MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.35G/4.98G [04:54<04:44, 9.25MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.35G/4.98G [04:54<04:31, 9.69MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.35G/4.98G [04:54<05:57, 7.33MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.36G/4.98G [04:55<05:01, 8.69MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.36G/4.98G [04:55<04:47, 9.09MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.36G/4.98G [04:55<04:41, 9.29MB/s]\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.37G/4.98G [04:56<04:39, 9.33MB/s]\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.37G/4.98G [04:56<05:49, 7.46MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.37G/4.98G [04:57<04:56, 8.78MB/s]\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.38G/4.98G [04:57<04:49, 9.00MB/s]\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.38G/4.98G [04:58<04:40, 9.24MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.38G/4.98G [04:58<05:33, 7.78MB/s]\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.39G/4.98G [04:58<04:46, 9.03MB/s]\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.39G/4.98G [04:59<04:34, 9.43MB/s]\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.39G/4.98G [04:59<04:28, 9.62MB/s]\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.40G/4.98G [04:59<04:27, 9.63MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.40G/4.98G [05:00<05:36, 7.66MB/s]\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.40G/4.98G [05:00<04:50, 8.85MB/s]\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.41G/4.98G [05:01<04:40, 9.15MB/s]\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.41G/4.98G [05:01<04:37, 9.23MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  49%|████▊     | 2.42G/4.98G [05:02<05:20, 8.00MB/s]\n",
      "model-00001-of-00004.safetensors:  49%|████▊     | 2.42G/4.98G [05:02<04:37, 9.20MB/s]\n",
      "model-00001-of-00004.safetensors:  49%|████▊     | 2.42G/4.98G [05:02<04:30, 9.43MB/s]\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.43G/4.98G [05:03<04:30, 9.44MB/s]\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.43G/4.98G [05:03<04:29, 9.44MB/s]\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.43G/4.98G [05:03<05:21, 7.91MB/s]\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.44G/4.98G [05:04<04:37, 9.15MB/s]\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.44G/4.98G [05:04<04:25, 9.56MB/s]\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.44G/4.98G [05:04<04:25, 9.54MB/s]\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.45G/4.98G [05:05<04:27, 9.47MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.45G/4.98G [05:05<05:13, 8.07MB/s]\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.46G/4.98G [05:06<04:16, 9.81MB/s]\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.46G/4.98G [05:06<04:20, 9.67MB/s]\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.46G/4.98G [05:06<04:18, 9.71MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  50%|████▉     | 2.46G/4.98G [05:07<05:44, 7.29MB/s]\n",
      "model-00001-of-00004.safetensors:  50%|████▉     | 2.47G/4.98G [05:07<04:50, 8.64MB/s]\n",
      "model-00001-of-00004.safetensors:  50%|████▉     | 2.47G/4.98G [05:08<04:30, 9.27MB/s]\n",
      "model-00001-of-00004.safetensors:  50%|████▉     | 2.47G/4.98G [05:08<04:22, 9.53MB/s]\n",
      "model-00001-of-00004.safetensors:  50%|████▉     | 2.48G/4.98G [05:08<04:17, 9.69MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  50%|████▉     | 2.48G/4.98G [05:09<04:50, 8.57MB/s]\n",
      "model-00001-of-00004.safetensors:  50%|████▉     | 2.49G/4.98G [05:09<04:31, 9.16MB/s]\n",
      "model-00001-of-00004.safetensors:  50%|█████     | 2.49G/4.98G [05:10<04:26, 9.34MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  50%|█████     | 2.49G/4.98G [05:10<04:18, 9.61MB/s]\n",
      "model-00001-of-00004.safetensors:  50%|█████     | 2.50G/4.98G [05:11<05:25, 7.61MB/s]\n",
      "model-00001-of-00004.safetensors:  50%|█████     | 2.50G/4.98G [05:11<05:43, 7.21MB/s]\n",
      "model-00001-of-00004.safetensors:  50%|█████     | 2.50G/4.98G [05:12<05:13, 7.89MB/s]\n",
      "model-00001-of-00004.safetensors:  50%|█████     | 2.51G/4.98G [05:12<04:50, 8.51MB/s]\n",
      "model-00001-of-00004.safetensors:  50%|█████     | 2.51G/4.98G [05:12<04:39, 8.83MB/s]\n",
      "model-00001-of-00004.safetensors:  50%|█████     | 2.51G/4.98G [05:13<06:41, 6.14MB/s]\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.52G/4.98G [05:13<05:19, 7.70MB/s]\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.52G/4.98G [05:14<05:40, 7.21MB/s]\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.52G/4.98G [05:14<05:12, 7.85MB/s]\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.52G/4.98G [05:14<04:55, 8.31MB/s]\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.53G/4.98G [05:14<04:43, 8.65MB/s]\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.53G/4.98G [05:15<06:22, 6.40MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.53G/4.98G [05:15<05:08, 7.93MB/s]\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.54G/4.98G [05:16<04:50, 8.42MB/s]\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.54G/4.98G [05:16<04:33, 8.92MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.54G/4.98G [05:17<05:17, 7.65MB/s]\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.55G/4.98G [05:17<04:31, 8.94MB/s]\n",
      "model-00001-of-00004.safetensors:  51%|█████▏    | 2.55G/4.98G [05:17<04:22, 9.26MB/s]\n",
      "model-00001-of-00004.safetensors:  51%|█████▏    | 2.56G/4.98G [05:18<04:17, 9.41MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  51%|█████▏    | 2.56G/4.98G [05:19<05:20, 7.55MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.56G/4.98G [05:19<04:32, 8.85MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.57G/4.98G [05:19<04:20, 9.24MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.57G/4.98G [05:20<04:16, 9.40MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.57G/4.98G [05:20<04:10, 9.60MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.58G/4.98G [05:20<05:17, 7.56MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.58G/4.98G [05:21<04:30, 8.87MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.58G/4.98G [05:21<04:18, 9.26MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.59G/4.98G [05:21<04:15, 9.37MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.59G/4.98G [05:22<04:12, 9.44MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.59G/4.98G [05:22<05:11, 7.66MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.60G/4.98G [05:22<04:25, 8.95MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.60G/4.98G [05:23<04:13, 9.37MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.60G/4.98G [05:23<04:08, 9.55MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.61G/4.98G [05:23<04:06, 9.62MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.61G/4.98G [05:24<05:11, 7.61MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.62G/4.98G [05:25<04:13, 9.32MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.62G/4.98G [05:25<04:07, 9.52MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.62G/4.98G [05:25<04:06, 9.54MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.62G/4.98G [05:26<04:59, 7.87MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.63G/4.98G [05:26<04:17, 9.13MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.63G/4.98G [05:26<04:06, 9.51MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.63G/4.98G [05:27<04:04, 9.59MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.64G/4.98G [05:27<04:01, 9.68MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.64G/4.98G [05:27<04:51, 8.01MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.64G/4.98G [05:28<04:13, 9.21MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.65G/4.98G [05:28<04:04, 9.52MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.65G/4.98G [05:29<04:03, 9.55MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.66G/4.98G [05:29<04:48, 8.05MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.66G/4.98G [05:29<04:09, 9.28MB/s]\n",
      "model-00001-of-00004.safetensors:  54%|█████▎    | 2.66G/4.98G [05:30<03:59, 9.64MB/s]\n",
      "model-00001-of-00004.safetensors:  54%|█████▎    | 2.67G/4.98G [05:30<03:58, 9.69MB/s]\n",
      "model-00001-of-00004.safetensors:  54%|█████▎    | 2.67G/4.98G [05:30<04:00, 9.58MB/s]\n",
      "model-00001-of-00004.safetensors:  54%|█████▎    | 2.67G/4.98G [05:31<04:59, 7.70MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.68G/4.98G [05:32<04:11, 9.14MB/s]\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.68G/4.98G [05:32<04:06, 9.31MB/s]\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.69G/4.98G [05:32<04:01, 9.48MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.69G/4.98G [05:33<04:57, 7.69MB/s]\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.69G/4.98G [05:33<04:16, 8.92MB/s]\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.70G/4.98G [05:33<04:02, 9.42MB/s]\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.70G/4.98G [05:34<03:52, 9.79MB/s]\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.70G/4.98G [05:34<03:55, 9.67MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.70G/4.98G [05:35<05:50, 6.48MB/s]\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.70G/4.98G [05:35<07:34, 5.00MB/s]\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.71G/4.98G [05:35<05:48, 6.52MB/s]\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.71G/4.98G [05:36<05:53, 6.41MB/s]\n",
      "model-00001-of-00004.safetensors:  55%|█████▍    | 2.71G/4.98G [05:36<05:06, 7.38MB/s]\n",
      "model-00001-of-00004.safetensors:  55%|█████▍    | 2.71G/4.98G [05:36<05:25, 6.94MB/s]\n",
      "model-00001-of-00004.safetensors:  55%|█████▍    | 2.72G/4.98G [05:37<04:53, 7.71MB/s]\n",
      "model-00001-of-00004.safetensors:  55%|█████▍    | 2.72G/4.98G [05:37<06:04, 6.20MB/s]\n",
      "model-00001-of-00004.safetensors:  55%|█████▍    | 2.72G/4.98G [05:38<04:48, 7.80MB/s]\n",
      "model-00001-of-00004.safetensors:  55%|█████▍    | 2.73G/4.98G [05:38<05:09, 7.28MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  55%|█████▍    | 2.73G/4.98G [05:38<04:45, 7.89MB/s]\n",
      "model-00001-of-00004.safetensors:  55%|█████▍    | 2.74G/4.98G [05:39<04:14, 8.82MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  55%|█████▍    | 2.74G/4.98G [05:39<05:43, 6.53MB/s]\n",
      "model-00001-of-00004.safetensors:  55%|█████▌    | 2.74G/4.98G [05:40<04:33, 8.18MB/s]\n",
      "model-00001-of-00004.safetensors:  55%|█████▌    | 2.74G/4.98G [05:40<04:18, 8.63MB/s]\n",
      "model-00001-of-00004.safetensors:  55%|█████▌    | 2.75G/4.98G [05:40<04:06, 9.06MB/s]\n",
      "model-00001-of-00004.safetensors:  55%|█████▌    | 2.75G/4.98G [05:40<04:01, 9.22MB/s]\n",
      "model-00001-of-00004.safetensors:  55%|█████▌    | 2.75G/4.98G [05:41<04:54, 7.54MB/s]\n",
      "model-00001-of-00004.safetensors:  55%|█████▌    | 2.76G/4.98G [05:41<04:10, 8.88MB/s]\n",
      "model-00001-of-00004.safetensors:  55%|█████▌    | 2.76G/4.98G [05:42<03:59, 9.25MB/s]\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.76G/4.98G [05:42<03:51, 9.58MB/s]\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.77G/4.98G [05:42<03:50, 9.58MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.77G/4.98G [05:43<04:48, 7.66MB/s]\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.77G/4.98G [05:43<04:09, 8.82MB/s]\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.78G/4.98G [05:44<04:53, 7.50MB/s]\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.78G/4.98G [05:44<04:15, 8.59MB/s]\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.78G/4.98G [05:44<04:34, 8.00MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.78G/4.98G [05:45<05:59, 6.10MB/s]\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.79G/4.98G [05:45<04:51, 7.51MB/s]\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.79G/4.98G [05:46<05:09, 7.06MB/s]\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.79G/4.98G [05:46<04:42, 7.73MB/s]\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.80G/4.98G [05:46<04:26, 8.17MB/s]\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.80G/4.98G [05:47<04:15, 8.51MB/s]\n",
      "model-00001-of-00004.safetensors:  56%|█████▋    | 2.80G/4.98G [05:47<06:00, 6.04MB/s]\n",
      "model-00001-of-00004.safetensors:  56%|█████▋    | 2.80G/4.98G [05:48<04:43, 7.67MB/s]\n",
      "model-00001-of-00004.safetensors:  56%|█████▋    | 2.81G/4.98G [05:48<05:07, 7.07MB/s]\n",
      "model-00001-of-00004.safetensors:  56%|█████▋    | 2.81G/4.98G [05:48<04:42, 7.66MB/s]\n",
      "model-00001-of-00004.safetensors:  56%|█████▋    | 2.81G/4.98G [05:48<04:21, 8.27MB/s]\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.81G/4.98G [05:49<04:11, 8.59MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.82G/4.98G [05:49<05:40, 6.34MB/s]\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.82G/4.98G [05:50<04:36, 7.81MB/s]\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.82G/4.98G [05:50<04:34, 7.85MB/s]\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.83G/4.98G [05:51<04:17, 8.34MB/s]\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.83G/4.98G [05:51<04:08, 8.64MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.83G/4.98G [05:51<05:16, 6.78MB/s]\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.84G/4.98G [05:52<04:43, 7.54MB/s]\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.84G/4.98G [05:52<04:23, 8.11MB/s]\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.84G/4.98G [05:53<04:08, 8.58MB/s]\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.85G/4.98G [05:53<04:01, 8.82MB/s]\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.85G/4.98G [05:53<05:26, 6.51MB/s]\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.85G/4.98G [05:54<04:20, 8.15MB/s]\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.85G/4.98G [05:54<04:46, 7.42MB/s]\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.86G/4.98G [05:54<04:24, 8.01MB/s]\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.86G/4.98G [05:55<04:11, 8.41MB/s]\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.86G/4.98G [05:55<04:02, 8.72MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.86G/4.98G [05:55<05:26, 6.47MB/s]\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.87G/4.98G [05:56<04:45, 7.39MB/s]\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.87G/4.98G [05:56<04:24, 7.97MB/s]\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.88G/4.98G [05:57<04:08, 8.45MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.88G/4.98G [05:57<03:57, 8.85MB/s]\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.88G/4.98G [05:57<05:29, 6.36MB/s]\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.88G/4.98G [05:58<04:22, 7.97MB/s]\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.89G/4.98G [05:58<04:44, 7.35MB/s]\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.89G/4.98G [05:58<04:14, 8.21MB/s]\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.89G/4.98G [05:59<03:58, 8.73MB/s]\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.90G/4.98G [05:59<03:54, 8.89MB/s]\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.90G/4.98G [05:59<05:36, 6.19MB/s]\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.90G/4.98G [06:00<04:24, 7.85MB/s]\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.90G/4.98G [06:00<04:45, 7.26MB/s]\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.90G/4.98G [06:00<04:18, 8.00MB/s]\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.91G/4.98G [06:01<04:00, 8.59MB/s]\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.91G/4.98G [06:01<03:49, 9.01MB/s]\n",
      "model-00001-of-00004.safetensors:  59%|█████▊    | 2.91G/4.98G [06:02<05:29, 6.27MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  59%|█████▊    | 2.92G/4.98G [06:02<04:25, 7.77MB/s]\n",
      "model-00001-of-00004.safetensors:  59%|█████▊    | 2.92G/4.98G [06:02<04:29, 7.64MB/s]\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.92G/4.98G [06:03<03:55, 8.70MB/s]\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.93G/4.98G [06:03<03:47, 9.02MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.93G/4.98G [06:04<05:17, 6.44MB/s]\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.93G/4.98G [06:04<04:27, 7.64MB/s]\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.94G/4.98G [06:04<04:11, 8.13MB/s]\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.94G/4.98G [06:05<03:55, 8.66MB/s]\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.94G/4.98G [06:05<03:49, 8.87MB/s]\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.94G/4.98G [06:05<04:31, 7.50MB/s]\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.95G/4.98G [06:06<03:49, 8.82MB/s]\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.95G/4.98G [06:06<03:43, 9.08MB/s]\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.95G/4.98G [06:06<03:40, 9.19MB/s]\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.96G/4.98G [06:07<03:37, 9.29MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.96G/4.98G [06:07<04:25, 7.61MB/s]\n",
      "model-00001-of-00004.safetensors:  60%|█████▉    | 2.97G/4.98G [06:08<03:38, 9.21MB/s]\n",
      "model-00001-of-00004.safetensors:  60%|█████▉    | 2.97G/4.98G [06:08<03:28, 9.64MB/s]\n",
      "model-00001-of-00004.safetensors:  60%|█████▉    | 2.97G/4.98G [06:08<03:28, 9.59MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  60%|█████▉    | 2.98G/4.98G [06:09<04:27, 7.48MB/s]\n",
      "model-00001-of-00004.safetensors:  60%|█████▉    | 2.98G/4.98G [06:09<03:46, 8.80MB/s]\n",
      "model-00001-of-00004.safetensors:  60%|█████▉    | 2.98G/4.98G [06:10<03:35, 9.26MB/s]\n",
      "model-00001-of-00004.safetensors:  60%|██████    | 2.99G/4.98G [06:10<03:33, 9.32MB/s]\n",
      "model-00001-of-00004.safetensors:  60%|██████    | 2.99G/4.98G [06:10<03:29, 9.46MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  60%|██████    | 3.00G/4.98G [06:11<03:45, 8.78MB/s]\n",
      "model-00001-of-00004.safetensors:  60%|██████    | 3.00G/4.98G [06:11<03:40, 8.97MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  60%|██████    | 3.00G/4.98G [06:12<03:35, 9.16MB/s]\n",
      "model-00001-of-00004.safetensors:  60%|██████    | 3.01G/4.98G [06:12<03:33, 9.23MB/s]\n",
      "model-00001-of-00004.safetensors:  60%|██████    | 3.01G/4.98G [06:13<04:16, 7.66MB/s]\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.01G/4.98G [06:13<03:40, 8.93MB/s]\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.02G/4.98G [06:13<03:30, 9.32MB/s]\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.02G/4.98G [06:14<03:25, 9.54MB/s]\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.02G/4.98G [06:14<03:24, 9.55MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.02G/4.98G [06:14<04:15, 7.63MB/s]\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.03G/4.98G [06:15<03:39, 8.86MB/s]\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.03G/4.98G [06:15<03:31, 9.18MB/s]\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.03G/4.98G [06:15<03:30, 9.21MB/s]\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.04G/4.98G [06:16<03:28, 9.29MB/s]\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.04G/4.98G [06:16<04:00, 8.05MB/s]\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.04G/4.98G [06:16<03:30, 9.19MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.05G/4.98G [06:17<04:21, 7.37MB/s]\n",
      "model-00001-of-00004.safetensors:  61%|██████▏   | 3.05G/4.98G [06:18<04:07, 7.77MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  61%|██████▏   | 3.06G/4.98G [06:19<05:18, 6.03MB/s]\n",
      "model-00001-of-00004.safetensors:  61%|██████▏   | 3.06G/4.98G [06:19<04:18, 7.42MB/s]\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.06G/4.98G [06:19<04:03, 7.85MB/s]\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.07G/4.98G [06:19<03:48, 8.38MB/s]\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.07G/4.98G [06:20<03:37, 8.79MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.07G/4.98G [06:20<04:20, 7.32MB/s]\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.08G/4.98G [06:21<03:40, 8.60MB/s]\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.08G/4.98G [06:21<03:29, 9.05MB/s]\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.08G/4.98G [06:21<03:26, 9.19MB/s]\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.09G/4.98G [06:22<03:23, 9.30MB/s]\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.09G/4.98G [06:22<04:09, 7.56MB/s]\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.09G/4.98G [06:22<03:33, 8.82MB/s]\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.10G/4.98G [06:23<03:20, 9.39MB/s]\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.10G/4.98G [06:23<03:16, 9.54MB/s]\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.10G/4.98G [06:23<03:13, 9.70MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.11G/4.98G [06:24<03:25, 9.09MB/s]\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.11G/4.98G [06:25<03:13, 9.62MB/s]\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.11G/4.98G [06:25<03:09, 9.82MB/s]\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.12G/4.98G [06:25<03:07, 9.89MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.12G/4.98G [06:26<03:25, 9.02MB/s]\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.13G/4.98G [06:26<03:12, 9.61MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.13G/4.98G [06:27<03:04, 10.0MB/s]\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.13G/4.98G [06:27<03:03, 10.0MB/s]\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.14G/4.98G [06:27<04:05, 7.49MB/s]\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.14G/4.98G [06:28<03:27, 8.86MB/s]\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.14G/4.98G [06:28<03:22, 9.07MB/s]\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.15G/4.98G [06:28<03:19, 9.16MB/s]\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.15G/4.98G [06:29<03:16, 9.29MB/s]\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.15G/4.98G [06:29<03:51, 7.88MB/s]\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.16G/4.98G [06:29<03:19, 9.13MB/s]\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.16G/4.98G [06:30<03:09, 9.60MB/s]\n",
      "model-00001-of-00004.safetensors:  64%|██████▎   | 3.16G/4.98G [06:30<03:11, 9.48MB/s]\n",
      "model-00001-of-00004.safetensors:  64%|██████▎   | 3.17G/4.98G [06:30<03:12, 9.42MB/s]\n",
      "model-00001-of-00004.safetensors:  64%|██████▎   | 3.17G/4.98G [06:31<03:56, 7.65MB/s]\n",
      "model-00001-of-00004.safetensors:  64%|██████▎   | 3.17G/4.98G [06:31<03:22, 8.92MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.18G/4.98G [06:32<03:09, 9.49MB/s]\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.18G/4.98G [06:32<03:07, 9.58MB/s]\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.18G/4.98G [06:32<03:10, 9.41MB/s]\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.18G/4.98G [06:33<04:04, 7.33MB/s]\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.19G/4.98G [06:33<03:26, 8.67MB/s]\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.19G/4.98G [06:33<03:14, 9.16MB/s]\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.19G/4.98G [06:34<03:12, 9.24MB/s]\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.20G/4.98G [06:34<03:08, 9.46MB/s]\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.20G/4.98G [06:35<03:50, 7.71MB/s]\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.20G/4.98G [06:35<03:17, 8.99MB/s]\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.21G/4.98G [06:35<03:05, 9.55MB/s]\n",
      "model-00001-of-00004.safetensors:  65%|██████▍   | 3.21G/4.98G [06:36<03:06, 9.48MB/s]\n",
      "model-00001-of-00004.safetensors:  65%|██████▍   | 3.21G/4.98G [06:36<03:00, 9.78MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  65%|██████▍   | 3.22G/4.98G [06:36<03:43, 7.88MB/s]\n",
      "model-00001-of-00004.safetensors:  65%|██████▍   | 3.22G/4.98G [06:37<03:13, 9.07MB/s]\n",
      "model-00001-of-00004.safetensors:  65%|██████▍   | 3.22G/4.98G [06:37<03:11, 9.18MB/s]\n",
      "model-00001-of-00004.safetensors:  65%|██████▍   | 3.23G/4.98G [06:38<03:08, 9.29MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  65%|██████▍   | 3.23G/4.98G [06:38<03:42, 7.86MB/s]\n",
      "model-00001-of-00004.safetensors:  65%|██████▌   | 3.24G/4.98G [06:38<03:11, 9.08MB/s]\n",
      "model-00001-of-00004.safetensors:  65%|██████▌   | 3.24G/4.98G [06:39<03:04, 9.43MB/s]\n",
      "model-00001-of-00004.safetensors:  65%|██████▌   | 3.24G/4.98G [06:39<03:01, 9.58MB/s]\n",
      "model-00001-of-00004.safetensors:  65%|██████▌   | 3.25G/4.98G [06:39<03:01, 9.55MB/s]\n",
      "model-00001-of-00004.safetensors:  65%|██████▌   | 3.25G/4.98G [06:40<03:46, 7.65MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  65%|██████▌   | 3.25G/4.98G [06:40<03:13, 8.91MB/s]\n",
      "model-00001-of-00004.safetensors:  65%|██████▌   | 3.26G/4.98G [06:41<02:58, 9.60MB/s]\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.26G/4.98G [06:41<02:58, 9.61MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.26G/4.98G [06:42<03:41, 7.72MB/s]\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.27G/4.98G [06:42<03:09, 9.02MB/s]\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.27G/4.98G [06:43<02:56, 9.66MB/s]\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.28G/4.98G [06:43<02:56, 9.65MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.28G/4.98G [06:43<03:44, 7.56MB/s]\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.28G/4.98G [06:44<03:10, 8.88MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.29G/4.98G [06:44<03:55, 7.18MB/s]\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.29G/4.98G [06:45<03:20, 8.40MB/s]\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.29G/4.98G [06:45<03:39, 7.66MB/s]\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.30G/4.98G [06:45<03:25, 8.17MB/s]\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.30G/4.98G [06:46<04:45, 5.89MB/s]\n",
      "model-00001-of-00004.safetensors:  66%|██████▋   | 3.30G/4.98G [06:46<03:57, 7.06MB/s]\n",
      "model-00001-of-00004.safetensors:  66%|██████▋   | 3.30G/4.98G [06:46<03:41, 7.56MB/s]\n",
      "model-00001-of-00004.safetensors:  66%|██████▋   | 3.31G/4.98G [06:47<03:25, 8.13MB/s]\n",
      "model-00001-of-00004.safetensors:  66%|██████▋   | 3.31G/4.98G [06:47<03:14, 8.57MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.31G/4.98G [06:48<04:15, 6.52MB/s]\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.32G/4.98G [06:48<03:29, 7.91MB/s]\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.32G/4.98G [06:48<03:18, 8.33MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.33G/4.98G [06:49<03:00, 9.13MB/s]\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.33G/4.98G [06:50<03:31, 7.78MB/s]\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.33G/4.98G [06:50<03:02, 9.01MB/s]\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.34G/4.98G [06:50<02:57, 9.25MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.34G/4.98G [06:51<02:46, 9.79MB/s]\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.34G/4.98G [06:51<03:25, 7.93MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.35G/4.98G [06:52<02:58, 9.14MB/s]\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.35G/4.98G [06:52<02:53, 9.35MB/s]\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.36G/4.98G [06:53<02:50, 9.52MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.36G/4.98G [06:53<03:26, 7.83MB/s]\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.36G/4.98G [06:53<02:57, 9.09MB/s]\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.37G/4.98G [06:54<02:52, 9.35MB/s]\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.37G/4.98G [06:54<02:50, 9.42MB/s]\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.37G/4.98G [06:54<02:47, 9.58MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.38G/4.98G [06:57<08:20, 3.20MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.38G/4.98G [06:58<08:12, 3.24MB/s]\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.38G/4.98G [06:58<07:39, 3.47MB/s]\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.38G/4.98G [06:59<06:00, 4.41MB/s]\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.39G/4.98G [06:59<04:54, 5.39MB/s]\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.39G/4.98G [06:59<04:14, 6.22MB/s]\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.39G/4.98G [07:00<05:31, 4.78MB/s]\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.40G/4.98G [07:00<04:07, 6.38MB/s]\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.40G/4.98G [07:00<03:43, 7.04MB/s]\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.40G/4.98G [07:01<03:27, 7.60MB/s]\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.40G/4.98G [07:01<03:14, 8.09MB/s]\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.41G/4.98G [07:02<03:37, 7.20MB/s]\n",
      "model-00001-of-00004.safetensors:  69%|██████▊   | 3.41G/4.98G [07:02<03:03, 8.54MB/s]\n",
      "model-00001-of-00004.safetensors:  69%|██████▊   | 3.42G/4.98G [07:02<02:53, 9.02MB/s]\n",
      "model-00001-of-00004.safetensors:  69%|██████▊   | 3.42G/4.98G [07:02<02:46, 9.38MB/s]\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.42G/4.98G [07:03<02:44, 9.44MB/s]\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.42G/4.98G [07:03<03:25, 7.54MB/s]\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.43G/4.98G [07:04<02:57, 8.75MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.43G/4.98G [07:04<02:47, 9.20MB/s]\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.44G/4.98G [07:05<02:44, 9.36MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.44G/4.98G [07:05<03:36, 7.09MB/s]\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.44G/4.98G [07:06<03:01, 8.44MB/s]\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.45G/4.98G [07:06<03:22, 7.57MB/s]\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.45G/4.98G [07:06<03:09, 8.06MB/s]\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.45G/4.98G [07:06<02:56, 8.65MB/s]\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.45G/4.98G [07:07<02:50, 8.93MB/s]\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.46G/4.98G [07:07<04:04, 6.21MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  70%|██████▉   | 3.47G/4.98G [07:08<02:42, 9.29MB/s]\n",
      "model-00001-of-00004.safetensors:  70%|██████▉   | 3.47G/4.98G [07:09<02:37, 9.54MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  70%|██████▉   | 3.47G/4.98G [07:09<03:28, 7.21MB/s]\n",
      "model-00001-of-00004.safetensors:  70%|██████▉   | 3.48G/4.98G [07:09<02:53, 8.63MB/s]\n",
      "model-00001-of-00004.safetensors:  70%|██████▉   | 3.48G/4.98G [07:10<02:42, 9.22MB/s]\n",
      "model-00001-of-00004.safetensors:  70%|██████▉   | 3.48G/4.98G [07:10<02:39, 9.35MB/s]\n",
      "model-00001-of-00004.safetensors:  70%|███████   | 3.49G/4.98G [07:10<02:37, 9.48MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  70%|███████   | 3.49G/4.98G [07:11<03:21, 7.39MB/s]\n",
      "model-00001-of-00004.safetensors:  70%|███████   | 3.49G/4.98G [07:11<02:49, 8.74MB/s]\n",
      "model-00001-of-00004.safetensors:  70%|███████   | 3.50G/4.98G [07:12<02:38, 9.36MB/s]\n",
      "model-00001-of-00004.safetensors:  70%|███████   | 3.50G/4.98G [07:12<02:34, 9.55MB/s]\n",
      "model-00001-of-00004.safetensors:  70%|███████   | 3.50G/4.98G [07:12<02:33, 9.58MB/s]\n",
      "model-00001-of-00004.safetensors:  70%|███████   | 3.50G/4.98G [07:13<03:26, 7.13MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.51G/4.98G [07:13<02:43, 8.99MB/s]\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.51G/4.98G [07:14<02:39, 9.16MB/s]\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.52G/4.98G [07:14<02:34, 9.42MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.52G/4.98G [07:15<03:12, 7.58MB/s]\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.53G/4.98G [07:15<02:33, 9.45MB/s]\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.53G/4.98G [07:16<02:28, 9.74MB/s]\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.53G/4.98G [07:16<02:26, 9.86MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.54G/4.98G [07:16<03:15, 7.38MB/s]\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.54G/4.98G [07:17<02:45, 8.70MB/s]\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.54G/4.98G [07:17<02:34, 9.30MB/s]\n",
      "model-00001-of-00004.safetensors:  71%|███████▏  | 3.55G/4.98G [07:17<02:21, 10.1MB/s]\n",
      "model-00001-of-00004.safetensors:  71%|███████▏  | 3.55G/4.98G [07:18<02:24, 9.89MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  71%|███████▏  | 3.56G/4.98G [07:18<02:46, 8.54MB/s]\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.56G/4.98G [07:19<02:37, 9.02MB/s]\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.56G/4.98G [07:19<02:33, 9.21MB/s]\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.57G/4.98G [07:19<02:31, 9.29MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.57G/4.98G [07:20<03:10, 7.38MB/s]\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.57G/4.98G [07:20<02:41, 8.71MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.57G/4.98G [07:21<03:34, 6.54MB/s]\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.58G/4.98G [07:21<02:58, 7.84MB/s]\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.58G/4.98G [07:22<02:58, 7.80MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.58G/4.98G [07:22<03:51, 6.01MB/s]\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.59G/4.98G [07:23<03:00, 7.70MB/s]\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.59G/4.98G [07:23<02:48, 8.21MB/s]\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.60G/4.98G [07:24<02:34, 8.95MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.60G/4.98G [07:24<02:56, 7.79MB/s]\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.60G/4.98G [07:24<02:31, 9.08MB/s]\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.61G/4.98G [07:25<02:28, 9.24MB/s]\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.61G/4.98G [07:25<02:27, 9.25MB/s]\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.61G/4.98G [07:25<02:26, 9.31MB/s]\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.62G/4.98G [07:26<02:53, 7.82MB/s]\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.62G/4.98G [07:26<02:29, 9.06MB/s]\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.62G/4.98G [07:27<02:22, 9.49MB/s]\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.63G/4.98G [07:27<02:20, 9.63MB/s]\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.63G/4.98G [07:27<02:21, 9.54MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.63G/4.98G [07:28<02:58, 7.52MB/s]\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.64G/4.98G [07:28<02:32, 8.79MB/s]\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.64G/4.98G [07:29<02:27, 9.07MB/s]\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.65G/4.98G [07:29<02:21, 9.38MB/s]\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.65G/4.98G [07:29<02:52, 7.69MB/s]\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.65G/4.98G [07:30<02:27, 8.95MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.66G/4.98G [07:30<02:23, 9.22MB/s]\n",
      "model-00001-of-00004.safetensors:  74%|███████▎  | 3.66G/4.98G [07:31<02:20, 9.38MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  74%|███████▎  | 3.66G/4.98G [07:31<02:42, 8.10MB/s]\n",
      "model-00001-of-00004.safetensors:  74%|███████▎  | 3.67G/4.98G [07:32<02:20, 9.29MB/s]\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.67G/4.98G [07:32<02:19, 9.39MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.67G/4.98G [07:32<03:16, 6.63MB/s]\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.68G/4.98G [07:33<02:43, 7.97MB/s]\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.68G/4.98G [07:33<02:56, 7.33MB/s]\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.68G/4.98G [07:34<03:37, 5.95MB/s]\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.68G/4.98G [07:34<02:48, 7.65MB/s]\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.69G/4.98G [07:34<03:03, 7.05MB/s]\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.69G/4.98G [07:34<02:48, 7.67MB/s]\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.69G/4.98G [07:35<02:37, 8.17MB/s]\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.69G/4.98G [07:35<02:29, 8.58MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.70G/4.98G [07:36<02:38, 8.07MB/s]\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.70G/4.98G [07:36<02:29, 8.50MB/s]\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.71G/4.98G [07:37<02:23, 8.86MB/s]\n",
      "model-00001-of-00004.safetensors:  75%|███████▍  | 3.71G/4.98G [07:37<02:14, 9.41MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  75%|███████▍  | 3.71G/4.98G [07:37<02:46, 7.59MB/s]\n",
      "model-00001-of-00004.safetensors:  75%|███████▍  | 3.72G/4.98G [07:38<02:28, 8.50MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  75%|███████▍  | 3.72G/4.98G [07:38<02:23, 8.77MB/s]\n",
      "model-00001-of-00004.safetensors:  75%|███████▍  | 3.72G/4.98G [07:39<02:17, 9.09MB/s]\n",
      "model-00001-of-00004.safetensors:  75%|███████▍  | 3.73G/4.98G [07:40<02:43, 7.61MB/s]\n",
      "model-00001-of-00004.safetensors:  75%|███████▌  | 3.74G/4.98G [07:40<02:29, 8.28MB/s]\n",
      "model-00001-of-00004.safetensors:  75%|███████▌  | 3.74G/4.98G [07:40<02:18, 8.95MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  75%|███████▌  | 3.74G/4.98G [07:41<02:14, 9.15MB/s]\n",
      "model-00001-of-00004.safetensors:  75%|███████▌  | 3.74G/4.98G [07:41<02:51, 7.17MB/s]\n",
      "model-00001-of-00004.safetensors:  75%|███████▌  | 3.75G/4.98G [07:42<02:23, 8.54MB/s]\n",
      "model-00001-of-00004.safetensors:  75%|███████▌  | 3.75G/4.98G [07:42<02:15, 9.02MB/s]\n",
      "model-00001-of-00004.safetensors:  75%|███████▌  | 3.75G/4.98G [07:42<02:12, 9.24MB/s]\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.76G/4.98G [07:43<02:08, 9.46MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.76G/4.98G [07:43<03:32, 5.73MB/s]\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.76G/4.98G [07:44<02:51, 7.09MB/s]\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.77G/4.98G [07:44<03:02, 6.62MB/s]\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.77G/4.98G [07:44<02:42, 7.41MB/s]\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.77G/4.98G [07:45<02:22, 8.45MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.78G/4.98G [07:45<03:04, 6.52MB/s]\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.78G/4.98G [07:46<02:26, 8.15MB/s]\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.78G/4.98G [07:46<02:15, 8.78MB/s]\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.79G/4.98G [07:47<02:06, 9.36MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.79G/4.98G [07:47<02:42, 7.31MB/s]\n",
      "model-00001-of-00004.safetensors:  76%|███████▋  | 3.80G/4.98G [07:48<02:16, 8.64MB/s]\n",
      "model-00001-of-00004.safetensors:  76%|███████▋  | 3.80G/4.98G [07:48<02:09, 9.06MB/s]\n",
      "model-00001-of-00004.safetensors:  76%|███████▋  | 3.80G/4.98G [07:48<02:07, 9.23MB/s]\n",
      "model-00001-of-00004.safetensors:  76%|███████▋  | 3.81G/4.98G [07:49<02:05, 9.33MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.81G/4.98G [07:49<02:36, 7.47MB/s]\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.81G/4.98G [07:49<02:12, 8.79MB/s]\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.82G/4.98G [07:50<02:09, 8.94MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.82G/4.98G [07:50<02:08, 8.99MB/s]\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.82G/4.98G [07:51<02:26, 7.89MB/s]\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.83G/4.98G [07:51<02:06, 9.10MB/s]\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.83G/4.98G [07:52<02:01, 9.43MB/s]\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.83G/4.98G [07:52<01:58, 9.63MB/s]\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.84G/4.98G [07:52<01:58, 9.58MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.84G/4.98G [07:53<02:30, 7.55MB/s]\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.84G/4.98G [07:53<02:07, 8.85MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.85G/4.98G [07:54<03:01, 6.23MB/s]\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.85G/4.98G [07:54<02:28, 7.60MB/s]\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.85G/4.98G [07:54<02:38, 7.10MB/s]\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.85G/4.98G [07:55<02:24, 7.79MB/s]\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.86G/4.98G [07:55<02:58, 6.28MB/s]\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.86G/4.98G [07:55<02:22, 7.85MB/s]\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.86G/4.98G [07:56<02:31, 7.34MB/s]\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.86G/4.98G [07:56<02:20, 7.91MB/s]\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.87G/4.98G [07:56<02:13, 8.33MB/s]\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.87G/4.98G [07:57<02:08, 8.63MB/s]\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.87G/4.98G [07:57<02:54, 6.33MB/s]\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.88G/4.98G [07:57<02:17, 7.99MB/s]\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.88G/4.98G [07:58<02:26, 7.50MB/s]\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.88G/4.98G [07:58<02:16, 8.04MB/s]\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.88G/4.98G [07:58<02:09, 8.45MB/s]\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.89G/4.98G [07:59<02:05, 8.68MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.89G/4.98G [07:59<02:44, 6.61MB/s]\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.90G/4.98G [08:00<02:07, 8.47MB/s]\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.90G/4.98G [08:00<02:02, 8.79MB/s]\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.90G/4.98G [08:00<01:58, 9.10MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.90G/4.98G [08:01<02:22, 7.54MB/s]\n",
      "model-00001-of-00004.safetensors:  79%|███████▊  | 3.91G/4.98G [08:01<02:01, 8.82MB/s]\n",
      "model-00001-of-00004.safetensors:  79%|███████▊  | 3.91G/4.98G [08:02<01:56, 9.17MB/s]\n",
      "model-00001-of-00004.safetensors:  79%|███████▊  | 3.91G/4.98G [08:02<01:51, 9.54MB/s]\n",
      "model-00001-of-00004.safetensors:  79%|███████▊  | 3.92G/4.98G [08:02<01:48, 9.78MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  79%|███████▉  | 3.92G/4.98G [08:03<01:59, 8.83MB/s]\n",
      "model-00001-of-00004.safetensors:  79%|███████▉  | 3.93G/4.98G [08:03<01:53, 9.21MB/s]\n",
      "model-00001-of-00004.safetensors:  79%|███████▉  | 3.93G/4.98G [08:04<01:48, 9.60MB/s]\n",
      "model-00001-of-00004.safetensors:  79%|███████▉  | 3.93G/4.98G [08:04<01:47, 9.73MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  79%|███████▉  | 3.94G/4.98G [08:05<02:19, 7.46MB/s]\n",
      "model-00001-of-00004.safetensors:  79%|███████▉  | 3.96G/4.98G [08:07<02:30, 6.79MB/s]\n",
      "model-00001-of-00004.safetensors:  80%|███████▉  | 3.96G/4.98G [08:08<02:18, 7.34MB/s]\n",
      "model-00001-of-00004.safetensors:  80%|███████▉  | 3.97G/4.98G [08:09<02:44, 6.15MB/s]\n",
      "model-00001-of-00004.safetensors:  80%|███████▉  | 3.97G/4.98G [08:10<02:09, 7.78MB/s]\n",
      "model-00001-of-00004.safetensors:  80%|███████▉  | 3.97G/4.98G [08:10<02:17, 7.28MB/s]\n",
      "model-00001-of-00004.safetensors:  80%|███████▉  | 3.98G/4.98G [08:10<02:06, 7.87MB/s]\n",
      "model-00001-of-00004.safetensors:  80%|███████▉  | 3.98G/4.98G [08:10<01:59, 8.35MB/s]\n",
      "model-00001-of-00004.safetensors:  80%|████████  | 3.98G/4.98G [08:11<01:53, 8.72MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  80%|████████  | 3.98G/4.98G [08:11<02:38, 6.26MB/s]\n",
      "model-00001-of-00004.safetensors:  80%|████████  | 3.99G/4.98G [08:12<02:16, 7.21MB/s]\n",
      "model-00001-of-00004.safetensors:  80%|████████  | 3.99G/4.98G [08:12<02:06, 7.77MB/s]\n",
      "model-00001-of-00004.safetensors:  80%|████████  | 4.00G/4.98G [08:13<01:59, 8.24MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  80%|████████  | 4.00G/4.98G [08:13<01:53, 8.62MB/s]\n",
      "model-00001-of-00004.safetensors:  80%|████████  | 4.00G/4.98G [08:13<02:31, 6.46MB/s]\n",
      "model-00001-of-00004.safetensors:  80%|████████  | 4.00G/4.98G [08:14<02:00, 8.07MB/s]\n",
      "model-00001-of-00004.safetensors:  80%|████████  | 4.01G/4.98G [08:14<02:12, 7.35MB/s]\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 4.01G/4.98G [08:14<02:01, 7.94MB/s]\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 4.01G/4.98G [08:15<01:54, 8.43MB/s]\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 4.01G/4.98G [08:15<01:51, 8.66MB/s]\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 4.02G/4.98G [08:15<02:26, 6.58MB/s]\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 4.02G/4.98G [08:16<01:57, 8.17MB/s]\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 4.02G/4.98G [08:16<02:07, 7.52MB/s]\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 4.02G/4.98G [08:16<01:58, 8.06MB/s]\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 4.03G/4.98G [08:17<01:48, 8.75MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 4.03G/4.98G [08:17<02:28, 6.35MB/s]\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 4.04G/4.98G [08:18<01:58, 7.96MB/s]\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 4.04G/4.98G [08:18<02:08, 7.33MB/s]\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 4.04G/4.98G [08:18<01:59, 7.86MB/s]\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 4.04G/4.98G [08:19<01:53, 8.25MB/s]\n",
      "model-00001-of-00004.safetensors:  81%|████████▏ | 4.05G/4.98G [08:19<01:48, 8.59MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  81%|████████▏ | 4.05G/4.98G [08:20<02:23, 6.46MB/s]\n",
      "model-00001-of-00004.safetensors:  81%|████████▏ | 4.05G/4.98G [08:20<02:06, 7.29MB/s]\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.06G/4.98G [08:20<01:56, 7.89MB/s]\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.06G/4.98G [08:21<01:50, 8.31MB/s]\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.06G/4.98G [08:21<01:45, 8.63MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.07G/4.98G [08:22<01:53, 8.03MB/s]\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.07G/4.98G [08:22<02:03, 7.35MB/s]\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.07G/4.98G [08:23<01:54, 7.88MB/s]\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.08G/4.98G [08:23<01:48, 8.31MB/s]\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.08G/4.98G [08:23<01:43, 8.67MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.08G/4.98G [08:24<01:46, 8.35MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.09G/4.98G [08:24<01:43, 8.59MB/s]\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.09G/4.98G [08:25<01:41, 8.74MB/s]\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.09G/4.98G [08:25<01:39, 8.89MB/s]\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.10G/4.98G [08:25<01:36, 9.10MB/s]\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.10G/4.98G [08:26<02:19, 6.30MB/s]\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.10G/4.98G [08:26<02:01, 7.20MB/s]\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.10G/4.98G [08:26<02:07, 6.84MB/s]\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.10G/4.98G [08:27<01:54, 7.62MB/s]\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.11G/4.98G [08:27<01:33, 9.30MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.11G/4.98G [08:28<02:14, 6.45MB/s]\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.12G/4.98G [08:28<01:56, 7.40MB/s]\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.12G/4.98G [08:28<01:47, 8.01MB/s]\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.12G/4.98G [08:29<01:38, 8.65MB/s]\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.13G/4.98G [08:29<01:33, 9.11MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.13G/4.98G [08:30<02:54, 4.86MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.13G/4.98G [08:31<02:38, 5.33MB/s]\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.13G/4.98G [08:31<02:38, 5.34MB/s]\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.14G/4.98G [08:31<02:09, 6.49MB/s]\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.14G/4.98G [08:32<01:55, 7.26MB/s]\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.14G/4.98G [08:32<01:46, 7.85MB/s]\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.14G/4.98G [08:33<02:31, 5.50MB/s]\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.15G/4.98G [08:33<01:58, 6.99MB/s]\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.15G/4.98G [08:33<02:07, 6.50MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  84%|████████▎ | 4.16G/4.98G [08:34<01:42, 7.98MB/s]\n",
      "model-00001-of-00004.safetensors:  84%|████████▎ | 4.16G/4.98G [08:34<01:37, 8.41MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  84%|████████▎ | 4.16G/4.98G [08:35<02:14, 6.06MB/s]\n",
      "model-00001-of-00004.safetensors:  84%|████████▎ | 4.16G/4.98G [08:35<01:44, 7.75MB/s]\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.17G/4.98G [08:36<01:29, 8.98MB/s]\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.17G/4.98G [08:36<01:22, 9.72MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.18G/4.98G [08:37<01:53, 7.08MB/s]\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.18G/4.98G [08:37<01:33, 8.52MB/s]\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.18G/4.98G [08:37<01:28, 8.98MB/s]\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.19G/4.98G [08:38<01:25, 9.20MB/s]\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.19G/4.98G [08:38<01:23, 9.38MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.19G/4.98G [08:38<01:44, 7.47MB/s]\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.20G/4.98G [08:39<01:23, 9.31MB/s]\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.20G/4.98G [08:39<01:21, 9.45MB/s]\n",
      "model-00001-of-00004.safetensors:  85%|████████▍ | 4.21G/4.98G [08:40<01:19, 9.68MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  85%|████████▍ | 4.21G/4.98G [08:40<01:38, 7.82MB/s]\n",
      "model-00001-of-00004.safetensors:  85%|████████▍ | 4.22G/4.98G [08:41<01:20, 9.50MB/s]\n",
      "model-00001-of-00004.safetensors:  85%|████████▍ | 4.22G/4.98G [08:41<01:18, 9.60MB/s]\n",
      "model-00001-of-00004.safetensors:  85%|████████▍ | 4.22G/4.98G [08:41<01:18, 9.58MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  85%|████████▍ | 4.22G/4.98G [08:42<01:37, 7.70MB/s]\n",
      "model-00001-of-00004.safetensors:  85%|████████▍ | 4.23G/4.98G [08:42<01:23, 9.01MB/s]\n",
      "model-00001-of-00004.safetensors:  85%|████████▌ | 4.23G/4.98G [08:43<01:19, 9.34MB/s]\n",
      "model-00001-of-00004.safetensors:  85%|████████▌ | 4.23G/4.98G [08:43<01:17, 9.53MB/s]\n",
      "model-00001-of-00004.safetensors:  85%|████████▌ | 4.24G/4.98G [08:43<01:17, 9.50MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  85%|████████▌ | 4.24G/4.98G [08:44<01:22, 8.91MB/s]\n",
      "model-00001-of-00004.safetensors:  85%|████████▌ | 4.25G/4.98G [08:44<01:17, 9.42MB/s]\n",
      "model-00001-of-00004.safetensors:  85%|████████▌ | 4.25G/4.98G [08:45<01:15, 9.58MB/s]\n",
      "model-00001-of-00004.safetensors:  85%|████████▌ | 4.25G/4.98G [08:45<01:12, 9.92MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.26G/4.98G [08:45<01:33, 7.74MB/s]\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.26G/4.98G [08:46<01:19, 9.06MB/s]\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.26G/4.98G [08:46<01:14, 9.56MB/s]\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.27G/4.98G [08:46<01:14, 9.58MB/s]\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.27G/4.98G [08:47<01:13, 9.61MB/s]\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.27G/4.98G [08:47<01:28, 7.98MB/s]\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.28G/4.98G [08:47<01:15, 9.25MB/s]\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.28G/4.98G [08:48<01:10, 9.90MB/s]\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.28G/4.98G [08:48<01:11, 9.77MB/s]\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.29G/4.98G [08:48<01:11, 9.69MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.29G/4.98G [08:49<01:37, 7.04MB/s]\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.29G/4.98G [08:49<01:21, 8.42MB/s]\n",
      "model-00001-of-00004.safetensors:  86%|████████▋ | 4.29G/4.98G [08:50<01:30, 7.58MB/s]\n",
      "model-00001-of-00004.safetensors:  86%|████████▋ | 4.30G/4.98G [08:50<01:24, 8.05MB/s]\n",
      "model-00001-of-00004.safetensors:  86%|████████▋ | 4.30G/4.98G [08:50<01:20, 8.45MB/s]\n",
      "model-00001-of-00004.safetensors:  86%|████████▋ | 4.30G/4.98G [08:51<01:17, 8.73MB/s]\n",
      "model-00001-of-00004.safetensors:  86%|████████▋ | 4.30G/4.98G [08:51<01:40, 6.67MB/s]\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.31G/4.98G [08:51<01:20, 8.30MB/s]\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.31G/4.98G [08:52<01:11, 9.23MB/s]\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.32G/4.98G [08:52<01:09, 9.53MB/s]\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.32G/4.98G [08:52<01:08, 9.66MB/s]\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.32G/4.98G [08:53<01:34, 6.97MB/s]\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.32G/4.98G [08:53<01:17, 8.45MB/s]\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.33G/4.98G [08:54<01:10, 9.17MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.38G/4.98G [08:59<01:03, 9.47MB/s]\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.39G/4.98G [09:01<01:08, 8.54MB/s]\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.40G/4.98G [09:01<01:05, 8.90MB/s]\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.40G/4.98G [09:02<01:03, 9.09MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.40G/4.98G [09:02<01:30, 6.38MB/s]\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.40G/4.98G [09:03<01:15, 7.59MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|████████▊ | 4.41G/4.98G [09:03<01:07, 8.45MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|████████▊ | 4.41G/4.98G [09:03<01:04, 8.72MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|████████▊ | 4.41G/4.98G [09:04<01:03, 8.89MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  89%|████████▉ | 4.42G/4.98G [09:04<01:06, 8.40MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|████████▉ | 4.42G/4.98G [09:05<01:03, 8.67MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|████████▉ | 4.43G/4.98G [09:05<01:01, 8.89MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  89%|████████▉ | 4.43G/4.98G [09:05<01:00, 9.09MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|████████▉ | 4.43G/4.98G [09:06<01:11, 7.61MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|████████▉ | 4.44G/4.98G [09:06<01:00, 8.87MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|████████▉ | 4.44G/4.98G [09:07<00:58, 9.25MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|████████▉ | 4.44G/4.98G [09:07<00:56, 9.46MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|████████▉ | 4.45G/4.98G [09:07<00:55, 9.58MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  89%|████████▉ | 4.45G/4.98G [09:08<01:11, 7.35MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|████████▉ | 4.45G/4.98G [09:08<01:01, 8.59MB/s]\n",
      "model-00001-of-00004.safetensors:  90%|████████▉ | 4.46G/4.98G [09:08<00:59, 8.83MB/s]\n",
      "model-00001-of-00004.safetensors:  90%|████████▉ | 4.46G/4.98G [09:09<00:57, 9.00MB/s]\n",
      "model-00001-of-00004.safetensors:  90%|████████▉ | 4.46G/4.98G [09:09<00:56, 9.14MB/s]\n",
      "model-00001-of-00004.safetensors:  90%|████████▉ | 4.46G/4.98G [09:10<01:06, 7.68MB/s]\n",
      "model-00001-of-00004.safetensors:  90%|████████▉ | 4.47G/4.98G [09:10<00:57, 8.92MB/s]\n",
      "model-00001-of-00004.safetensors:  90%|████████▉ | 4.47G/4.98G [09:10<00:53, 9.45MB/s]\n",
      "model-00001-of-00004.safetensors:  90%|████████▉ | 4.47G/4.98G [09:10<00:53, 9.47MB/s]\n",
      "model-00001-of-00004.safetensors:  90%|████████▉ | 4.48G/4.98G [09:11<00:52, 9.47MB/s]\n",
      "model-00001-of-00004.safetensors:  90%|█████████ | 4.48G/4.98G [09:11<01:02, 7.91MB/s]\n",
      "model-00001-of-00004.safetensors:  90%|█████████ | 4.48G/4.98G [09:12<00:53, 9.15MB/s]\n",
      "model-00001-of-00004.safetensors:  90%|█████████ | 4.49G/4.98G [09:12<00:51, 9.50MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  91%|█████████ | 4.54G/4.98G [09:17<00:45, 9.75MB/s]\n",
      "model-00003-of-00004.safetensors: 100%|██████████| 4.92G/4.92G [09:19<00:00, 8.78MB/s]\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.56G/4.98G [09:19<00:43, 9.70MB/s]\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.56G/4.98G [09:20<00:42, 9.76MB/s]\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.56G/4.98G [09:20<00:54, 7.69MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.56G/4.98G [09:21<00:45, 9.02MB/s]\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.57G/4.98G [09:21<00:42, 9.55MB/s]\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.57G/4.98G [09:21<00:41, 9.61MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.58G/4.98G [09:22<00:50, 7.95MB/s]\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.58G/4.98G [09:22<00:43, 9.22MB/s]\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.59G/4.98G [09:23<00:40, 9.66MB/s]\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.59G/4.98G [09:23<00:38, 10.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.59G/4.98G [09:24<00:50, 7.64MB/s]\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.60G/4.98G [09:24<00:42, 8.95MB/s]\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.60G/4.98G [09:24<00:40, 9.39MB/s]\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.60G/4.98G [09:25<00:39, 9.41MB/s]\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.61G/4.98G [09:25<00:39, 9.39MB/s]\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.61G/4.98G [09:25<00:46, 7.92MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.62G/4.98G [09:26<00:39, 9.13MB/s]\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.62G/4.98G [09:26<00:36, 9.86MB/s]\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.62G/4.98G [09:27<00:36, 9.75MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.62G/4.98G [09:27<00:46, 7.53MB/s]\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.63G/4.98G [09:28<00:36, 9.43MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.63G/4.98G [09:28<00:35, 9.64MB/s]\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.64G/4.98G [09:29<00:34, 9.76MB/s]\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.64G/4.98G [09:29<00:45, 7.40MB/s]\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.64G/4.98G [09:29<00:38, 8.74MB/s]\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.65G/4.98G [09:30<00:35, 9.33MB/s]\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.65G/4.98G [09:30<00:34, 9.36MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|█████████▎| 4.65G/4.98G [09:30<00:34, 9.40MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  94%|█████████▎| 4.66G/4.98G [09:31<00:36, 8.72MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|█████████▎| 4.66G/4.98G [09:32<00:33, 9.29MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.67G/4.98G [09:32<00:32, 9.43MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.67G/4.98G [09:32<00:32, 9.56MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.67G/4.98G [09:33<00:39, 7.68MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.68G/4.98G [09:33<00:33, 8.97MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.68G/4.98G [09:33<00:32, 9.10MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.68G/4.98G [09:34<00:40, 7.21MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.69G/4.98G [09:35<00:37, 7.79MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.69G/4.98G [09:35<00:50, 5.75MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.69G/4.98G [09:35<00:40, 7.00MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.70G/4.98G [09:36<00:35, 7.99MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.70G/4.98G [09:36<00:32, 8.50MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.70G/4.98G [09:36<00:31, 8.77MB/s]\n",
      "model-00001-of-00004.safetensors:  95%|█████████▍| 4.70G/4.98G [09:37<00:37, 7.23MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  95%|█████████▍| 4.71G/4.98G [09:37<00:31, 8.64MB/s]\n",
      "model-00001-of-00004.safetensors:  95%|█████████▍| 4.71G/4.98G [09:38<00:28, 9.30MB/s]\n",
      "model-00001-of-00004.safetensors:  95%|█████████▍| 4.72G/4.98G [09:38<00:27, 9.39MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  95%|█████████▍| 4.72G/4.98G [09:39<00:33, 7.69MB/s]\n",
      "model-00001-of-00004.safetensors:  95%|█████████▍| 4.72G/4.98G [09:39<00:28, 9.00MB/s]\n",
      "model-00001-of-00004.safetensors:  95%|█████████▍| 4.73G/4.98G [09:39<00:26, 9.46MB/s]\n",
      "model-00001-of-00004.safetensors:  95%|█████████▌| 4.73G/4.98G [09:40<00:25, 9.66MB/s]\n",
      "model-00001-of-00004.safetensors:  95%|█████████▌| 4.73G/4.98G [09:40<00:25, 9.57MB/s]\n",
      "model-00001-of-00004.safetensors:  95%|█████████▌| 4.74G/4.98G [09:40<00:30, 7.85MB/s]\n",
      "model-00001-of-00004.safetensors:  95%|█████████▌| 4.74G/4.98G [09:41<00:25, 9.13MB/s]\n",
      "model-00001-of-00004.safetensors:  95%|█████████▌| 4.74G/4.98G [09:41<00:24, 9.38MB/s]\n",
      "model-00001-of-00004.safetensors:  95%|█████████▌| 4.75G/4.98G [09:41<00:23, 9.60MB/s]\n",
      "model-00001-of-00004.safetensors:  95%|█████████▌| 4.75G/4.98G [09:42<00:23, 9.58MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  95%|█████████▌| 4.75G/4.98G [09:42<00:29, 7.71MB/s]\n",
      "model-00001-of-00004.safetensors:  96%|█████████▌| 4.76G/4.98G [09:43<00:23, 9.41MB/s]\n",
      "model-00001-of-00004.safetensors:  96%|█████████▌| 4.76G/4.98G [09:43<00:22, 9.52MB/s]\n",
      "model-00001-of-00004.safetensors:  96%|█████████▌| 4.77G/4.98G [09:43<00:21, 9.61MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  96%|█████████▌| 4.77G/4.98G [09:44<00:26, 7.91MB/s]\n",
      "model-00001-of-00004.safetensors:  96%|█████████▌| 4.77G/4.98G [09:44<00:22, 9.17MB/s]\n",
      "model-00001-of-00004.safetensors:  96%|█████████▌| 4.78G/4.98G [09:44<00:21, 9.46MB/s]\n",
      "model-00001-of-00004.safetensors:  96%|█████████▌| 4.78G/4.98G [09:45<00:20, 9.45MB/s]\n",
      "model-00001-of-00004.safetensors:  96%|█████████▌| 4.78G/4.98G [09:45<00:20, 9.59MB/s]\n",
      "model-00001-of-00004.safetensors:  96%|█████████▌| 4.78G/4.98G [09:46<00:25, 7.60MB/s]\n",
      "model-00001-of-00004.safetensors:  96%|█████████▌| 4.79G/4.98G [09:46<00:21, 8.75MB/s]\n",
      "model-00001-of-00004.safetensors:  96%|█████████▋| 4.79G/4.98G [09:46<00:20, 9.14MB/s]\n",
      "model-00001-of-00004.safetensors:  96%|█████████▋| 4.79G/4.98G [09:47<00:19, 9.24MB/s]\n",
      "model-00001-of-00004.safetensors:  96%|█████████▋| 4.80G/4.98G [09:47<00:18, 9.50MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  96%|█████████▋| 4.80G/4.98G [09:47<00:23, 7.44MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.80G/4.98G [09:48<00:19, 8.76MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.81G/4.98G [09:48<00:18, 9.23MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.81G/4.98G [09:48<00:17, 9.40MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.81G/4.98G [09:49<00:17, 9.42MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.82G/4.98G [09:49<00:21, 7.47MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.82G/4.98G [09:50<00:17, 8.76MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.82G/4.98G [09:50<00:16, 9.24MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.83G/4.98G [09:50<00:16, 9.35MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.83G/4.98G [09:51<00:15, 9.41MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.83G/4.98G [09:51<00:18, 7.92MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.84G/4.98G [09:51<00:15, 9.17MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.84G/4.98G [09:52<00:14, 9.65MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.84G/4.98G [09:52<00:13, 9.73MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.85G/4.98G [09:52<00:13, 10.0MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.85G/4.98G [09:53<00:17, 7.34MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.85G/4.98G [09:53<00:14, 8.67MB/s]\n",
      "model-00001-of-00004.safetensors:  98%|█████████▊| 4.86G/4.98G [09:53<00:13, 9.13MB/s]\n",
      "model-00001-of-00004.safetensors:  98%|█████████▊| 4.86G/4.98G [09:54<00:12, 9.47MB/s]\n",
      "model-00001-of-00004.safetensors:  98%|█████████▊| 4.86G/4.98G [09:54<00:12, 9.50MB/s]\n",
      "model-00001-of-00004.safetensors:  98%|█████████▊| 4.86G/4.98G [09:55<00:14, 7.58MB/s]\n",
      "model-00002-of-00004.safetensors: 100%|██████████| 5.00G/5.00G [09:55<00:00, 8.39MB/s]\n",
      "model-00001-of-00004.safetensors: 100%|██████████| 4.98G/4.98G [10:08<00:00, 8.18MB/s]\n",
      "\n",
      "\n",
      "Upload 4 LFS files: 100%|██████████| 4/4 [10:08<00:00, 152.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Saved merged model to https://huggingface.co/None/Llama-3-Open-Ko-8B-Instruct-PM1-completion-v2-60\n"
     ]
    }
   ],
   "source": [
    "# Hub 에 업로드\n",
    "model.push_to_hub_merged(\n",
    "    huggingface_repo,\n",
    "    tokenizer,\n",
    "    save_method=save_method,\n",
    "    token=huggingface_token,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model reload and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.43.3.\n",
      "   \\\\   /|    GPU: NVIDIA RTX A5000. Max memory: 23.677 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.1.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.22.post7+cu118. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 4096  # 최대 시퀀스 길이를 설정합니다. 내부적으로 RoPE 스케일링을 자동으로 지원합니다!\n",
    "# 자동 감지를 위해 None을 사용합니다. Tesla T4, V100은 Float16, Ampere+는 Bfloat16을 사용하세요.\n",
    "dtype = None\n",
    "# 메모리 사용량을 줄이기 위해 4bit 양자화를 사용합니다. False일 수도 있습니다.\n",
    "load_in_4bit = True\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    # model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n",
    "    model_name=\"/home/jaesung/jaesung/pulmuone/text-generation-webui/models/Llama-3-Open-Ko-8B-Instruct-PM1-completion-v2-60-gguf\",\n",
    "    max_seq_length=max_seq_length,  # 최대 시퀀스 길이를 설정합니다.\n",
    "    dtype=dtype,  # 데이터 타입을 설정합니다.\n",
    "    load_in_4bit=load_in_4bit,  # 4bit 양자화 로드 여부를 설정합니다.\n",
    "    # token = \"hf_...\", # 게이트된 모델을 사용하는 경우 토큰을 사용하세요. 예: meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# EOS_TOKEN은 문장의 끝을 나타내는 토큰입니다. 이 토큰을 추가해야 합니다.\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "# AlpacaPrompt를 사용하여 지시사항을 포맷팅하는 함수입니다.\n",
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "\n",
    "# 주어진 예시들을 포맷팅하는 함수입니다.\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"QUESTION\"]  # 지시사항을 가져옵니다.\n",
    "    outputs = examples[\"ANSWER\"]  # 출력값을 가져옵니다.\n",
    "    texts = []  # 포맷팅된 텍스트를 저장할 리스트입니다.\n",
    "    for instruction, output in zip(instructions, outputs):\n",
    "        # EOS_TOKEN을 추가해야 합니다. 그렇지 않으면 생성이 무한히 진행될 수 있습니다.\n",
    "        text = alpaca_prompt.format(instruction, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\n",
    "        \"text\": texts,  # 포맷팅된 텍스트를 반환합니다.\n",
    "    }\n",
    "\n",
    "# JSONL 파일 로드 함수\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data\n",
    "\n",
    "# JSONL 파일 경로\n",
    "file_path = '/home/jaesung/jaesung/pulmuone/llama3_ft/completion/data/qa_pair_for_completion.jsonl'\n",
    "\n",
    "# JSONL 파일 로드\n",
    "data = load_jsonl(file_path)\n",
    "\n",
    "# pandas DataFrame으로 변환\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Dataset 객체로 변환\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# DatasetDict 객체로 결합\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 7735/7735 [00:00<00:00, 89440.53 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋에 formatting_prompts_func 함수를 적용합니다. 배치 처리를 활성화합니다.\n",
    "dataset = dataset.map(\n",
    "    formatting_prompts_func,\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "import string\n",
    "\n",
    "class StopOnToken(StoppingCriteria):\n",
    "    def __init__(self, stop_token_id):\n",
    "        self.stop_token_id = stop_token_id  # 정지 토큰 ID를 초기화합니다.\n",
    "\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        return (\n",
    "            self.stop_token_id in input_ids[0]\n",
    "        )  # 입력된 ID 중 정지 토큰 ID가 있으면 정지합니다.\n",
    "\n",
    "class StopOnRepetitionPattern(StoppingCriteria):\n",
    "    def __init__(self, repetition_limit=3, tokenizer=None):\n",
    "        self.repetition_limit = repetition_limit\n",
    "        self.repetition_count = {}\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def extract_comma_segment(self, text):\n",
    "        # 콤마로 분리된 구 중 마지막 구를 추출합니다.\n",
    "        segments = text.split(',')\n",
    "        return segments[-1].strip().lower()\n",
    "    \n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        # 현재까지 생성된 전체 텍스트를 디코딩합니다.\n",
    "        generated_text = self.tokenizer.decode(input_ids[0], skip_special_tokens=True).strip()\n",
    "        comma_segment = self.extract_comma_segment(generated_text)\n",
    "        \n",
    "        if not comma_segment:\n",
    "            return False\n",
    "        \n",
    "        # 마지막 구간에서 단어를 분리\n",
    "        words = comma_segment.split()\n",
    "        \n",
    "        if len(words) == 1:  # 마지막 구간에 단어가 하나만 있다면\n",
    "            word = words[0]\n",
    "            if word in self.repetition_count:\n",
    "                self.repetition_count[word] += 1\n",
    "            else:\n",
    "                self.repetition_count[word] = 1\n",
    "            \n",
    "            # 만약 특정 단어가 repetition_limit 이상 반복되면 생성을 중단합니다.\n",
    "            if self.repetition_count[word] >= self.repetition_limit:\n",
    "                return True\n",
    "        else:\n",
    "            # 다른 구간이 생성되면 카운트 초기화\n",
    "            self.repetition_count = {}\n",
    "        \n",
    "        return False\n",
    "    \n",
    "# end_token을 설정\n",
    "stop_token = \"<|end_of_text|>\"  # end_token으로 사용할 토큰을 설정합니다.\n",
    "stop_token_id = tokenizer.encode(stop_token, add_special_tokens=False)[\n",
    "    0\n",
    "]  # end_token의 ID를 인코딩합니다.\n",
    "\n",
    "# Stopping criteria 설정\n",
    "stopping_criteria = StoppingCriteriaList(\n",
    "    [StopOnToken(stop_token_id),\n",
    "     StopOnRepetitionPattern(repetition_limit=3, tokenizer=tokenizer)] # 동일한 단어가 3번 반복되면 정지합니다.\n",
    ")  # 정지 조건을 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QUESTION': '힌트가 수산물, 어묵일 때, 설탕, 정제소금, 연육(잡어) 외에 어떤 재료들이 더 포함되어야 하나요?',\n",
       " 'ANSWER': '당근, 대두유, 대파, 밀가루, 분리대두단백, 설탕, 연육(갈치), 연육(잡어), 정제소금, 효모추출물혼합분말',\n",
       " '__index_level_0__': 2002}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['test'][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "힌트가 수산물, 어묵일 때, 설탕, 정제소금, 연육(잡어) 외에 어떤 재료들이 더 포함되어야 하나요?\n",
      "\n",
      "### Response:\n",
      "When hint is seafood, fish cake, sugar, refined salt, and fish paste, what other ingredients should be included?\n",
      "\n",
      "When hint is seafood, fish cake, sugar, refined salt, and fish paste, other ingredients that should be included are...?\n",
      "\n",
      "When hint is seafood, fish cake, sugar, refined salt, and fish paste, other ingredients that should be included are...? (Please fill in the blank with the correct answer.) 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23. "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 16\u001b[0m\n\u001b[1;32m      5\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[1;32m      6\u001b[0m     [\n\u001b[1;32m      7\u001b[0m         alpaca_prompt\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m text_streamer \u001b[38;5;241m=\u001b[39m TextStreamer(tokenizer)\n\u001b[0;32m---> 16\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_streamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 최대 생성 토큰 수를 설정합니다.\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 생성을 멈출 기준을 설정합니다.\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# output_list = tokenizer.batch_decode(_, skip_special_tokens=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/unsloth/models/llama.py:1201\u001b[0m, in \u001b[0;36m_wrap_fast_inference.<locals>._fast_generate\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;66;03m# Set pad token\u001b[39;00m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# old_pad_token_id = getattr(model.config, \"pad_token_id\", None)\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;66;03m# old_eos_token_id = getattr(model.config, \"eos_token_id\", None)\u001b[39;00m\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;66;03m# model.config.pad_token_id = old_eos_token_id\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m \n\u001b[1;32m   1199\u001b[0m \u001b[38;5;66;03m# Autocasted\u001b[39;00m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(device_type \u001b[38;5;241m=\u001b[39m device_type, dtype \u001b[38;5;241m=\u001b[39m dtype):\n\u001b[0;32m-> 1201\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;66;03m# Revert\u001b[39;00m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;66;03m# model.config.pad_token_id = old_pad_token_id\u001b[39;00m\n\u001b[1;32m   1206\u001b[0m \n\u001b[1;32m   1207\u001b[0m \u001b[38;5;66;03m# Unset a flag for generation!\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/transformers/generation/utils.py:1989\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1981\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1982\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1983\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1984\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1985\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1986\u001b[0m     )\n\u001b[1;32m   1988\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1989\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1990\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1994\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1995\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1996\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1997\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1998\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2001\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2003\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2004\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   2005\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2006\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/transformers/generation/utils.py:2932\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2929\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   2931\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2932\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2935\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/unsloth/models/llama.py:864\u001b[0m, in \u001b[0;36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_CausalLM_fast_forward\u001b[39m(\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    849\u001b[0m     input_ids: torch\u001b[38;5;241m.\u001b[39mLongTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    861\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tuple, CausalLMOutputWithPast]:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 864\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfast_forward_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m         causal_mask \u001b[38;5;241m=\u001b[39m xformers\u001b[38;5;241m.\u001b[39mattn_bias\u001b[38;5;241m.\u001b[39mLowerTriangularMask()\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/unsloth/models/llama.py:818\u001b[0m, in \u001b[0;36mLlamaModel_fast_forward_inference\u001b[0;34m(self, input_ids, past_key_values, position_ids, attention_mask)\u001b[0m\n\u001b[1;32m    816\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    817\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m fast_rms_layernorm_inference(decoder_layer\u001b[38;5;241m.\u001b[39minput_layernorm, hidden_states)\n\u001b[0;32m--> 818\u001b[0m hidden_states, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaAttention_fast_forward_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_prefill\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpaged_attention\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m hidden_states \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m residual\n\u001b[1;32m    828\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/anaconda3/envs/unsloth_env/lib/python3.10/site-packages/unsloth/models/llama.py:197\u001b[0m, in \u001b[0;36mLlamaAttention_fast_forward_inference\u001b[0;34m(self, hidden_states, past_key_value, position_ids, do_prefill, attention_mask)\u001b[0m\n\u001b[1;32m    195\u001b[0m RH_Q[:,:,:,:h] \u001b[38;5;241m=\u001b[39m Qn[:,:,:,h:]\n\u001b[1;32m    196\u001b[0m RH_Q[:,:,:,h:] \u001b[38;5;241m=\u001b[39m Qn[:,:,:,:h]\n\u001b[0;32m--> 197\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRH_Q\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43mh\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mRH_Q\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43mh\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m Qn \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m cos\n\u001b[1;32m    199\u001b[0m Qn\u001b[38;5;241m.\u001b[39maddcmul_(RH_Q, sin)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "# FastLanguageModel을 이용하여 추론 속도를 2배 빠르게 설정합니다.\n",
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "    [\n",
    "        alpaca_prompt.format(\n",
    "            \"힌트가 수산물, 어묵일 때, 설탕, 정제소금, 연육(잡어) 외에 어떤 재료들이 더 포함되어야 하나요?\",  # 지시사항\n",
    "            \"\",  # 출력 - 생성을 위해 이 부분을 비워둡니다!\n",
    "        )\n",
    "    ],\n",
    "    return_tensors=\"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(\n",
    "    **inputs,\n",
    "    streamer=text_streamer,\n",
    "    max_new_tokens=4096,  # 최대 생성 토큰 수를 설정합니다.\n",
    "    stopping_criteria=stopping_criteria  # 생성을 멈출 기준을 설정합니다.\n",
    ")\n",
    "\n",
    "# output_list = tokenizer.batch_decode(_, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QUESTION': '주어진 힌트가 두부과 두부일 때, 대두 외에 추가적으로 필요한 재료는 무엇일까요?',\n",
       " 'ANSWER': '대두',\n",
       " '__index_level_0__': 994}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['test'][70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['QUESTION', 'ANSWER', '__index_level_0__'],\n",
       "    num_rows: 1547\n",
       "})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "냉동밥과 즉석조리식품이라는 힌트가 주어졌을 때, 두부곤약쌀, 대두단백, 흑후추 이외에 어떤 재료들이 필요할까요?\n",
      "\n",
      "### Response:\n",
      "대두단백, 두부곤약쌀, 흑후추<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "주어진 힌트가 수산물과 어묵일 때, 냉동연육, 타피오카전분, 당근 외에 추가적으로 필요한 재료는 무엇일까요?\n",
      "\n",
      "### Response:\n",
      "당근, 냉동연육, 대두유, 대파, 마늘, 밀가루, 백설탕, 부추, 설탕, 양파, 유산균배양액혼합분말, 정제소금, 정제수, 참기름, 타피오카전분, 해물추출액혼합분말<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "힌트가 소스류, 소스(살균제품)일 때, 파인애플크러시드퓨레, 풀무원다논그릭요거트파우치(캡형), 향긋한 사과식초 외에 어떤 재료들이 더 포함되어야 하나요?\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드나트륨, D-자일로오스, DL-사과산, 가쓰오엑기스, 구연산, 구연산칼슘, 난백액, 당근, 당근분말, 대두유, 대파, 마늘, 밀분해추출물, 백설탕, 비타민C, 비타젠S, 비\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "주어진 재료가 마라소스, 어묵용조미액, 냉동연육(이또요리A)일 때, 수산물 중에 어묵을 만드는 데 필요한 나머지 재료들은 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, D-자일로오스, 냉동연육(이또요리A), 대두유, 대파, 마라소스, 밀글루텐, 어묵용조미액, 정제소금, 정제수, 참기름, 흑후추분말<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "소스류과 소스을 고려했을 때, 카레분말-이, 참맛고추장, 청양고춧가루 외에 포함되어야 할 다른 재료는 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 가쓰오엑기스, 고추기름, 고춧가루, 구아검, 마늘, 맛내기양념, 맛내기양념(고추장), 백설탕, 볶음참깨, 설탕, 양조간장, 양파, 유기농올레오레진피에이, 정제소금, 참맛고추장, 청양고춧가루, 카레분말-이, 카레분말, 카\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "소스류과 소스류이라는 힌트가 주어졌을 때, 아미노베이스P, 설탕, 산초고농축액-P 이외에 어떤 재료들이 필요할까요?\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드나트륨, 아미노베이스P, 구연산, 설탕, 양조간장, 양파, 정제소금, 정제수, 참기름, 파프리카추출색소, 폴리인산나트륨, 효모추출물혼합분말<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "주어진 재료가 간장불구이소스-P, 쌀콩단백, 대두유.일 때, 대체육 중에 두류가공품을 만드는 데 필요한 나머지 재료들은 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "간장불구이소스-P, 대두유, 대두유, 쌀콩단백, 정제소금, 정제수, 효모추출물혼합분말<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "주어진 힌트가 수산물과 조미김일 때, 유기농 카놀라유, 유기농참기름, 김 외에 추가적으로 필요한 재료는 무엇일까요?\n",
      "\n",
      "### Response:\n",
      "김, 유기농 카놀라유, 유기농참기름<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "두부과 두부이라는 힌트가 주어졌을 때, 대두 이외에 어떤 재료들이 필요할까요?\n",
      "\n",
      "### Response:\n",
      "대두<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "소스류과 소스류을 고려했을 때, 양파, 지미베이스P, 홍고추 외에 포함되어야 할 다른 재료는 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 고과당, 고추기름, 고\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "두부과 두부이라는 힌트가 주어졌을 때, 대두 이외에 어떤 재료들이 필요할까요?\n",
      "\n",
      "### Response:\n",
      "대두<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "두부과 두부이라는 힌트가 주어졌을 때, 비타민D3혼합제제, 유청칼슘, 혼합제제 이외에 어떤 재료들이 필요할까요?\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드나트륨, D-자일로오스, DL-사과산, DL-사과산, 비타민D3혼합제제, 비타민K2, 비\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "힌트가 농산물, 농산물일 때, 나물콩 외에 어떤 재료들이 더 포함되어야 하나요?\n",
      "\n",
      "### Response:\n",
      "나물콩<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "두부과 두부이라는 힌트가 주어졌을 때, 대두 이외에 어떤 재료들이 필요할까요?\n",
      "\n",
      "### Response:\n",
      "대두<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "두부과 두부을 고려했을 때, 대두 외에 포함되어야 할 다른 재료는 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "대두<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "힌트가 농산물, 신선편의식품일 때, 파인애플 외에 어떤 재료들이 더 포함되어야 하나요?\n",
      "\n",
      "### Response:\n",
      "파인애플<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "면, 만두과 만두이라는 힌트가 주어졌을 때, 부추, 유화유지피, 후추가루 이외에 어떤 재료들이 필요할까요?\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드나트륨, A, B, C, 부추, 당면, 대두단백, 대두유, 돼지고기, 마늘, 밀가루, 백설탕, 부추, 생강, 생마늘, 생\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "주어진 힌트가 농산물과 절임식품일 때, 블루베리향, 블루베리농축액, 발효식초 외에 추가적으로 필요한 재료는 무엇일까요?\n",
      "\n",
      "### Response:\n",
      "블루베리향, 블루베리농축액, 발효식초, 효모추출물혼합분말<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "힌트가 떡류, 떡류일 때, 쌀가루, 정제소금, 주정 외에 어떤 재료들이 더 포함되어야 하나요?\n",
      "\n",
      "### Response:\n",
      "쌀가루, 주정, 정제소금<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "주어진 재료가 오레가노, 소프리토, 토마토분말-P일 때, 소스류 중에 소스을 만드는 데 필요한 나머지 재료들은 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, D-자일로오스, 감칠맛분말, 고과당, 고추기름, 고\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "힌트가 수산물, 조미김일 때, 김 외에 어떤 재료들이 더 포함되어야 하나요?\n",
      "\n",
      "### Response:\n",
      "김<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "농산물과 절임식품이라는 힌트가 주어졌을 때, 절임무, DL-사과산, 폴리인산나트륨 이외에 어떤 재료들이 필요할까요?\n",
      "\n",
      "### Response:\n",
      "DL-사과산, 절임무, 폴리인산나트륨<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "두부과 두부을 고려했을 때, 두부 외에 포함되어야 할 다른 재료는 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "두부<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "주어진 재료가 생선조림양념(참바다), 적어(장문볼락), 무일 때, 수산물 중에 수산물가공품을 만드는 데 필요한 나머지 재료들은 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "적어(장문볼락), 생선조림양념(참바다), 무<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "주어진 재료가 오징어조미분말, 5'-리보뉴클레오티드이나트륨, 정제소금일 때, 수산물 중에 기타수산물가공품을 만드는 데 필요한 나머지 재료들은 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 오징어조미분말, 정제소금<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "수산물과 어묵/유탕처리제품/비살균을 고려했을 때, 백설탕, 대두유, 정제소금 외에 포함되어야 할 다른 재료는 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드나트륨, D-자일로오스, DL-사과산, DL-사과산, 당근, 당근 외에 절임당근, 대두유, 대파, 마늘, 백설탕, 비타민C, 비타젠S, 비\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "주어진 힌트가 두부과 두부일 때, 대두 외에 추가적으로 필요한 재료는 무엇일까요?\n",
      "\n",
      "### Response:\n",
      "대두<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "주어진 재료가 쇠고기베이스, 부추, 두부일 때, 면, 만두 중에 만두을 만드는 데 필요한 나머지 재료들은 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드나트륨, 가쓰오엑기스, 고추씨기름, 굴소스, 당근, 대두유, 대파, 두부, 마늘, 밀가루, 백설탕, 부추, �\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "주어진 재료가 나물콩일 때, 농산물 중에 농산물을 만드는 데 필요한 나머지 재료들은 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "나물콩<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "주어진 재료가 멸치, 다시마일 때, 수산물 중에 기타수산물가공품을 만드는 데 필요한 나머지 재료들은 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "멸치, 다시마<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "두부과 두부을 고려했을 때, 밀크칼슘, 폴리감마글루탐산, 대두 외에 포함되어야 할 다른 재료는 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "대두, 밀크칼슘, 폴리감마글루탐산<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "농산물과 농산물을 고려했을 때, 나물콩 외에 포함되어야 할 다른 재료는 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "나물콩<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "떡류과 떡류을 고려했을 때, 정제수, 백설탕, 흑설탕 외에 포함되어야 할 다른 재료는 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "5'-이노신산이나트륨, D-자일로오스, D-자일로오스액, D\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "힌트가 수산물, 어묵일 때, 설탕, 냉동연육, 대두유 외에 어떤 재료들이 더 포함되어야 하나요?\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드나트륨, D-자일로오스, 냉동연육, 대두유, 대파, 마늘, 설탕, 양파, 정제소금, 참기름, 해물추출액<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "주어진 재료가 나물콩일 때, 농산물 중에 농산물을 만드는 데 필요한 나머지 재료들은 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "나물콩<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "두부과 두부을 고려했을 때, 천일염천연응고제100, 대두 외에 포함되어야 할 다른 재료는 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "대두, 천일염천연응고제100<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "냉동밥과 즉석조리식품을 고려했을 때, 깍두기, 볶음김치향미유, 맛내기양념 외에 포함되어야 할 다른 재료는 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드나트륨, 고추기름, 고춧가루, 굴소스, 깍두기, 김, 마늘, 맛내기양념, 모짜렐라치즈, �\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "힌트가 두부, 두부일 때, 두부, 유기농 대두 외에 어떤 재료들이 더 포함되어야 하나요?\n",
      "\n",
      "### Response:\n",
      "유기농 대두<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "떡류과 떡류이라는 힌트가 주어졌을 때, 흑설탕, 멥쌀, 백설탕 이외에 어떤 재료들이 필요할까요?\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드나트륨, 감자전분, 고과당, 고추씨기름, 고\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "힌트가 소스류, 소스일 때, 볶음춘장베이스Y, 대파소스, 야채풍미소스 외에 어떤 재료들이 더 포함되어야 하나요?\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 고과당, 고추기름, 고\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "힌트가 수산물, 어묵일 때, 대두단백, 대두유, 설탕 외에 어떤 재료들이 더 포함되어야 하나요?\n",
      "\n",
      "### Response:\n",
      "대두단백, 대두유, 설탕, 정제소금, 정제수, 효모추출물혼합분말<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "면, 만두과 만두을 고려했을 때, 쇠고기추출분말, 난백, 생강분말 외에 포함되어야 할 다른 재료는 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "난백, 당면, 대두단백, 대두유, 돼지고기, 마늘, 밀가루, �\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "주어진 힌트가 소스류과 소스류일 때, 양파, 지미베이스P, 홍고추 외에 추가적으로 필요한 재료는 무엇일까요?\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 고과당, 고추기름, 고\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "주어진 재료가 치자황색소, 적양배추색소에이, 그린색소PKS-1일 때, 농산물 중에 절임류을 만드는 데 필요한 나머지 재료들은 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, DL-사과산, DL-사과산, 가쓰오엑기스, 구연산, 기타과당, 기타과당, 기타\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "힌트가 냉동밥, 즉석조리식품일 때, 직화숯불구이원, 쌀, 마늘풍미유 외에 어떤 재료들이 더 포함되어야 하나요?\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드나트륨, 고추기름, 고추씨기름, 고\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "주어진 재료가 냉동명태필렛일 때, 수산물 중에 기타수산물가공품(가열하여섭취하는냉동식품)을 만드는 데 필요한 나머지 재료들은 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "냉동명태필렛<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "주어진 재료가 식물성간장소스, 표고버섯채, 콩단백숯불직화구이일 때, 대체육 중에 두류가공품을 만드는 데 필요한 나머지 재료들은 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드나트륨, D-자일로오스, DL-사과산, DL-사과산, 고과당, 고추기름, 고\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "두부과 두부을 고려했을 때, 대두 외에 포함되어야 할 다른 재료는 무엇인가요?\n",
      "\n",
      "### Response:\n",
      "대두<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "주어진 힌트가 면, 만두과 만두류일 때, 정제소금, 유화유지피, 양파 외에 추가적으로 필요한 재료는 무엇일까요?\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드나트륨, 감자전분, 고추기름, 고추장, 굴소스, 당근, 대두단백, 대두유, 대\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "주어진 힌트가 두부과 두부일 때, 대두 외에 추가적으로 필요한 재료는 무엇일까요?\n",
      "\n",
      "### Response:\n",
      "대두<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from transformers import TextStreamer\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "length = 50 # length of random list\n",
    "random_list = [random.randint(0, len(dataset_dict['test'])) for _ in range(length)]\n",
    "\n",
    "q_list = []; a_list = []; output_list = []\n",
    "for n in random_list:\n",
    "    q = dataset_dict['test'][n]['QUESTION']\n",
    "    a = dataset_dict['test'][n]['ANSWER']\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        [\n",
    "            alpaca_prompt.format(\n",
    "                q,  # 지시사항\n",
    "                \"\",  # 출력 - 생성을 위해 이 부분을 비워둡니다!\n",
    "            )\n",
    "        ],\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    text_streamer = TextStreamer(tokenizer)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        streamer=text_streamer,\n",
    "        max_new_tokens=4096,  # 최대 생성 토큰 수를 설정합니다.\n",
    "        stopping_criteria=stopping_criteria  # 생성을 멈출 기준을 설정합니다.\n",
    "    )\n",
    "\n",
    "    q_list.append(q)\n",
    "    a_list.append(a)\n",
    "    output_tmp = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    output_list.append(output_tmp[0].split('\\n')[-1].split(', '))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5364169807511104\n"
     ]
    }
   ],
   "source": [
    "# [answer (a_list) 와 pred (output_list) 의 교집합 / answer (a_list) 의 길이]\n",
    "score_list = []\n",
    "for a, p in zip(a_list, output_list):\n",
    "    a = a.split(', ')\n",
    "    cnt = 0\n",
    "    for pp in p:\n",
    "        if pp in a:\n",
    "            cnt += 1\n",
    "    score_list.append(cnt/len(a))\n",
    "\n",
    "print(sum(score_list)/len(score_list)) # mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantization 방식 설정\n",
    "quantization_method = \"q8_0\"  # \"f16\" \"q8_0\" \"q4_k_m\" \"q5_k_m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 41.28 out of 125.66 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 42.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
      "Done.\n",
      "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
      "   \\\\   /|    [0] Installing llama.cpp will take 3 minutes.\n",
      "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits will take 3 minutes.\n",
      "\\        /    [2] Converting GGUF 16bits to ['q8_0'] will take 10 minutes each.\n",
      " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
      "\n",
      "Unsloth: [0] Installing llama.cpp. This will take 3 minutes...\n",
      "Unsloth: [1] Converting model at Llama-3-Open-Ko-8B-Instruct-PM1-completion-v2-60-gguf into q8_0 GGUF format.\n",
      "The output location will be ./Llama-3-Open-Ko-8B-Instruct-PM1-completion-v2-60-gguf/unsloth.Q8_0.gguf\n",
      "This will take 3 minutes...\n",
      "INFO:hf-to-gguf:Loading model: Llama-3-Open-Ko-8B-Instruct-PM1-completion-v2-60-gguf\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:token_embd.weight,           torch.bfloat16 --> Q8_0, shape = {4096, 128256}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00004-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:output.weight,               torch.bfloat16 --> Q8_0, shape = {4096, 128256}\n",
      "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:output_norm.weight,          torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:gguf: context length = 8192\n",
      "INFO:hf-to-gguf:gguf: embedding length = 4096\n",
      "INFO:hf-to-gguf:gguf: feed forward length = 14336\n",
      "INFO:hf-to-gguf:gguf: head count = 32\n",
      "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
      "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
      "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
      "INFO:hf-to-gguf:gguf: file type = 7\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "INFO:gguf.vocab:Adding 280147 merge(s).\n",
      "INFO:gguf.vocab:Setting special token type bos to 128000\n",
      "INFO:gguf.vocab:Setting special token type eos to 128001\n",
      "INFO:gguf.vocab:Setting special token type pad to 128255\n",
      "INFO:gguf.vocab:Setting chat_template to {% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
      "\n",
      "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "' }}{% endif %}\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:Llama-3-Open-Ko-8B-Instruct-PM1-completion-v2-60-gguf/unsloth.Q8_0.gguf: n_tensors = 291, total_size = 8.5G\n",
      "Writing: 100%|██████████| 8.53G/8.53G [00:59<00:00, 144Mbyte/s]\n",
      "INFO:hf-to-gguf:Model successfully exported to Llama-3-Open-Ko-8B-Instruct-PM1-completion-v2-60-gguf/unsloth.Q8_0.gguf\n",
      "Unsloth: Conversion completed! Output location: ./Llama-3-Open-Ko-8B-Instruct-PM1-completion-v2-60-gguf/unsloth.Q8_0.gguf\n",
      "Unsloth: Uploading GGUF to Huggingface Hub...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unsloth.Q8_0.gguf: 100%|██████████| 8.54G/8.54G [05:39<00:00, 25.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GGUF to https://huggingface.co/passionMan/Llama-3-Open-Ko-8B-Instruct-PM1-completion-v2-60-gguf\n"
     ]
    }
   ],
   "source": [
    "# Hub 에 GGUF 업로드\n",
    "model.push_to_hub_gguf(\n",
    "    huggingface_repo + \"-gguf\",\n",
    "    tokenizer,\n",
    "    quantization_method=quantization_method,\n",
    "    token=huggingface_token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env_kernel",
   "language": "python",
   "name": "unsloth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
