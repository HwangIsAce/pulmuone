{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## unsloth_env_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# CUDA 장치의 주요 버전과 부 버전을 가져옵니다.\n",
    "major_version, minor_version = torch.cuda.get_device_capability()\n",
    "major_version, minor_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[unsloth]\n",
    "\n",
    "unsloth 패키지는 대형 언어 모델(LLM)인 Llama 3.1, Mistral, Phi 및 Gemma의 미세 조정을 기존 방법보다 2-5배 빠르게 하고 메모리 사용량을 80%까지 줄이는 데 사용되는 도구입니다. 이 패키지는 OpenAI의 Triton 언어로 작성된 커스텀 GPU 커널을 사용하여 성능을 최적화합니다. 이를 통해 정확도 손실 없이 효율적으로 모델을 훈련할 수 있습니다.\n",
    "\n",
    "주요 기능\n",
    "성능: 특정 경우에는 최대 30배 빠르게 미세 조정할 수 있으며, 메모리 사용량을 크게 줄여 더 큰 배치 크기와 효율적인 훈련이 가능합니다.\n",
    "호환성: NVIDIA, Intel, AMD 등 다양한 GPU를 지원합니다.\n",
    "메모리 최적화: 메모리 사용량을 줄이기 위해 수동 미분 및 체인 매트릭스 곱셈 최적화를 수행합니다.\n",
    "오픈 소스: 무료 오픈 소스 버전이 있으며, 프로 버전에서는 다중 GPU 지원 및 더 빠른 훈련 속도를 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Colab에서 torch 2.2.1을 사용하고 있으므로, 패키지 충돌을 방지하기 위해 별도로 설치해야 합니다.\n",
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "if major_version >= 8:\n",
    "    # 새로운 GPU(예: Ampere, Hopper GPUs - RTX 30xx, RTX 40xx, A100, H100, L40)에 사용하세요.\n",
    "    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n",
    "else:\n",
    "    # 오래된 GPU(예: V100, Tesla T4, RTX 20xx)에 사용하세요.\n",
    "    !pip install --no-deps xformers trl peft accelerate bitsandbytes\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaesung/anaconda3/envs/alpaca/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.44.0.\n",
      "   \\\\   /|    GPU: NVIDIA A10. Max memory: 21.988 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27.post2. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.35s/it]\n",
      "beomi/Llama-3-Open-Ko-8B-Instruct-preview does not have a padding token! Will use pad_token = <|reserved_special_token_250|>.\n",
      "<string>:209: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:210: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:211: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:209: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:210: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:211: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from accelerate import PartialState\n",
    "\n",
    "device_string = PartialState().process_index\n",
    "\n",
    "max_seq_length = 4096  # 최대 시퀀스 길이를 설정합니다. 내부적으로 RoPE 스케일링을 자동으로 지원합니다!\n",
    "# 자동 감지를 위해 None을 사용합니다. Tesla T4, V100은 Float16, Ampere+는 Bfloat16을 사용하세요.\n",
    "dtype = None\n",
    "# 메모리 사용량을 줄이기 위해 4bit 양자화를 사용합니다. False일 수도 있습니다.\n",
    "load_in_4bit = True\n",
    "\n",
    "# 4배 빠른 다운로드와 메모리 부족 문제를 방지하기 위해 지원하는 4bit 사전 양자화 모델입니다.\n",
    "fourbit_models = [\n",
    "    \"unsloth/mistral-7b-bnb-4bit\",\n",
    "    \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n",
    "    \"unsloth/llama-2-7b-bnb-4bit\",\n",
    "    \"unsloth/gemma-7b-bnb-4bit\",\n",
    "    \"unsloth/gemma-7b-it-bnb-4bit\",  # Gemma 7b의 Instruct 버전\n",
    "    \"unsloth/gemma-2b-bnb-4bit\",\n",
    "    \"unsloth/gemma-2b-it-bnb-4bit\",  # Gemma 2b의 Instruct 버전\n",
    "    \"unsloth/llama-3-8b-bnb-4bit\",  # Llama-3 8B\n",
    "]  # 더 많은 모델은 https://huggingface.co/unsloth 에서 확인할 수 있습니다.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    # model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n",
    "    model_name=\"beomi/Llama-3-Open-Ko-8B-Instruct-preview\",  # 모델 이름을 설정합니다.\n",
    "    max_seq_length=max_seq_length,  # 최대 시퀀스 길이를 설정합니다.\n",
    "    dtype=dtype,  # 데이터 타입을 설정합니다.\n",
    "    load_in_4bit=load_in_4bit,  # 4bit 양자화 로드 여부를 설정합니다.\n",
    "    # token = \"hf_...\", # 게이트된 모델을 사용하는 경우 토큰을 사용하세요. 예: meta-llama/Llama-2-7b-hf,\n",
    "    device_map={'':device_string}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2024.8 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    # r=16,\n",
    "    r=32,  # 0보다 큰 어떤 숫자도 선택 가능! 8, 16, 32, 64, 128이 권장됩니다. # 얼마나 압축할지, 많이 압축할 수록 파라미터 수가 작아집니다.\n",
    "    lora_alpha=32,  # LoRA 알파 값을 설정합니다.\n",
    "    lora_dropout=0.05,  # 드롭아웃을 지원합니다.\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],  # 타겟 모듈을 지정합니다.\n",
    "    bias=\"none\",  # 바이어스를 지원합니다.\n",
    "    # True 또는 \"unsloth\"를 사용하여 매우 긴 컨텍스트에 대해 VRAM을 30% 덜 사용하고, 2배 더 큰 배치 크기를 지원합니다.\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=123,  # 난수 상태를 설정합니다.\n",
    "    use_rslora=False,  # 순위 안정화 LoRA를 지원합니다.\n",
    "    loftq_config=None,  # LoftQ를 지원합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# EOS_TOKEN은 문장의 끝을 나타내는 토큰입니다. 이 토큰을 추가해야 합니다.\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "# AlpacaPrompt를 사용하여 지시사항을 포맷팅하는 함수입니다.\n",
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "\n",
    "# 주어진 예시들을 포맷팅하는 함수입니다.\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"QUESTION\"]  # 지시사항을 가져옵니다.\n",
    "    outputs = examples[\"ANSWER\"]  # 출력값을 가져옵니다.\n",
    "    texts = []  # 포맷팅된 텍스트를 저장할 리스트입니다.\n",
    "    for instruction, output in zip(instructions, outputs):\n",
    "        # EOS_TOKEN을 추가해야 합니다. 그렇지 않으면 생성이 무한히 진행될 수 있습니다.\n",
    "        text = alpaca_prompt.format(instruction, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\n",
    "        \"text\": texts,  # 포맷팅된 텍스트를 반환합니다.\n",
    "    }\n",
    "\n",
    "# JSONL 파일 로드 함수\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data\n",
    "\n",
    "# JSONL 파일 경로\n",
    "file_path = '/home/jaesung/pulmuone/instruction_tuning_2/v4_completion/data/qa_pair_for_completion.jsonl'\n",
    "\n",
    "# JSONL 파일 로드\n",
    "data = load_jsonl(file_path)\n",
    "\n",
    "# pandas DataFrame으로 변환\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Dataset 객체로 변환\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# DatasetDict 객체로 결합\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['QUESTION', 'ANSWER', '__index_level_0__'],\n",
      "        num_rows: 10940\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['QUESTION', 'ANSWER', '__index_level_0__'],\n",
      "        num_rows: 2736\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_dict['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['QUESTION', 'ANSWER', '__index_level_0__'],\n",
       "    num_rows: 10940\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10940/10940 [00:00<00:00, 59651.37 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋에 formatting_prompts_func 함수를 적용합니다. 배치 처리를 활성화합니다.\n",
    "dataset = dataset.map(\n",
    "    formatting_prompts_func,\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaesung/anaconda3/envs/alpaca/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/jaesung/anaconda3/envs/alpaca/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Map (num_proc=2): 100%|██████████| 10940/10940 [00:02<00:00, 4329.57 examples/s]\n",
      "Map (num_proc=2): 100%|██████████| 10940/10940 [00:02<00:00, 4306.42 examples/s]\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "from accelerate import notebook_launcher\n",
    "\n",
    "tokenizer.padding_side = \"right\"  # 토크나이저의 패딩을 오른쪽으로 설정합니다.\n",
    "\n",
    "# SFTTrainer를 사용하여 모델 학습 설정\n",
    "trainer = SFTTrainer(\n",
    "    model=model,  # 학습할 모델\n",
    "    tokenizer=tokenizer,  # 토크나이저\n",
    "    train_dataset=dataset,  # 학습 데이터셋\n",
    "    eval_dataset=dataset,\n",
    "    dataset_text_field=\"text\",  # 데이터셋에서 텍스트 필드의 이름\n",
    "    max_seq_length=max_seq_length,  # 최대 시퀀스 길이\n",
    "    dataset_num_proc=2,  # 데이터 처리에 사용할 프로세스 수\n",
    "    packing=False,  # 짧은 시퀀스에 대한 학습 속도를 5배 빠르게 할 수 있음,\n",
    "\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=2,  # 각 디바이스당 훈련 배치 크기\n",
    "        gradient_accumulation_steps=4,\n",
    "        # gradient_accumulation_steps=2,  # 그래디언트 누적 단계\n",
    "        warmup_steps=5,  # 웜업 스텝 수\n",
    "        num_train_epochs=3,  # 훈련 에폭 수\n",
    "        max_steps=38,  # 최대 스텝 수\n",
    "        do_eval=True,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        logging_steps=1,  # logging 스텝 수\n",
    "        learning_rate=2e-4,  # 학습률\n",
    "        fp16=not torch.cuda.is_bf16_supported(),  # fp16 사용 여부, bf16이 지원되지 않는 경우에만 사용\n",
    "        bf16=torch.cuda.is_bf16_supported(),  # bf16 사용 여부, bf16이 지원되는 경우에만 사용\n",
    "        optim=\"adamw_8bit\",  # 최적화 알고리즘\n",
    "        weight_decay=0.01,  # 가중치 감소\n",
    "        lr_scheduler_type=\"cosine\",  # 학습률 스케줄러 유형\n",
    "        seed=123,  # 랜덤 시드\n",
    "        output_dir=\"outputs\",  # 출력 디렉토리\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA A10. Max memory = 21.988 GB.\n",
      "5.781 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "# 현재 메모리 상태를 보여주는 코드\n",
    "gpu_stats = torch.cuda.get_device_properties(0)  # GPU 속성 가져오기\n",
    "start_gpu_memory = round(\n",
    "    torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3\n",
    ")  # 시작 시 예약된 GPU 메모리 계산\n",
    "max_memory = round(\n",
    "    gpu_stats.total_memory / 1024 / 1024 / 1024, 3\n",
    ")  # GPU의 최대 메모리 계산\n",
    "print(\n",
    "    f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\"\n",
    ")  # GPU 이름과 최대 메모리 출력\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")  # 예약된 메모리 양 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 10,940 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 38\n",
      " \"-____-\"     Number of trainable parameters = 83,886,080\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 9:28:49, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.533100</td>\n",
       "      <td>3.544315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.425000</td>\n",
       "      <td>3.486726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.373600</td>\n",
       "      <td>3.183954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.178400</td>\n",
       "      <td>2.787812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.747700</td>\n",
       "      <td>2.456101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.474500</td>\n",
       "      <td>2.088660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.207700</td>\n",
       "      <td>1.770539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.524500</td>\n",
       "      <td>1.578229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.361100</td>\n",
       "      <td>1.503049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.304900</td>\n",
       "      <td>1.440570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.386700</td>\n",
       "      <td>1.394267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.124900</td>\n",
       "      <td>1.330091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.363600</td>\n",
       "      <td>1.292368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.301500</td>\n",
       "      <td>1.255865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.119000</td>\n",
       "      <td>1.232563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.199300</td>\n",
       "      <td>1.204866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.118900</td>\n",
       "      <td>1.172677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.076400</td>\n",
       "      <td>1.152578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.019300</td>\n",
       "      <td>1.150680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.181800</td>\n",
       "      <td>1.136062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.310400</td>\n",
       "      <td>1.114020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.988600</td>\n",
       "      <td>1.097485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.210600</td>\n",
       "      <td>1.086179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.968200</td>\n",
       "      <td>1.077115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.916300</td>\n",
       "      <td>1.068567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.264500</td>\n",
       "      <td>1.060168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.912200</td>\n",
       "      <td>1.053435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.166400</td>\n",
       "      <td>1.048616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.044400</td>\n",
       "      <td>1.044908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.230800</td>\n",
       "      <td>1.041666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>1.038719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.963600</td>\n",
       "      <td>1.035910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1.033671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.162800</td>\n",
       "      <td>1.031687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.108100</td>\n",
       "      <td>1.030358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.768300</td>\n",
       "      <td>1.029529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.326200</td>\n",
       "      <td>1.029125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.880800</td>\n",
       "      <td>1.029055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()  # 모델을 훈련시키고 통계를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34133.3211 seconds used for training.\n",
      "568.89 minutes used for training.\n",
      "Peak reserved memory = 9.615 GB.\n",
      "Peak reserved memory for training = 3.834 GB.\n",
      "Peak reserved memory % of max memory = 43.728 %.\n",
      "Peak reserved memory for training % of max memory = 17.437 %.\n"
     ]
    }
   ],
   "source": [
    "# 최종 메모리 및 시간 통계를 보여줍니다.\n",
    "used_memory = round(\n",
    "    torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3\n",
    ")  # 사용된 최대 메모리를 GB 단위로 계산합니다.\n",
    "used_memory_for_lora = round(\n",
    "    used_memory - start_gpu_memory, 3\n",
    ")  # LoRA를 위해 사용된 메모리를 GB 단위로 계산합니다.\n",
    "used_percentage = round(\n",
    "    used_memory / max_memory * 100, 3\n",
    ")  # 최대 메모리 대비 사용된 메모리의 비율을 계산합니다.\n",
    "lora_percentage = round(\n",
    "    used_memory_for_lora / max_memory * 100, 3\n",
    ")  # 최대 메모리 대비 LoRA를 위해 사용된 메모리의 비율을 계산합니다.\n",
    "print(\n",
    "    f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\"\n",
    ")  # 훈련에 사용된 시간을 초 단위로 출력합니다.\n",
    "print(\n",
    "    # 훈련에 사용된 시간을 분 단위로 출력합니다.\n",
    "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
    ")\n",
    "print(\n",
    "    f\"Peak reserved memory = {used_memory} GB.\"\n",
    ")  # 예약된 최대 메모리를 GB 단위로 출력합니다.\n",
    "print(\n",
    "    f\"Peak reserved memory for training = {used_memory_for_lora} GB.\"\n",
    ")  # 훈련을 위해 예약된 최대 메모리를 GB 단위로 출력합니다.\n",
    "print(\n",
    "    f\"Peak reserved memory % of max memory = {used_percentage} %.\"\n",
    ")  # 최대 메모리 대비 예약된 메모리의 비율을 출력합니다.\n",
    "print(\n",
    "    f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\"\n",
    ")  # 최대 메모리 대비 훈련을 위해 예약된 메모리의 비율을 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"beomi/Llama-3-Open-Ko-8B-Instruct-preview\" # 병합을 수행할 베이스 모델\n",
    "huggingface_token = \"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\"  # HuggingFace 토큰\n",
    "huggingface_repo = \"Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38\"  # 모델을 업로드할 repository\n",
    "save_method = (\n",
    "    \"merged_16bit\"  # \"merged_4bit\", \"merged_4bit_forced\", \"merged_16bit\", \"lora\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 365.44 out of 503.13 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 22/32 [00:00<00:00, 31.23it/s]We will save to Disk and not RAM now.\n",
      "100%|██████████| 32/32 [00:05<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving to organization with address passionMan/Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38\n",
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
      "Unsloth: Saving to organization with address passionMan/Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38\n",
      "Unsloth: Uploading all files... Please wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 2.18M/4.98G [00:00<07:04, 11.7MB/s]\n",
      "model-00001-of-00004.safetensors:   0%|          | 3.39M/4.98G [00:00<09:01, 9.19MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 4.75M/4.98G [00:00<15:11, 5.45MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 8.40M/4.98G [00:01<08:51, 9.35MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 11.6M/4.98G [00:01<06:41, 12.4MB/s]\n",
      "model-00001-of-00004.safetensors:   0%|          | 14.4M/4.98G [00:01<05:12, 15.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 24.7M/4.98G [00:01<04:33, 18.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 32.0M/4.98G [00:02<04:44, 17.4MB/s]\n",
      "model-00001-of-00004.safetensors:   1%|          | 38.1M/4.98G [00:02<03:34, 23.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|          | 42.1M/4.98G [00:03<05:47, 14.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 45.0M/4.98G [00:03<06:02, 13.6MB/s]\n",
      "model-00001-of-00004.safetensors:   1%|          | 47.4M/4.98G [00:03<05:59, 13.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|          | 49.5M/4.98G [00:04<09:13, 8.90MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 54.7M/4.98G [00:04<06:35, 12.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 58.0M/4.98G [00:04<06:00, 13.7MB/s]\n",
      "model-00001-of-00004.safetensors:   1%|          | 60.0M/4.98G [00:04<08:58, 9.14MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 61.5M/4.98G [00:05<08:36, 9.51MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 76.5M/4.98G [00:05<04:48, 17.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 80.9M/4.98G [00:06<05:13, 15.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 99.2M/4.98G [00:06<03:40, 22.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 104M/4.98G [00:07<03:34, 22.7MB/s] \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 107M/4.98G [00:07<05:40, 14.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 110M/4.98G [00:07<05:36, 14.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 113M/4.98G [00:08<09:17, 8.73MB/s]\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 122M/4.98G [00:08<05:13, 15.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 128M/4.98G [00:09<05:14, 15.4MB/s]\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 133M/4.98G [00:09<04:16, 18.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 137M/4.98G [00:09<04:04, 19.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 143M/4.98G [00:10<06:09, 13.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 158M/4.98G [00:11<04:41, 17.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 164M/4.98G [00:11<04:59, 16.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 168M/4.98G [00:11<04:29, 17.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 174M/4.98G [00:12<06:47, 11.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▎         | 176M/4.98G [00:13<11:03, 7.24MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 189M/4.98G [00:13<04:45, 16.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 204M/4.98G [00:14<03:21, 23.6MB/s]\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 209M/4.98G [00:14<03:50, 20.7MB/s]\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 215M/4.98G [00:14<03:25, 23.2MB/s]\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 219M/4.98G [00:15<05:09, 15.4MB/s]\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 222M/4.98G [00:15<05:11, 15.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|▍         | 225M/4.98G [00:16<08:33, 9.26MB/s]\n",
      "model-00001-of-00004.safetensors:   5%|▍         | 235M/4.98G [00:16<04:34, 17.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▌         | 252M/4.98G [00:16<02:55, 26.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▌         | 268M/4.98G [00:17<02:49, 27.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 294M/4.98G [00:18<02:43, 28.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 303M/4.98G [00:18<02:10, 35.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 309M/4.98G [00:18<02:51, 27.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▋         | 318M/4.98G [00:18<02:10, 35.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 335M/4.98G [00:19<02:10, 35.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 341M/4.98G [00:19<02:39, 29.1MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 348M/4.98G [00:19<02:21, 32.7MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 364M/4.98G [00:24<09:17, 8.28MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 384M/4.98G [00:24<04:53, 15.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 391M/4.98G [00:25<04:55, 15.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 396M/4.98G [00:25<04:08, 18.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 402M/4.98G [00:25<04:30, 16.9MB/s]\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 408M/4.98G [00:25<03:41, 20.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 413M/4.98G [00:25<03:14, 23.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   9%|▊         | 426M/4.98G [00:26<02:42, 28.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 443M/4.98G [00:26<02:18, 32.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 458M/4.98G [00:27<02:29, 30.2MB/s]\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 464M/4.98G [00:27<02:16, 33.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 469M/4.98G [00:27<02:55, 25.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 475M/4.98G [00:27<02:25, 30.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 492M/4.98G [00:28<02:04, 36.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|█         | 498M/4.98G [00:29<03:42, 20.1MB/s]\n",
      "model-00001-of-00004.safetensors:  10%|█         | 505M/4.98G [00:29<03:01, 24.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|█         | 511M/4.98G [00:29<02:31, 29.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|█         | 516M/4.98G [00:29<03:02, 24.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|█         | 522M/4.98G [00:29<02:37, 28.3MB/s]\n",
      "model-00001-of-00004.safetensors:  11%|█         | 538M/4.98G [00:30<02:20, 31.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|█         | 544M/4.98G [00:30<03:09, 23.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 550M/4.98G [00:30<02:54, 25.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 555M/4.98G [00:32<06:38, 11.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 557M/4.98G [00:32<06:23, 11.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|█         | 560M/4.98G [00:32<06:12, 11.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█▏        | 562M/4.98G [00:33<09:56, 7.40MB/s]\n",
      "model-00001-of-00004.safetensors:  11%|█▏        | 568M/4.98G [00:33<06:12, 11.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 575M/4.98G [00:33<04:15, 17.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 578M/4.98G [00:33<05:13, 14.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 588M/4.98G [00:34<03:08, 23.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 593M/4.98G [00:34<03:49, 19.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 603M/4.98G [00:34<02:29, 29.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 609M/4.98G [00:34<03:07, 23.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 616M/4.98G [00:35<02:25, 30.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 622M/4.98G [00:35<02:11, 33.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 627M/4.98G [00:36<06:31, 11.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 632M/4.98G [00:36<05:14, 13.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 637M/4.98G [00:36<04:13, 17.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 650M/4.98G [00:37<03:15, 22.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 655M/4.98G [00:37<02:47, 25.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 670M/4.98G [00:37<02:19, 30.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▎        | 675M/4.98G [00:38<03:08, 22.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 687M/4.98G [00:38<02:02, 35.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 693M/4.98G [00:38<02:49, 25.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 702M/4.98G [00:38<02:06, 33.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 714M/4.98G [00:39<02:20, 30.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 720M/4.98G [00:39<03:05, 23.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 734M/4.98G [00:40<02:01, 35.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 740M/4.98G [00:40<02:51, 24.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 746M/4.98G [00:40<02:28, 28.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 752M/4.98G [00:41<03:06, 22.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 765M/4.98G [00:41<01:54, 36.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 778M/4.98G [00:41<02:08, 32.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 783M/4.98G [00:41<01:58, 35.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 794M/4.98G [00:42<02:20, 29.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 800M/4.98G [00:42<02:57, 23.5MB/s]\n",
      "model-00001-of-00004.safetensors:  16%|█▋        | 813M/4.98G [00:42<02:08, 32.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▋        | 817M/4.98G [00:43<03:03, 22.7MB/s]\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 829M/4.98G [00:43<02:05, 33.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 847M/4.98G [00:44<02:08, 32.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 857M/4.98G [00:44<02:36, 26.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 864M/4.98G [00:44<02:03, 33.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 868M/4.98G [00:45<03:03, 22.4MB/s]\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 874M/4.98G [00:45<02:27, 27.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 880M/4.98G [00:45<03:00, 22.7MB/s]\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 890M/4.98G [00:45<02:05, 32.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 896M/4.98G [00:46<02:45, 24.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 906M/4.98G [00:46<01:58, 34.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 911M/4.98G [00:46<01:50, 36.7MB/s]\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 916M/4.98G [00:46<02:34, 26.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▊        | 926M/4.98G [00:46<01:52, 36.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  19%|█▊        | 932M/4.98G [00:47<02:37, 25.7MB/s]\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 938M/4.98G [00:47<02:12, 30.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 944M/4.98G [00:47<02:59, 22.5MB/s]\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 959M/4.98G [00:48<01:55, 34.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 970M/4.98G [00:48<02:19, 28.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|█▉        | 975M/4.98G [00:48<02:03, 32.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|█▉        | 988M/4.98G [00:49<02:12, 30.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|█▉        | 992M/4.98G [00:49<02:59, 22.2MB/s]\n",
      "model-00001-of-00004.safetensors:  20%|██        | 1.00G/4.98G [00:49<02:20, 28.3MB/s]\n",
      "model-00001-of-00004.safetensors:  20%|██        | 1.00G/4.98G [00:49<02:11, 30.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|██        | 1.01G/4.98G [00:50<03:20, 19.8MB/s]\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.02G/4.98G [00:50<02:00, 32.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.03G/4.98G [00:51<02:20, 28.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.04G/4.98G [00:51<03:57, 16.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.05G/4.98G [00:51<02:58, 22.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.05G/4.98G [00:51<02:35, 25.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██▏       | 1.07G/4.98G [00:52<02:09, 30.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.08G/4.98G [00:53<02:03, 31.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.09G/4.98G [00:53<02:45, 23.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.10G/4.98G [00:53<02:12, 29.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.10G/4.98G [00:53<02:04, 31.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.10G/4.98G [00:54<02:44, 23.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.12G/4.98G [00:54<01:46, 36.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.12G/4.98G [00:54<02:26, 26.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.13G/4.98G [00:54<01:58, 32.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.14G/4.98G [00:54<01:50, 34.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.14G/4.98G [00:55<02:47, 22.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.15G/4.98G [00:55<02:17, 27.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.15G/4.98G [00:55<01:57, 32.7MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.16G/4.98G [00:59<15:37, 4.07MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.16G/4.98G [00:59<11:27, 5.55MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.17G/4.98G [00:59<08:42, 7.30MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  24%|██▎       | 1.18G/4.98G [01:00<05:22, 11.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  24%|██▎       | 1.18G/4.98G [01:00<04:08, 15.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.20G/4.98G [01:00<02:53, 21.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.21G/4.98G [01:01<02:18, 27.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|██▍       | 1.23G/4.98G [01:01<01:55, 32.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|██▍       | 1.24G/4.98G [01:02<02:00, 31.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|██▌       | 1.26G/4.98G [01:03<01:47, 34.7MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.27G/4.98G [01:03<02:09, 28.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.28G/4.98G [01:03<02:03, 30.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.29G/4.98G [01:04<02:22, 25.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.29G/4.98G [01:04<02:05, 29.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  26%|██▋       | 1.31G/4.98G [01:04<02:03, 29.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  26%|██▋       | 1.31G/4.98G [01:05<03:10, 19.3MB/s]\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.32G/4.98G [01:05<01:55, 31.7MB/s]\n",
      "model-00004-of-00004.safetensors: 100%|██████████| 1.17G/1.17G [01:05<00:00, 17.8MB/s]\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.34G/4.98G [01:06<01:44, 34.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.36G/4.98G [01:06<01:52, 32.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.39G/4.98G [01:07<01:50, 32.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.39G/4.98G [01:08<02:22, 25.1MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.41G/4.98G [01:08<01:39, 35.9MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.41G/4.98G [01:08<02:10, 27.3MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.42G/4.98G [01:08<01:45, 33.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  30%|██▉       | 1.47G/4.98G [01:10<01:50, 31.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  30%|██▉       | 1.48G/4.98G [01:10<02:11, 26.6MB/s]\n",
      "model-00001-of-00004.safetensors:  30%|██▉       | 1.49G/4.98G [01:11<02:02, 28.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  30%|███       | 1.50G/4.98G [01:11<02:04, 28.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  30%|███       | 1.52G/4.98G [01:12<01:54, 30.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.53G/4.98G [01:12<01:41, 34.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.55G/4.98G [01:13<01:35, 35.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  31%|███▏      | 1.56G/4.98G [01:13<02:03, 27.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.58G/4.98G [01:14<01:28, 38.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.60G/4.98G [01:14<01:27, 38.7MB/s]\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.61G/4.98G [01:15<01:53, 29.7MB/s]\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.61G/4.98G [01:15<01:43, 32.6MB/s]\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.70G/4.98G [01:17<01:23, 39.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.71G/4.98G [01:18<01:39, 33.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  35%|███▍      | 1.73G/4.98G [01:19<01:25, 37.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  35%|███▍      | 1.73G/4.98G [01:19<01:57, 27.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  35%|███▌      | 1.75G/4.98G [01:20<01:42, 31.5MB/s]\n",
      "model-00001-of-00004.safetensors:  35%|███▌      | 1.76G/4.98G [01:20<01:33, 34.4MB/s]\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.77G/4.98G [01:20<01:36, 33.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.79G/4.98G [01:21<01:41, 31.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  36%|███▋      | 1.81G/4.98G [01:21<01:22, 38.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.82G/4.98G [01:22<01:44, 30.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.82G/4.98G [01:22<02:22, 22.1MB/s]\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.83G/4.98G [01:22<01:47, 29.2MB/s]\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.84G/4.98G [01:22<01:31, 34.3MB/s]\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.85G/4.98G [01:23<01:39, 31.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.87G/4.98G [01:23<01:31, 34.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.88G/4.98G [01:24<01:28, 34.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.89G/4.98G [01:24<01:48, 28.6MB/s]\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.90G/4.98G [01:25<01:17, 39.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.91G/4.98G [01:25<01:50, 27.8MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|███▊      | 1.92G/4.98G [01:25<01:27, 35.0MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|███▊      | 1.92G/4.98G [01:25<01:56, 26.2MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.93G/4.98G [01:26<01:38, 30.9MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.93G/4.98G [01:26<01:28, 34.5MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.94G/4.98G [01:26<02:01, 25.0MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.95G/4.98G [01:26<01:33, 32.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.96G/4.98G [01:27<01:39, 30.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  40%|███▉      | 1.98G/4.98G [01:27<01:38, 30.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  40%|████      | 2.00G/4.98G [01:28<01:15, 39.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  40%|████      | 2.01G/4.98G [01:28<01:18, 37.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.03G/4.98G [01:29<01:20, 36.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.05G/4.98G [01:30<02:09, 22.7MB/s]\n",
      "model-00001-of-00004.safetensors:  41%|████▏     | 2.06G/4.98G [01:30<01:35, 30.7MB/s]\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.07G/4.98G [01:30<01:48, 26.9MB/s]\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.08G/4.98G [01:30<01:23, 34.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.08G/4.98G [01:31<02:10, 22.1MB/s]\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.09G/4.98G [01:31<01:21, 35.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.11G/4.98G [01:32<02:01, 23.7MB/s]\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.11G/4.98G [01:32<01:48, 26.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.13G/4.98G [01:33<01:45, 26.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.13G/4.98G [01:33<02:13, 21.2MB/s]\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.14G/4.98G [01:33<01:50, 25.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.16G/4.98G [01:34<01:32, 30.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  44%|████▎     | 2.17G/4.98G [01:34<01:22, 34.0MB/s]\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.18G/4.98G [01:35<01:49, 25.6MB/s]\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.18G/4.98G [01:35<01:42, 27.2MB/s]\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.19G/4.98G [01:35<01:35, 29.3MB/s]\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.19G/4.98G [01:35<02:27, 18.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.20G/4.98G [01:36<01:38, 28.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.21G/4.98G [01:36<03:19, 13.9MB/s]\n",
      "model-00001-of-00004.safetensors:  45%|████▍     | 2.22G/4.98G [01:37<01:47, 25.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  45%|████▍     | 2.24G/4.98G [01:37<01:21, 33.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  45%|████▌     | 2.26G/4.98G [01:38<01:15, 36.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  45%|████▌     | 2.26G/4.98G [01:38<01:46, 25.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.28G/4.98G [01:39<01:24, 32.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  46%|████▋     | 2.30G/4.98G [01:39<01:13, 36.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  46%|████▋     | 2.31G/4.98G [01:40<01:31, 29.2MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.32G/4.98G [01:40<01:21, 32.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.33G/4.98G [01:40<01:17, 34.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.35G/4.98G [01:41<01:17, 34.2MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.35G/4.98G [01:41<01:30, 29.1MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.36G/4.98G [01:41<01:13, 35.7MB/s]\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.37G/4.98G [01:42<01:23, 31.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.38G/4.98G [01:42<01:11, 36.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.39G/4.98G [01:42<01:45, 24.6MB/s]\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.40G/4.98G [01:42<01:15, 34.1MB/s]\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.40G/4.98G [01:43<01:47, 24.0MB/s]\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.41G/4.98G [01:43<01:29, 28.8MB/s]\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.41G/4.98G [01:43<01:25, 30.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  49%|████▊     | 2.42G/4.98G [01:44<02:35, 16.5MB/s]\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.43G/4.98G [01:44<01:42, 24.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.44G/4.98G [01:44<01:47, 23.6MB/s]\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.44G/4.98G [01:45<01:30, 28.1MB/s]\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.46G/4.98G [01:45<01:23, 30.0MB/s]\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.46G/4.98G [01:45<01:17, 32.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  50%|████▉     | 2.47G/4.98G [01:46<01:53, 22.2MB/s]\n",
      "model-00001-of-00004.safetensors:  50%|████▉     | 2.47G/4.98G [01:46<01:33, 26.8MB/s]\n",
      "model-00001-of-00004.safetensors:  50%|████▉     | 2.48G/4.98G [01:46<01:21, 30.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  50%|█████     | 2.49G/4.98G [01:46<01:40, 24.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  50%|█████     | 2.50G/4.98G [01:47<01:59, 20.7MB/s]\n",
      "model-00001-of-00004.safetensors:  50%|█████     | 2.50G/4.98G [01:47<01:26, 28.6MB/s]\n",
      "model-00001-of-00004.safetensors:  50%|█████     | 2.51G/4.98G [01:47<01:38, 25.1MB/s]\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.53G/4.98G [01:48<01:04, 37.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.53G/4.98G [01:48<01:57, 20.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.54G/4.98G [01:49<02:28, 16.4MB/s]\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.54G/4.98G [01:49<02:53, 14.1MB/s]\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.54G/4.98G [01:49<02:55, 13.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.54G/4.98G [01:50<04:37, 8.76MB/s]\n",
      "model-00001-of-00004.safetensors:  51%|█████▏    | 2.55G/4.98G [01:50<02:47, 14.5MB/s]\n",
      "model-00001-of-00004.safetensors:  51%|█████▏    | 2.56G/4.98G [01:50<02:25, 16.7MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.56G/4.98G [01:50<02:28, 16.3MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.57G/4.98G [01:51<01:45, 22.8MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.57G/4.98G [01:51<01:30, 26.6MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.59G/4.98G [01:51<01:31, 26.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.60G/4.98G [01:52<01:29, 26.6MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.61G/4.98G [01:52<01:19, 29.7MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.61G/4.98G [01:52<01:43, 22.8MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.62G/4.98G [01:52<01:27, 27.1MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.63G/4.98G [01:53<01:51, 21.0MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.63G/4.98G [01:53<01:20, 29.1MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.64G/4.98G [01:53<01:10, 33.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.64G/4.98G [01:53<01:40, 23.2MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.65G/4.98G [01:54<01:10, 33.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  54%|█████▎    | 2.66G/4.98G [01:54<01:13, 31.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.68G/4.98G [01:55<01:01, 37.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.70G/4.98G [01:55<01:04, 35.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  55%|█████▍    | 2.71G/4.98G [01:56<01:11, 31.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  55%|█████▍    | 2.73G/4.98G [01:56<01:26, 26.1MB/s]\n",
      "model-00001-of-00004.safetensors:  55%|█████▍    | 2.73G/4.98G [01:56<01:12, 31.0MB/s]\n",
      "model-00001-of-00004.safetensors:  55%|█████▌    | 2.75G/4.98G [01:57<01:06, 33.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.77G/4.98G [01:57<00:57, 38.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.78G/4.98G [01:58<01:00, 36.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.80G/4.98G [01:59<01:13, 29.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|█████▋    | 2.80G/4.98G [01:59<01:56, 18.7MB/s]\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.81G/4.98G [02:00<01:25, 25.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.83G/4.98G [02:00<01:14, 28.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.85G/4.98G [02:01<01:01, 34.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.91G/4.98G [02:03<01:05, 31.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.93G/4.98G [02:03<00:59, 34.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.94G/4.98G [02:04<00:56, 35.9MB/s]\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.96G/4.98G [02:04<00:53, 37.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  60%|█████▉    | 2.97G/4.98G [02:05<01:12, 27.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  60%|██████    | 2.99G/4.98G [02:05<00:53, 37.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  60%|██████    | 3.01G/4.98G [02:06<01:01, 31.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.02G/4.98G [02:07<01:19, 24.7MB/s]\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.02G/4.98G [02:07<01:07, 29.1MB/s]\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.03G/4.98G [02:07<01:30, 21.5MB/s]\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.03G/4.98G [02:07<01:12, 26.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  61%|██████▏   | 3.05G/4.98G [02:08<00:58, 33.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.07G/4.98G [02:08<00:53, 35.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.08G/4.98G [02:09<00:48, 39.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.10G/4.98G [02:10<00:59, 31.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.12G/4.98G [02:10<00:50, 36.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.13G/4.98G [02:10<01:00, 30.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.15G/4.98G [02:11<00:56, 32.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.16G/4.98G [02:12<00:57, 31.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.18G/4.98G [02:12<00:49, 36.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.19G/4.98G [02:13<00:59, 29.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  65%|██████▍   | 3.22G/4.98G [02:13<00:48, 36.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  65%|██████▍   | 3.23G/4.98G [02:14<00:50, 34.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  65%|██████▌   | 3.25G/4.98G [02:14<00:44, 39.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.26G/4.98G [02:15<00:48, 35.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.27G/4.98G [02:15<00:49, 34.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.29G/4.98G [02:16<00:46, 36.3MB/s]\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.30G/4.98G [02:16<01:01, 27.3MB/s]\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.31G/4.98G [02:16<00:43, 38.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  70%|███████   | 3.49G/4.98G [02:22<00:37, 39.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  70%|███████   | 3.49G/4.98G [02:23<00:46, 32.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.51G/4.98G [02:23<00:42, 34.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.53G/4.98G [02:24<00:43, 33.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  71%|███████▏  | 3.55G/4.98G [02:24<00:41, 34.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.56G/4.98G [02:25<00:37, 37.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.57G/4.98G [02:25<00:49, 28.4MB/s]\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.58G/4.98G [02:25<00:38, 36.2MB/s]\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.60G/4.98G [02:26<00:34, 39.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.61G/4.98G [02:26<00:49, 27.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.63G/4.98G [02:27<00:35, 38.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.64G/4.98G [02:27<00:44, 30.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.67G/4.98G [02:28<00:43, 29.9MB/s]\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.69G/4.98G [02:29<00:33, 38.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.70G/4.98G [02:29<00:42, 30.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  75%|███████▍  | 3.73G/4.98G [02:30<00:31, 39.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  75%|███████▌  | 3.73G/4.98G [02:30<00:38, 31.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.76G/4.98G [02:31<00:32, 37.6MB/s]\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.76G/4.98G [02:31<00:36, 33.1MB/s]\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.77G/4.98G [02:31<00:33, 36.5MB/s]\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.79G/4.98G [02:32<00:32, 36.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  76%|███████▋  | 3.81G/4.98G [02:32<00:27, 42.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.81G/4.98G [02:33<00:38, 29.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.83G/4.98G [02:33<00:33, 33.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.85G/4.98G [02:34<00:30, 36.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.87G/4.98G [02:34<00:28, 39.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.89G/4.98G [02:35<00:30, 35.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.90G/4.98G [02:36<00:33, 31.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.90G/4.98G [02:36<00:49, 21.6MB/s]\n",
      "model-00001-of-00004.safetensors:  79%|███████▊  | 3.92G/4.98G [02:36<00:31, 33.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  79%|███████▉  | 3.94G/4.98G [02:37<00:27, 38.6MB/s]\n",
      "model-00001-of-00004.safetensors:  79%|███████▉  | 3.94G/4.98G [02:37<00:35, 29.4MB/s]\n",
      "model-00001-of-00004.safetensors:  79%|███████▉  | 3.95G/4.98G [02:37<00:31, 32.2MB/s]\n",
      "model-00001-of-00004.safetensors:  80%|███████▉  | 3.96G/4.98G [02:38<00:30, 33.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  80%|███████▉  | 3.97G/4.98G [02:38<00:45, 22.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  80%|███████▉  | 3.98G/4.98G [02:38<00:32, 30.8MB/s]\n",
      "model-00001-of-00004.safetensors:  80%|████████  | 4.00G/4.98G [02:39<00:25, 38.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  80%|████████  | 4.01G/4.98G [02:39<00:32, 30.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 4.02G/4.98G [02:40<00:28, 33.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 4.04G/4.98G [02:40<00:27, 34.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.06G/4.98G [02:41<00:26, 34.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.07G/4.98G [02:41<00:25, 35.6MB/s]\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.09G/4.98G [02:42<00:23, 38.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.11G/4.98G [02:42<00:20, 42.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.12G/4.98G [02:43<00:36, 23.8MB/s]\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.12G/4.98G [02:43<00:32, 25.9MB/s]\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.15G/4.98G [02:44<00:24, 34.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.17G/4.98G [02:45<00:22, 35.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.19G/4.98G [02:45<00:24, 32.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.19G/4.98G [02:46<00:32, 24.2MB/s]\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.20G/4.98G [02:46<00:33, 23.1MB/s]\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.20G/4.98G [02:46<00:42, 18.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.20G/4.98G [02:47<01:10, 11.0MB/s]\n",
      "model-00001-of-00004.safetensors:  85%|████████▍ | 4.21G/4.98G [02:47<01:07, 11.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  85%|████████▍ | 4.21G/4.98G [02:48<01:47, 7.15MB/s]\n",
      "model-00001-of-00004.safetensors:  85%|████████▍ | 4.22G/4.98G [02:48<00:38, 19.3MB/s]\n",
      "model-00001-of-00004.safetensors:  85%|████████▍ | 4.23G/4.98G [02:49<00:44, 17.0MB/s]\n",
      "model-00001-of-00004.safetensors:  85%|████████▌ | 4.23G/4.98G [02:49<00:31, 23.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  85%|████████▌ | 4.24G/4.98G [02:49<00:40, 18.0MB/s]\n",
      "model-00001-of-00004.safetensors:  85%|████████▌ | 4.25G/4.98G [02:49<00:27, 26.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.27G/4.98G [02:50<00:22, 31.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.29G/4.98G [02:51<00:20, 33.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  86%|████████▋ | 4.30G/4.98G [02:51<00:20, 33.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.31G/4.98G [02:52<00:22, 29.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.34G/4.98G [02:52<00:18, 35.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.35G/4.98G [02:53<00:19, 32.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.35G/4.98G [02:53<00:27, 22.4MB/s]\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.37G/4.98G [02:54<00:24, 25.2MB/s]\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.38G/4.98G [02:54<00:17, 33.6MB/s]\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.38G/4.98G [02:54<00:16, 36.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.39G/4.98G [02:54<00:22, 25.8MB/s]\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.39G/4.98G [02:54<00:19, 29.5MB/s]\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.40G/4.98G [02:54<00:16, 35.1MB/s]\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.40G/4.98G [02:55<00:23, 24.2MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|████████▊ | 4.41G/4.98G [02:55<00:19, 28.8MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|████████▊ | 4.41G/4.98G [02:55<00:17, 32.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  89%|████████▉ | 4.42G/4.98G [02:56<00:29, 19.1MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|████████▉ | 4.43G/4.98G [02:56<00:17, 31.9MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|████████▉ | 4.44G/4.98G [02:56<00:23, 23.3MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|████████▉ | 4.44G/4.98G [02:56<00:19, 28.0MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|████████▉ | 4.45G/4.98G [02:57<00:24, 22.0MB/s]\n",
      "model-00001-of-00004.safetensors:  90%|████████▉ | 4.46G/4.98G [02:57<00:16, 32.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  90%|████████▉ | 4.48G/4.98G [02:57<00:14, 34.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  90%|█████████ | 4.49G/4.98G [02:58<00:12, 38.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  91%|█████████ | 4.51G/4.98G [02:58<00:12, 36.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  91%|█████████ | 4.52G/4.98G [02:59<00:14, 31.4MB/s]\n",
      "model-00001-of-00004.safetensors:  91%|█████████ | 4.53G/4.98G [02:59<00:17, 25.9MB/s]\n",
      "model-00001-of-00004.safetensors:  91%|█████████ | 4.54G/4.98G [02:59<00:13, 32.8MB/s]\n",
      "model-00001-of-00004.safetensors:  91%|█████████▏| 4.54G/4.98G [02:59<00:11, 36.3MB/s]\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.56G/4.98G [03:00<00:11, 36.7MB/s]\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.56G/4.98G [03:00<00:15, 26.8MB/s]\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.59G/4.98G [03:01<00:09, 38.8MB/s]\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.60G/4.98G [03:01<00:13, 27.8MB/s]\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.60G/4.98G [03:02<00:14, 25.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.61G/4.98G [03:02<00:24, 15.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.62G/4.98G [03:03<00:25, 14.0MB/s]\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.62G/4.98G [03:04<00:24, 14.3MB/s]\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.63G/4.98G [03:04<00:16, 20.5MB/s]\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.64G/4.98G [03:04<00:13, 25.3MB/s]\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.64G/4.98G [03:04<00:15, 21.6MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|█████████▎| 4.66G/4.98G [03:05<00:14, 21.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  94%|█████████▎| 4.67G/4.98G [03:05<00:10, 30.7MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.67G/4.98G [03:05<00:09, 33.6MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.68G/4.98G [03:06<00:12, 23.7MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.68G/4.98G [03:06<00:10, 27.3MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.69G/4.98G [03:06<00:13, 21.0MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.70G/4.98G [03:06<00:09, 28.4MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.70G/4.98G [03:06<00:09, 30.5MB/s]\n",
      "model-00001-of-00004.safetensors:  95%|█████████▍| 4.71G/4.98G [03:07<00:14, 19.3MB/s]\n",
      "model-00001-of-00004.safetensors:  95%|█████████▍| 4.71G/4.98G [03:07<00:09, 27.1MB/s]\n",
      "model-00001-of-00004.safetensors:  95%|█████████▍| 4.72G/4.98G [03:07<00:08, 29.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  95%|█████████▍| 4.72G/4.98G [03:07<00:12, 20.7MB/s]\n",
      "model-00001-of-00004.safetensors:  95%|█████████▌| 4.73G/4.98G [03:08<00:08, 29.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  95%|█████████▌| 4.75G/4.98G [03:08<00:06, 34.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  96%|█████████▌| 4.77G/4.98G [03:09<00:08, 23.5MB/s]\n",
      "model-00001-of-00004.safetensors:  96%|█████████▌| 4.78G/4.98G [03:09<00:05, 35.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  96%|█████████▋| 4.80G/4.98G [03:10<00:05, 34.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.80G/4.98G [03:10<00:06, 27.5MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.82G/4.98G [03:11<00:06, 24.5MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.83G/4.98G [03:11<00:04, 34.4MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.83G/4.98G [03:11<00:04, 35.9MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.84G/4.98G [03:11<00:05, 25.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.84G/4.98G [03:12<00:04, 30.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  98%|█████████▊| 4.85G/4.98G [03:12<00:04, 26.2MB/s]\n",
      "model-00001-of-00004.safetensors:  98%|█████████▊| 4.86G/4.98G [03:12<00:04, 27.8MB/s]\n",
      "model-00001-of-00004.safetensors:  98%|█████████▊| 4.86G/4.98G [03:12<00:03, 29.6MB/s]\n",
      "model-00001-of-00004.safetensors:  98%|█████████▊| 4.87G/4.98G [03:13<00:04, 21.9MB/s]\n",
      "model-00001-of-00004.safetensors:  98%|█████████▊| 4.87G/4.98G [03:13<00:03, 26.8MB/s]\n",
      "model-00001-of-00004.safetensors:  98%|█████████▊| 4.88G/4.98G [03:13<00:03, 31.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  98%|█████████▊| 4.89G/4.98G [03:13<00:03, 28.7MB/s]\n",
      "model-00001-of-00004.safetensors:  98%|█████████▊| 4.90G/4.98G [03:14<00:03, 22.7MB/s]\n",
      "model-00001-of-00004.safetensors:  99%|█████████▊| 4.91G/4.98G [03:14<00:02, 31.8MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  99%|█████████▉| 4.92G/4.98G [03:15<00:04, 13.4MB/s]\n",
      "model-00001-of-00004.safetensors:  99%|█████████▉| 4.92G/4.98G [03:15<00:02, 21.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  99%|█████████▉| 4.94G/4.98G [03:16<00:01, 26.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors: 100%|█████████▉| 4.96G/4.98G [03:16<00:00, 33.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors: 100%|█████████▉| 4.97G/4.98G [03:17<00:00, 34.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors: 100%|██████████| 4.98G/4.98G [03:17<00:00, 25.2MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00003-of-00004.safetensors: 100%|██████████| 4.92G/4.92G [03:26<00:00, 23.8MB/s]\n",
      "model-00002-of-00004.safetensors: 100%|██████████| 5.00G/5.00G [03:32<00:00, 23.5MB/s]\n",
      "\n",
      "\n",
      "Upload 4 LFS files: 100%|██████████| 4/4 [03:32<00:00, 53.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Saved merged model to https://huggingface.co/None/Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38\n"
     ]
    }
   ],
   "source": [
    "# Hub 에 업로드\n",
    "model.push_to_hub_merged(\n",
    "    huggingface_repo,\n",
    "    tokenizer,\n",
    "    save_method=save_method,\n",
    "    token=huggingface_token,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model reload and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.43.3.\n",
      "   \\\\   /|    GPU: NVIDIA RTX A5000. Max memory: 23.677 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.1.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.22.post7+cu118. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 4096  # 최대 시퀀스 길이를 설정합니다. 내부적으로 RoPE 스케일링을 자동으로 지원합니다!\n",
    "# 자동 감지를 위해 None을 사용합니다. Tesla T4, V100은 Float16, Ampere+는 Bfloat16을 사용하세요.\n",
    "dtype = None\n",
    "# 메모리 사용량을 줄이기 위해 4bit 양자화를 사용합니다. False일 수도 있습니다.\n",
    "load_in_4bit = True\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    # model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n",
    "    model_name=\"/home/jaesung/jaesung/pulmuone/text-generation-webui/models/Llama-3-Open-Ko-8B-Instruct-PM1-completion-v2-60-gguf\",\n",
    "    max_seq_length=max_seq_length,  # 최대 시퀀스 길이를 설정합니다.\n",
    "    dtype=dtype,  # 데이터 타입을 설정합니다.\n",
    "    load_in_4bit=load_in_4bit,  # 4bit 양자화 로드 여부를 설정합니다.\n",
    "    # token = \"hf_...\", # 게이트된 모델을 사용하는 경우 토큰을 사용하세요. 예: meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# EOS_TOKEN은 문장의 끝을 나타내는 토큰입니다. 이 토큰을 추가해야 합니다.\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "# AlpacaPrompt를 사용하여 지시사항을 포맷팅하는 함수입니다.\n",
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "\n",
    "# 주어진 예시들을 포맷팅하는 함수입니다.\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"QUESTION\"]  # 지시사항을 가져옵니다.\n",
    "    outputs = examples[\"ANSWER\"]  # 출력값을 가져옵니다.\n",
    "    texts = []  # 포맷팅된 텍스트를 저장할 리스트입니다.\n",
    "    for instruction, output in zip(instructions, outputs):\n",
    "        # EOS_TOKEN을 추가해야 합니다. 그렇지 않으면 생성이 무한히 진행될 수 있습니다.\n",
    "        text = alpaca_prompt.format(instruction, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\n",
    "        \"text\": texts,  # 포맷팅된 텍스트를 반환합니다.\n",
    "    }\n",
    "\n",
    "# JSONL 파일 로드 함수\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data\n",
    "\n",
    "# JSONL 파일 경로\n",
    "file_path = '/home/jaesung/pulmuone/instruction_tuning_2/v4_completion/data/qa_pair_for_completion.jsonl'\n",
    "\n",
    "# JSONL 파일 로드\n",
    "data = load_jsonl(file_path)\n",
    "\n",
    "# pandas DataFrame으로 변환\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Dataset 객체로 변환\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# DatasetDict 객체로 결합\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 13676/13676 [00:00<00:00, 56412.33 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋에 formatting_prompts_func 함수를 적용합니다. 배치 처리를 활성화합니다.\n",
    "dataset = dataset.map(\n",
    "    formatting_prompts_func,\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "import string\n",
    "\n",
    "class StopOnToken(StoppingCriteria):\n",
    "    def __init__(self, stop_token_id):\n",
    "        self.stop_token_id = stop_token_id  # 정지 토큰 ID를 초기화합니다.\n",
    "\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        return (\n",
    "            self.stop_token_id in input_ids[0]\n",
    "        )  # 입력된 ID 중 정지 토큰 ID가 있으면 정지합니다.\n",
    "\n",
    "class StopOnRepetitionPattern(StoppingCriteria):\n",
    "    def __init__(self, repetition_limit=3, tokenizer=None):\n",
    "        self.repetition_limit = repetition_limit\n",
    "        self.repetition_count = {}\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def extract_comma_segment(self, text):\n",
    "        # 콤마로 분리된 구 중 마지막 구를 추출합니다.\n",
    "        segments = text.split(',')\n",
    "        return segments[-1].strip().lower()\n",
    "    \n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        # 현재까지 생성된 전체 텍스트를 디코딩합니다.\n",
    "        generated_text = self.tokenizer.decode(input_ids[0], skip_special_tokens=True).strip()\n",
    "        comma_segment = self.extract_comma_segment(generated_text)\n",
    "        \n",
    "        if not comma_segment:\n",
    "            return False\n",
    "        \n",
    "        # 마지막 구간에서 단어를 분리\n",
    "        words = comma_segment.split()\n",
    "        \n",
    "        if len(words) == 1:  # 마지막 구간에 단어가 하나만 있다면\n",
    "            word = words[0]\n",
    "            if word in self.repetition_count:\n",
    "                self.repetition_count[word] += 1\n",
    "            else:\n",
    "                self.repetition_count[word] = 1\n",
    "            \n",
    "            # 만약 특정 단어가 repetition_limit 이상 반복되면 생성을 중단합니다.\n",
    "            if self.repetition_count[word] >= self.repetition_limit:\n",
    "                return True\n",
    "        else:\n",
    "            # 다른 구간이 생성되면 카운트 초기화\n",
    "            self.repetition_count = {}\n",
    "        \n",
    "        return False\n",
    "    \n",
    "# end_token을 설정\n",
    "stop_token = \"<|end_of_text|>\"  # end_token으로 사용할 토큰을 설정합니다.\n",
    "stop_token_id = tokenizer.encode(stop_token, add_special_tokens=False)[\n",
    "    0\n",
    "]  # end_token의 ID를 인코딩합니다.\n",
    "\n",
    "# Stopping criteria 설정\n",
    "stopping_criteria = StoppingCriteriaList(\n",
    "    [StopOnToken(stop_token_id),\n",
    "    StopOnRepetitionPattern(repetition_limit=5, tokenizer=tokenizer)\n",
    "    ] # 동일한 단어가 3번 반복되면 정지합니다.\n",
    ")  # 정지 조건을 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QUESTION': {'input': '핵심 재료: \"\"\\n일반 재료: \"밀가루중력1등급, 양파분, 표고버섯분말\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"설탕, 옥수수전분, 정제소금, 흑후추분말\"',\n",
       "  'instruction': '복합조미식품 카테고리의 크림소스분말(내츄럴스푸드)에 사용되는 몇 가지 재료입니다. 누락된 재료를 찾아보세요.'},\n",
       " 'ANSWER': '체다치즈파우더, 크림베이스, 분말유크림, 말토덱스트린, 건조감자분말, 마늘분말',\n",
       " '__index_level_0__': 9955}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['test'][401]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"치킨텐더, 흰쌀베이스밥\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"물밤, 이든또띠아\"', 'instruction': '즉석조리식품가열섭취냉동식품 카테고리에 속하는 모짜렐라브리또(냉동)_스위트텐더의 일부 재료가 주어졌습니다. 나머지 식재료를 추측해보세요.'}\n",
      "\n",
      "### Response:\n",
      "치킨텐더, 흰쌀베이스밥, 모짜렐라치즈, 이든또띠아, 파프리카, 양파, 마늘, 정제수, 밀가루, 소맥전분, 정제소금, 백설탕, 정제수<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "# FastLanguageModel을 이용하여 추론 속도를 2배 빠르게 설정합니다.\n",
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "    [\n",
    "        alpaca_prompt.format(\n",
    "            dataset_dict['test'][10]['QUESTION'],\n",
    "\n",
    "           # {'instruction': '이 두부를 만들 때 사용할 몇 가지 재료가 이미 정해졌어. 여기에 어울릴 만한 다른 재료를 제안해줄 수 있니?', '제공된 재료': '대두', '카테고리': '두부'}, # 지시사항\n",
    "            \"\",  # 출력 - 생성을 위해 이 부분을 비워둡니다!\n",
    "        )\n",
    "    ],\n",
    "    return_tensors=\"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(\n",
    "    **inputs,\n",
    "    streamer=text_streamer,\n",
    "    max_new_tokens=4096,  # 최대 생성 토큰 수를 설정합니다.\n",
    "    stopping_criteria=stopping_criteria  # 생성을 멈출 기준을 설정합니다.\n",
    ")\n",
    "\n",
    "# output_list = tokenizer.batch_decode(_, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QUESTION': {'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"\"',\n",
       "  'instruction': '농산물 카테고리의 무농약국산콩새오리알콩나물_300g에 사용되는 몇 가지 재료입니다. 누락된 재료를 찾아보세요.'},\n",
       " 'ANSWER': '나물콩',\n",
       " '__index_level_0__': 3643}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['test'][70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['QUESTION', 'ANSWER', '__index_level_0__'],\n",
       "    num_rows: 2736\n",
       "})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"\"', 'instruction': '숙면 카테고리에 속하는 뽀모도로토마토파스타_190319의 일부 재료가 주어졌습니다. 나머지 식재료를 추측해보세요.'}\n",
      "\n",
      "### Response:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토마토, 파스타면, 마늘, 양파, 정제수, 올레오레진, 정제소금, 정제수<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"국산콩간장, 풀무원절단두부, 해찬들알찬고추장그린\"\\n일반 재료: \"아미노베이스\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"고춧가루, 대파, 돼지고기, 물엿, 백설탕, 생강, 정제수, 콩발효맛내기진, 홍고추\"', 'instruction': '소스류 카테고리의 이지쿡마파소스두부에 사용되는 몇 가지 재료입니다. 누락된 재료를 찾아보세요.'}\n",
      "\n",
      "### Response:\n",
      "두부, 마파두부, 정제소금, 정제수, 양조간장, 양파, 정제수<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"산도조절제, 알콘에쓰\"\\n매우 자주 등장하는 재료: \"d자일로오스, 고추, 난백액, 당면, 대두유, 마늘, 명태ra, 양파, 유산균배양액혼합분말, 전분가공품, 정백당, 정제염, 타이미, 함수결정포도당ng, 효모추출물혼합분말\"', 'instruction': '어묵 카테고리에 속하는 알래스칸특급맑은어묵전골의 일부 재료가 주어졌습니다. 나머지 식재료를 추측해보세요.'}\n",
      "\n",
      "### Response:\n",
      "어묵, 대두단백, 정제수, 정제소금, 정제수<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"클로렐라분말\"\\n매우 자주 등장하는 재료: \"\"', 'instruction': '곡류가공품 카테고리의 칼슘쏙쏙찹쌀클로렐라의 식재료의 일부입니다. 빠진 식재료를 맞추세요.'}\n",
      "\n",
      "### Response:\n",
      "쏙쏙찹쌀, 찹쌀<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"바지락조미엑기스\"\\n매우 자주 등장하는 재료: \"게추출농축액1호, 정제수\"', 'instruction': '육수 카테고리에 속하는 바지락육수의 레시피에서 몇 가지 재료가 제외되었습니다. 어떤 재료가 빠졌는지 맞춰보세요.'}\n",
      "\n",
      "### Response:\n",
      "바지락엑기스, 바지락추출농축액, 정제염, 정제수<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"맛내기베이스, 혼합조미분\"\\n공통 재료: \"올리브유\"\\n매우 자주 등장하는 재료: \"고추, 그레이티드파마산치즈, 바지락엑기스, 잔탄검, 타마린드검, 현미유, 후추가루\"', 'instruction': '소스류 카테고리의 바른선알리오올리오소스_180806의 식재료의 일부입니다. 빠진 식재료를 맞추세요.'}\n",
      "\n",
      "### Response:\n",
      "바른선알리오올리오소스_180806<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"볶음참깨분말\"\\n매우 자주 등장하는 재료: \"정제수\"', 'instruction': '소스류 카테고리의 쌀콩국물에 사용되는 몇 가지 재료입니다. 누락된 재료를 찾아보세요.'}\n",
      "\n",
      "### Response:\n",
      "콩나물국물<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"arconsb\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"잔탄검, 정제소금, 정제수, 화이바솔2l난소화성말토덱스트린\"', 'instruction': '즉석조리식품 카테고리에 속하는 잣죽의 일부 재료가 주어졌습니다. 나머지 식재료를 추측해보세요.'}\n",
      "\n",
      "### Response:\n",
      "잣, 정제수<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"볶은검은콩분말, 볶음검정깨분말\"\\n일반 재료: \"27종과야채혼합농축분말, 멀티비타민미네랄믹스, 분리유청단백질, 올리고당orafticrf\"\\n공통 재료: \"오트볼, 코코넛슈가\"\\n매우 자주 등장하는 재료: \"난소화성말토덱스트린, 효소처리스테비아\"', 'instruction': '체중조절식 카테고리에 속하는 포켓쉐이크-흑임자맛의 레시피에서 몇 가지 재료가 제외되었습니다. 어떤 재료가 빠졌는지 맞춰보세요.'}\n",
      "\n",
      "### Response:\n",
      "흑임자맛, 흑임자분말, 정제수, 정제염, 정제수<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"\"', 'instruction': '식육추출가공품 카테고리의 키즈THE뽀얀한우고기곰탕에 사용되는 몇 가지 재료입니다. 누락된 재료를 찾아보세요.'}\n",
      "\n",
      "### Response:\n",
      "한우곰탕, 돼지고기, 양파, 대파, 마늘, 생강, 정제수, 정제염, 백설탕, 정제소금, 정제수<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"\"', 'instruction': '포장육 카테고리에 속하는 무항생제한우의 일부 재료가 주어졌습니다. 나머지 식재료를 추측해보세요.'}\n",
      "\n",
      "### Response:\n",
      "한우등심, 한우갈비, 한우양지, 한우양지갈비, 양지갈비, 양지등심<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"벨로체다크림치즈\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"밀가루, 빵가루, 정제수\"', 'instruction': '기타가공품 카테고리에 속하는 체다크림치즈스틱의 일부 재료가 주어졌습니다. 나머지 식재료를 추측해보세요.'}\n",
      "\n",
      "### Response:\n",
      "체다크림치즈스틱<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"나가사끼시즈닝yw, 홍합엑기스분말에스\"\\n공통 재료: \"사골추출물15, 야채짬뽕베이스\"\\n매우 자주 등장하는 재료: \"설탕, 정제수, 치킨엑기스\"', 'instruction': '소스 카테고리의 풀스키친_나가사끼짬뽕소스의 식재료의 일부입니다. 빠진 식재료를 맞추세요.'}\n",
      "\n",
      "### Response:\n",
      "나가사끼시즈닝, 홍합엑기스분말, 풀스키친_나가사끼짬뽕소스<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"\"', 'instruction': '두부 카테고리에 속하는 소가찌개두부3kg의 레시피에서 몇 가지 재료가 제외되었습니다. 어떤 재료가 빠졌는지 맞춰보세요.'}\n",
      "\n",
      "### Response:\n",
      "소가찌개두부<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"\"', 'instruction': '신선편의식품 카테고리에 속하는 바른선자연담은청포도(특,1kg,냉장)수입산의 일부 재료가 주어졌습니다. 나머지 식재료를 추측해보세요.'}\n",
      "\n",
      "### Response:\n",
      "청포도<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"고춧가루, 난백액, 대두단백, 설탕, 소맥전분, 청양고추, 효모추출물혼합분말\"', 'instruction': '어묵 카테고리에 속하는 치즈인더어묵_핫스파이시의 레시피에서 몇 가지 재료가 제외되었습니다. 어떤 재료가 빠졌는지 맞춰보세요.'}\n",
      "\n",
      "### Response:\n",
      "치즈, 밀가루, 정제수, 정제염, 후추가루, 정제수<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"갈색설탕, 고추기름1, 발효농축액, 참기름, 파프리카추출색소, 혼합제제, 흑후추분말\"', 'instruction': '소스류 카테고리의 중식불맛소스(어묵볶음용소스)에 사용되는 몇 가지 재료입니다. 누락된 재료를 찾아보세요.'}\n",
      "\n",
      "### Response:\n",
      "어묵볶음용소스, 고추분말, 정제수, 정제소금, 설탕, 정제염, 정제수<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"아세로라농축과즙\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"열대혼합과일농축액, 정제수\"', 'instruction': '과채주스 카테고리에 속하는 아임샷파워C의 레시피에서 몇 가지 재료가 제외되었습니다. 어떤 재료가 빠졌는지 맞춰보세요.'}\n",
      "\n",
      "### Response:\n",
      "아임샷파워C<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"건조감자분말, 결정과당, 당근, 양파, 플레인소스, 혼합제제, 효모추출물\"', 'instruction': '즉석섭취식품 카테고리에 속하는 [푸드머스]감자샐러드FM의 일부 재료가 주어졌습니다. 나머지 식재료를 추측해보세요.'}\n",
      "\n",
      "### Response:\n",
      "감자, 생강, 정제수, 정제염, 설탕, 밀가루, 밀분해추출물<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"\"', 'instruction': '두부 카테고리에 속하는 소가크고단단한두부500g의 레시피에서 몇 가지 재료가 제외되었습니다. 어떤 재료가 빠졌는지 맞춰보세요.'}\n",
      "\n",
      "### Response:\n",
      "고구마전분, 대두단백, 정제수, 정제염<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"\"', 'instruction': '빙과 카테고리에 속하는 아이스큐브커피맛(매머드용)의 레시피에서 몇 가지 재료가 제외되었습니다. 어떤 재료가 빠졌는지 맞춰보세요.'}\n",
      "\n",
      "### Response:\n",
      "커피, 커피추출물, 커피농축액, 커�\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"\"', 'instruction': '과채주스 카테고리에 속하는 아임리얼유기농사과의 레시피에서 몇 가지 재료가 제외되었습니다. 어떤 재료가 빠졌는지 맞춰보세요.'}\n",
      "\n",
      "### Response:\n",
      "아임리얼유기농사과<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"산도조절제, 연육명태aa\"\\n매우 자주 등장하는 재료: \"d자일로오스, 고추, 당면, 대두유, 두부, 명태ra, 분리단백대두yx2001, 소맥전분, 양파, 전분가공품, 정백당, 정제염, 타이미, 함수결정포도당ng, 혼합제제\"', 'instruction': '어묵 카테고리의 알래스칸특급진한어묵전골에 사용되는 몇 가지 재료입니다. 누락된 재료를 찾아보세요.'}\n",
      "\n",
      "### Response:\n",
      "어묵, 대두, 정제수, 정제소금, 정제염, 정제수, 정\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"절임오이\"\\n매우 자주 등장하는 재료: \"구연산, 기타과당, 밀분해추출물, 정제소금, 정제수, 젖산칼슘, 효소처리스테비아\"', 'instruction': '절임류 카테고리에 속하는 바로절여꼬들꼬들한오이지무침의 일부 재료가 주어졌습니다. 나머지 식재료를 추측해보세요.'}\n",
      "\n",
      "### Response:\n",
      "꼬들꼬들한오이무침, 젖산칼슘, 정제소금<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"파프리카추출색소10만\"\\n공통 재료: \"숯불풍미액, 칠리오일r\"\\n매우 자주 등장하는 재료: \"고춧가루, 멀티롬파우더, 사골농축액, 설탕, 아미노베이스p, 오징어엑기스p, 정제수, 혼합야채엑기스, 흑후추분말\"', 'instruction': '소스류 카테고리에 속하는 진한양념의 일부 재료가 주어졌습니다. 나머지 식재료를 추측해보세요.'}\n",
      "\n",
      "### Response:\n",
      "진한양념, 양념분말, 양파, 양파농축액, 정제소금, 후추가루, 마늘, 마늘농축액, 양조간장, 양\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"정제소금\"', 'instruction': '기타수산물가공품 카테고리의 수비드연어오리지널에 사용되는 몇 가지 재료입니다. 누락된 재료를 찾아보세요.'}\n",
      "\n",
      "### Response:\n",
      "연어, 백설탕, 정제수<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"\"', 'instruction': '두부 카테고리의 소가연두부125g에 사용되는 몇 가지 재료입니다. 누락된 재료를 찾아보세요.'}\n",
      "\n",
      "### Response:\n",
      "소가연두부<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"숙주\"\\n매우 자주 등장하는 재료: \"대두유, 청양고춧가루\"', 'instruction': '향미유 카테고리에 속하는 허브풍미유(180807)의 레시피에서 몇 가지 재료가 제외되었습니다. 어떤 재료가 빠졌는지 맞춰보세요.'}\n",
      "\n",
      "### Response:\n",
      "숙주, 대두유, 청양고춧가루<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"유기농황설탕\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"\"', 'instruction': '과채주스 카테고리에 속하는 유기농포도주스의 일부 재료가 주어졌습니다. 나머지 식재료를 추측해보세요.'}\n",
      "\n",
      "### Response:\n",
      "포도주스, 유기농포도농축액, 유기농포도농축액p, 유기농포도농축액p2, 유기농포도농축액p3, 유\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"렌틸콩\"\\n일반 재료: \"\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"단호박, 새송이버섯, 양조간장, 옥수수유, 치킨스톡p, 콩발효맛내기진\"', 'instruction': '즉석조리식품 카테고리에 속하는 단호박영양밥의 일부 재료가 주어졌습니다. 나머지 식재료를 추측해보세요.'}\n",
      "\n",
      "### Response:\n",
      "콩나물, 대두유, 양파, 양조간장, 정제수, 정제소금, 참기름<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"\"', 'instruction': '농산물 카테고리의 건조대파의 식재료의 일부입니다. 빠진 식재료를 맞추세요.'}\n",
      "\n",
      "### Response:\n",
      "대파<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"\"', 'instruction': '농산물 카테고리의 제주도콩무농약안심콩나물의 식재료의 일부입니다. 빠진 식재료를 맞추세요.'}\n",
      "\n",
      "### Response:\n",
      "콩나물<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"양상추, 오이\"\\n매우 자주 등장하는 재료: \"\"', 'instruction': '농산물 카테고리에 속하는 이지쿠킹브리또만들기_혼합야채의 레시피에서 몇 가지 재료가 제외되었습니다. 어떤 재료가 빠졌는지 맞춰보세요.'}\n",
      "\n",
      "### Response:\n",
      "양파, 대파, 마늘, 생강, 양배추<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"기타가공품, 버터블랜드\"\\n매우 자주 등장하는 재료: \"정백당, 카놀라유\"', 'instruction': '기타가공품 카테고리에 속하는 트위스트꽈배기크림치즈(저당)의 일부 재료가 주어졌습니다. 나머지 식재료를 추측해보세요.'}\n",
      "\n",
      "### Response:\n",
      "트위스트꽈배기크림치즈(저당)<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"감귤과립\"\\n공통 재료: \"적양배추색소엘, 적자몽농축액\"\\n매우 자주 등장하는 재료: \"양조식초, 잔탄검, 정제소금, 타마린드검, 하얀설탕\"', 'instruction': '소스 카테고리에 속하는 바른선자몽치아씨드샐러드소스의 일부 재료가 주어졌습니다. 나머지 식재료를 추측해보세요.'}\n",
      "\n",
      "### Response:\n",
      "바른선자몽치아씨드, 바른선자몽농축액, 정제수, 정제소금, 정제수<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"리치빵가루\"\\n매우 자주 등장하는 재료: \"대두유, 정백당, 크림치즈, 흑후추분말\"', 'instruction': '빵류 카테고리의 대파크림볼의 식재료의 일부입니다. 빠진 식재료를 맞추세요.'}\n",
      "\n",
      "### Response:\n",
      "크림치즈볼, 대파, 정제수, 밀가루, 정백당, 대두유, 흑후추분말, 크림, 정제소금, 정제수<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"멥쌀, 분리대두단백, 재제소금, 정제수\"', 'instruction': '떡류 카테고리의 우리쌀단백설기에 사용되는 몇 가지 재료입니다. 누락된 재료를 찾아보세요.'}\n",
      "\n",
      "### Response:\n",
      "쌀, 대두단백, 정제소금, 정제수<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"분말셀룰로스\"', 'instruction': '치즈 카테고리의 푸드머스미세슈레드에 사용되는 몇 가지 재료입니다. 누락된 재료를 찾아보세요.'}\n",
      "\n",
      "### Response:\n",
      "슈레드, 유산균발효분말, 정제수, 정제염, 밀가루, 밀분해추출물<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"\"', 'instruction': '두부 카테고리에 속하는 국산콩두부부침용210g의 일부 재료가 주어졌습니다. 나머지 식재료를 추측해보세요.'}\n",
      "\n",
      "### Response:\n",
      "콩, 정제수, 정제소금, 정제수<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"국산채소밑국물, 레시틴, 바지락밑국물p\"\\n매우 자주 등장하는 재료: \"hvphr, 마늘, 매운맛분말, 멸치추출농축액, 발효맛내기, 볶음양념분, 아로마일드, 양파, 정백당, 정제수, 찰옥수수전분, 파프리카추출색소, 포크엑기스p, 호박산이나트륨\"', 'instruction': '소스류 카테고리에 속하는 정통순두부찌개양념(19년)의 레시피에서 몇 가지 재료가 제외되었습니다. 어떤 재료가 빠졌는지 맞춰보세요.'}\n",
      "\n",
      "### Response:\n",
      "순두부, 양조간장, 양파, 대두유, 정제소금, 정제수, 정제염, 정제수, 정\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"고춧잎, 요리플러스, 조미고추맛분\"\\n일반 재료: \"소브산칼륨, 진간장\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"물엿, 백설탕, 잔탄검, 정제소금\"', 'instruction': '절임류 카테고리의 무말랭이의 식재료의 일부입니다. 빠진 식재료를 맞추세요.'}\n",
      "\n",
      "### Response:\n",
      "무말랭이, 고춧가루, 정제수, 정제소금<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"고로케용믹스, 햄\"\\n공통 재료: \"가공버터\"\\n매우 자주 등장하는 재료: \"대두유, 마요네즈, 빵가루, 생이스트, 정백당, 청피망, 흑후추\"', 'instruction': '빵류 카테고리의 모짜렐라고로케베이컨포테이토의 식재료의 일부입니다. 빠진 식재료를 맞추세요.'}\n",
      "\n",
      "### Response:\n",
      "베이컨, 베이컨엑기스, 밀가루, 정제수, 정제소금, 설탕, 밀분해추출물, 정제염, 정제수<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"블루베리향, 홍삼농축액\"\\n매우 자주 등장하는 재료: \"백설탕, 액상과당, 정제수\"', 'instruction': '인삼홍삼음료 카테고리에 속하는 바른선스윗홍포도의 레시피에서 몇 가지 재료가 제외되었습니다. 어떤 재료가 빠졌는지 맞춰보세요.'}\n",
      "\n",
      "### Response:\n",
      "홍삼농축액, 홍삼농축액분말, 정제수, 백설탕, 액상과당, 블루베리향<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"산도조절제, 유산균발효분말\"\\n매우 자주 등장하는 재료: \"원유, 정제소금\"', 'instruction': '생치즈 카테고리의 정통리코타치즈_500g의 식재료의 일부입니다. 빠진 식재료를 맞추세요.'}\n",
      "\n",
      "### Response:\n",
      "리코타치즈, 유산균발효분말<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"유기사과퓨레\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"\"', 'instruction': '과채주스 카테고리에 속하는 아임리얼유기농포도의 일부 재료가 주어졌습니다. 나머지 식재료를 추측해보세요.'}\n",
      "\n",
      "### Response:\n",
      "아임리얼유기농포도퓨레<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"구연산철암모늄\"\\n공통 재료: \"가공버터\"\\n매우 자주 등장하는 재료: \"구연산나트륨, 유청분말, 정제수, 크림치즈\"', 'instruction': '가공치즈 카테고리에 속하는 풀스키즈고칼슘슬라이스치즈의 레시피에서 몇 가지 재료가 제외되었습니다. 어떤 재료가 빠졌는지 맞춰보세요.'}\n",
      "\n",
      "### Response:\n",
      "풀스키즈고칼슘슬라이스치즈, 풀스키즈고칼슘슬라이스치즈(소스)<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"곡류가공품, 돼지고기, 백설탕, 부추, 생강, 생강분말, 쇠고기추출분말, 양배추, 양파, 유화유지피, 정제소금, 흑후추분말\"', 'instruction': '만두류 카테고리의 P-육즙듬뿍만두에 사용되는 몇 가지 재료입니다. 누락된 재료를 찾아보세요.'}\n",
      "\n",
      "### Response:\n",
      "돼지고기추출분말, 생강, 생강분말, 양배추, 양파, 정제소금, 흑후추분말<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"\"\\n공통 재료: \"우엉\"\\n매우 자주 등장하는 재료: \"d자일로오스, 대두단백, 정백당, 포도당, 효모추출물\"', 'instruction': '어묵 카테고리에 속하는 알래스칸특급우엉말이어묵의 일부 재료가 주어졌습니다. 나머지 식재료를 추측해보세요.'}\n",
      "\n",
      "### Response:\n",
      "우엉, 대두단백, 정제수, 정백당, 정제염, 정제수, 효모추출물<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"녹차수제비, 호박수제비\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"\"', 'instruction': '숙면 카테고리에 속하는 풀스키친삼색쌀수제비의 일부 재료가 주어졌습니다. 나머지 식재료를 추측해보세요.'}\n",
      "\n",
      "### Response:\n",
      "풀스키친삼색쌀수제비<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': '핵심 재료: \"\"\\n일반 재료: \"오렌지향501007\"\\n공통 재료: \"\"\\n매우 자주 등장하는 재료: \"구연산나트륨, 비타민c, 정제수, 화이바솔2l\"', 'instruction': '과채음료 카테고리에 속하는 감귤주스의 일부 재료가 주어졌습니다. 나머지 식재료를 추측해보세요.'}\n",
      "\n",
      "### Response:\n",
      "감귤농축액, 감귤농축액p, 정제수<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from transformers import TextStreamer\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "length = 50 # length of random list\n",
    "random_list = [random.randint(0, len(dataset_dict['test'])) for _ in range(length)]\n",
    "\n",
    "q_list = []; a_list = []; output_list = []\n",
    "for n in random_list:\n",
    "    q = dataset_dict['test'][n]['QUESTION']\n",
    "    a = dataset_dict['test'][n]['ANSWER']\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        [\n",
    "            alpaca_prompt.format(\n",
    "                q,  # 지시사항\n",
    "                \"\",  # 출력 - 생성을 위해 이 부분을 비워둡니다!\n",
    "            )\n",
    "        ],\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    text_streamer = TextStreamer(tokenizer)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        streamer=text_streamer,\n",
    "        max_new_tokens=4096,  # 최대 생성 토큰 수를 설정합니다.\n",
    "        stopping_criteria=stopping_criteria  # 생성을 멈출 기준을 설정합니다.\n",
    "    )\n",
    "\n",
    "    q_list.append(q)\n",
    "    a_list.append(a)\n",
    "    output_tmp = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    output_list.append(output_tmp[0].split('\\n')[-1].split(', '))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10792857142857143\n"
     ]
    }
   ],
   "source": [
    "# [answer (a_list) 와 pred (output_list) 의 교집합 / answer (a_list) 의 길이]\n",
    "score_list = []\n",
    "for a, p in zip(a_list, output_list):\n",
    "    a = a.split(', ')\n",
    "    cnt = 0\n",
    "    for pp in p:\n",
    "        if pp in a:\n",
    "            cnt += 1\n",
    "    score_list.append(cnt/len(a))\n",
    "\n",
    "print(sum(score_list)/len(score_list)) # mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantization 방식 설정\n",
    "quantization_method = \"q8_0\"  # \"f16\" \"q8_0\" \"q4_k_m\" \"q5_k_m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Entering directory '/home/jaesung/pulmuone/instruction_tuning_2/v4_completion/modeling/llama.cpp'\n",
      "I ccache not found. Consider installing it for faster compilation.\n",
      "I llama.cpp build info: \n",
      "I UNAME_S:   Linux\n",
      "I UNAME_P:   x86_64\n",
      "I UNAME_M:   x86_64\n",
      "I CFLAGS:    -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion \n",
      "I CXXFLAGS:  -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE \n",
      "I NVCCFLAGS: -std=c++11 -O3 -g \n",
      "I LDFLAGS:    \n",
      "I CC:        cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "I CXX:       c++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "\n",
      "rm -vrf *.dot libllava.a llama-baby-llama llama-batched llama-batched-bench llama-bench llama-benchmark-matmult llama-cli llama-convert-llama2c-to-ggml llama-embedding llama-eval-callback llama-export-lora llama-gbnf-validator llama-gguf llama-gguf-hash llama-gguf-split llama-gritlm llama-imatrix llama-infill llama-llava-cli llama-minicpmv-cli llama-lookahead llama-lookup llama-lookup-create llama-lookup-merge llama-lookup-stats llama-parallel llama-passkey llama-perplexity llama-q8dot llama-quantize llama-quantize-stats llama-retrieval llama-save-load-state llama-server llama-simple llama-speculative llama-tokenize llama-vdot llama-cvector-generator tests/test-c.o tests/test-autorelease tests/test-backend-ops tests/test-chat-template tests/test-double-float tests/test-grad0 tests/test-grammar-integration tests/test-grammar-parser tests/test-json-schema-to-grammar tests/test-llama-grammar tests/test-model-load-cancel tests/test-opt tests/test-quantize-fns tests/test-quantize-perf tests/test-rope tests/test-sampling tests/test-tokenizer-0 tests/test-tokenizer-1-bpe tests/test-tokenizer-1-spm\n",
      "rm -rvf src/*.o\n",
      "rm -rvf tests/*.o\n",
      "rm -rvf examples/*.o\n",
      "rm -rvf common/*.o\n",
      "rm -rvf *.a\n",
      "rm -rvf *.dll\n",
      "rm -rvf *.so\n",
      "rm -rvf *.dot\n",
      "rm -rvf ggml/*.a\n",
      "rm -rvf ggml/*.dll\n",
      "rm -rvf ggml/*.so\n",
      "rm -vrf ggml/src/*.o\n",
      "rm -rvf ggml/src/llamafile/*.o\n",
      "rm -rvf common/build-info.cpp\n",
      "rm -vrf ggml/src/ggml-metal-embed.metal\n",
      "rm -vrf ggml/src/ggml-cuda/*.o\n",
      "rm -vrf ggml/src/ggml-cuda/template-instances/*.o\n",
      "rm -rvf libllava.a llama-baby-llama llama-batched llama-batched-bench llama-bench llama-benchmark-matmult llama-cli llama-convert-llama2c-to-ggml llama-embedding llama-eval-callback llama-export-lora llama-gbnf-validator llama-gguf llama-gguf-hash llama-gguf-split llama-gritlm llama-imatrix llama-infill llama-llava-cli llama-minicpmv-cli llama-lookahead llama-lookup llama-lookup-create llama-lookup-merge llama-lookup-stats llama-parallel llama-passkey llama-perplexity llama-q8dot llama-quantize llama-quantize-stats llama-retrieval llama-save-load-state llama-server llama-simple llama-speculative llama-tokenize llama-vdot llama-cvector-generator tests/test-c.o\n",
      "rm -rvf tests/test-autorelease tests/test-backend-ops tests/test-chat-template tests/test-double-float tests/test-grad0 tests/test-grammar-integration tests/test-grammar-parser tests/test-json-schema-to-grammar tests/test-llama-grammar tests/test-model-load-cancel tests/test-opt tests/test-quantize-fns tests/test-quantize-perf tests/test-rope tests/test-sampling tests/test-tokenizer-0 tests/test-tokenizer-1-bpe tests/test-tokenizer-1-spm\n",
      "rm -f vulkan-shaders-gen ggml/src/ggml-vulkan-shaders.hpp ggml/src/ggml-vulkan-shaders.cpp\n",
      "rm -rvf main quantize quantize-stats perplexity imatrix embedding vdot q8dot convert-llama2c-to-ggml simple batched batched-bench save-load-state server gguf gguf-split eval-callback llama-bench libllava.a llava-cli baby-llama retrieval speculative infill tokenize benchmark-matmult parallel export-lora lookahead lookup passkey gritlm\n",
      "find examples pocs -type f -name \"*.o\" -delete\n",
      "make: Leaving directory '/home/jaesung/pulmuone/instruction_tuning_2/v4_completion/modeling/llama.cpp'\n",
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 412.55 out of 503.13 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:02<00:00, 15.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Converting llama model. Can use fast conversion = False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
      "   \\\\   /|    [0] Installing llama.cpp will take 3 minutes.\n",
      "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits will take 3 minutes.\n",
      "\\        /    [2] Converting GGUF 16bits to ['q8_0'] will take 10 minutes each.\n",
      " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
      "\n",
      "Unsloth: [0] Installing llama.cpp. This will take 3 minutes...\n",
      "Unsloth: [1] Converting model at Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38-gguf into q8_0 GGUF format.\n",
      "The output location will be ./Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38-gguf/unsloth.Q8_0.gguf\n",
      "This will take 3 minutes...\n",
      "INFO:hf-to-gguf:Loading model: Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38-gguf\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:token_embd.weight,           torch.bfloat16 --> Q8_0, shape = {4096, 128256}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00004-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:output.weight,               torch.bfloat16 --> Q8_0, shape = {4096, 128256}\n",
      "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:output_norm.weight,          torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:gguf: context length = 8192\n",
      "INFO:hf-to-gguf:gguf: embedding length = 4096\n",
      "INFO:hf-to-gguf:gguf: feed forward length = 14336\n",
      "INFO:hf-to-gguf:gguf: head count = 32\n",
      "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
      "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
      "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
      "INFO:hf-to-gguf:gguf: file type = 7\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "INFO:gguf.vocab:Adding 280147 merge(s).\n",
      "INFO:gguf.vocab:Setting special token type bos to 128000\n",
      "INFO:gguf.vocab:Setting special token type eos to 128001\n",
      "INFO:gguf.vocab:Setting special token type pad to 128255\n",
      "INFO:gguf.vocab:Setting chat_template to {% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
      "\n",
      "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "' }}{% endif %}\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38-gguf/unsloth.Q8_0.gguf: n_tensors = 291, total_size = 8.5G\n",
      "Writing: 100%|██████████| 8.53G/8.53G [01:27<00:00, 98.0Mbyte/s]\n",
      "INFO:hf-to-gguf:Model successfully exported to Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38-gguf/unsloth.Q8_0.gguf\n",
      "Unsloth: Conversion completed! Output location: ./Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38-gguf/unsloth.Q8_0.gguf\n",
      "Unsloth: Uploading GGUF to Huggingface Hub...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unsloth.Q8_0.gguf: 100%|██████████| 8.54G/8.54G [05:05<00:00, 28.0MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GGUF to https://huggingface.co/passionMan/Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38-gguf\n"
     ]
    }
   ],
   "source": [
    "# Hub 에 GGUF 업로드\n",
    "model.push_to_hub_gguf(\n",
    "    huggingface_repo + \"-gguf\",\n",
    "    tokenizer,\n",
    "    quantization_method=quantization_method,\n",
    "    token=huggingface_token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpaca_kernel",
   "language": "python",
   "name": "alpaca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
