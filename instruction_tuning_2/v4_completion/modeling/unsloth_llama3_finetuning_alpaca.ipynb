{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## unsloth_env_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# CUDA ì¥ì¹˜ì˜ ì£¼ìš” ë²„ì „ê³¼ ë¶€ ë²„ì „ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "major_version, minor_version = torch.cuda.get_device_capability()\n",
    "major_version, minor_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[unsloth]\n",
    "\n",
    "unsloth íŒ¨í‚¤ì§€ëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì¸ Llama 3.1, Mistral, Phi ë° Gemmaì˜ ë¯¸ì„¸ ì¡°ì •ì„ ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ 2-5ë°° ë¹ ë¥´ê²Œ í•˜ê³  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ 80%ê¹Œì§€ ì¤„ì´ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. ì´ íŒ¨í‚¤ì§€ëŠ” OpenAIì˜ Triton ì–¸ì–´ë¡œ ì‘ì„±ëœ ì»¤ìŠ¤í…€ GPU ì»¤ë„ì„ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ìµœì í™”í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì •í™•ë„ ì†ì‹¤ ì—†ì´ íš¨ìœ¨ì ìœ¼ë¡œ ëª¨ë¸ì„ í›ˆë ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì£¼ìš” ê¸°ëŠ¥\n",
    "ì„±ëŠ¥: íŠ¹ì • ê²½ìš°ì—ëŠ” ìµœëŒ€ 30ë°° ë¹ ë¥´ê²Œ ë¯¸ì„¸ ì¡°ì •í•  ìˆ˜ ìˆìœ¼ë©°, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ í¬ê²Œ ì¤„ì—¬ ë” í° ë°°ì¹˜ í¬ê¸°ì™€ íš¨ìœ¨ì ì¸ í›ˆë ¨ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "í˜¸í™˜ì„±: NVIDIA, Intel, AMD ë“± ë‹¤ì–‘í•œ GPUë¥¼ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "ë©”ëª¨ë¦¬ ìµœì í™”: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ ìˆ˜ë™ ë¯¸ë¶„ ë° ì²´ì¸ ë§¤íŠ¸ë¦­ìŠ¤ ê³±ì…ˆ ìµœì í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "ì˜¤í”ˆ ì†ŒìŠ¤: ë¬´ë£Œ ì˜¤í”ˆ ì†ŒìŠ¤ ë²„ì „ì´ ìˆìœ¼ë©°, í”„ë¡œ ë²„ì „ì—ì„œëŠ” ë‹¤ì¤‘ GPU ì§€ì› ë° ë” ë¹ ë¥¸ í›ˆë ¨ ì†ë„ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Colabì—ì„œ torch 2.2.1ì„ ì‚¬ìš©í•˜ê³  ìˆìœ¼ë¯€ë¡œ, íŒ¨í‚¤ì§€ ì¶©ëŒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ë³„ë„ë¡œ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "if major_version >= 8:\n",
    "    # ìƒˆë¡œìš´ GPU(ì˜ˆ: Ampere, Hopper GPUs - RTX 30xx, RTX 40xx, A100, H100, L40)ì— ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n",
    "else:\n",
    "    # ì˜¤ë˜ëœ GPU(ì˜ˆ: V100, Tesla T4, RTX 20xx)ì— ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "    !pip install --no-deps xformers trl peft accelerate bitsandbytes\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaesung/anaconda3/envs/alpaca/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.44.0.\n",
      "   \\\\   /|    GPU: NVIDIA A10. Max memory: 21.988 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27.post2. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.35s/it]\n",
      "beomi/Llama-3-Open-Ko-8B-Instruct-preview does not have a padding token! Will use pad_token = <|reserved_special_token_250|>.\n",
      "<string>:209: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:210: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:211: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:209: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:210: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:211: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from accelerate import PartialState\n",
    "\n",
    "device_string = PartialState().process_index\n",
    "\n",
    "max_seq_length = 4096  # ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ë‚´ë¶€ì ìœ¼ë¡œ RoPE ìŠ¤ì¼€ì¼ë§ì„ ìë™ìœ¼ë¡œ ì§€ì›í•©ë‹ˆë‹¤!\n",
    "# ìë™ ê°ì§€ë¥¼ ìœ„í•´ Noneì„ ì‚¬ìš©í•©ë‹ˆë‹¤. Tesla T4, V100ì€ Float16, Ampere+ëŠ” Bfloat16ì„ ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "dtype = None\n",
    "# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ 4bit ì–‘ìí™”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. Falseì¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
    "load_in_4bit = True\n",
    "\n",
    "# 4ë°° ë¹ ë¥¸ ë‹¤ìš´ë¡œë“œì™€ ë©”ëª¨ë¦¬ ë¶€ì¡± ë¬¸ì œë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ì§€ì›í•˜ëŠ” 4bit ì‚¬ì „ ì–‘ìí™” ëª¨ë¸ì…ë‹ˆë‹¤.\n",
    "fourbit_models = [\n",
    "    \"unsloth/mistral-7b-bnb-4bit\",\n",
    "    \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n",
    "    \"unsloth/llama-2-7b-bnb-4bit\",\n",
    "    \"unsloth/gemma-7b-bnb-4bit\",\n",
    "    \"unsloth/gemma-7b-it-bnb-4bit\",  # Gemma 7bì˜ Instruct ë²„ì „\n",
    "    \"unsloth/gemma-2b-bnb-4bit\",\n",
    "    \"unsloth/gemma-2b-it-bnb-4bit\",  # Gemma 2bì˜ Instruct ë²„ì „\n",
    "    \"unsloth/llama-3-8b-bnb-4bit\",  # Llama-3 8B\n",
    "]  # ë” ë§ì€ ëª¨ë¸ì€ https://huggingface.co/unsloth ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    # model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n",
    "    model_name=\"beomi/Llama-3-Open-Ko-8B-Instruct-preview\",  # ëª¨ë¸ ì´ë¦„ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    max_seq_length=max_seq_length,  # ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    dtype=dtype,  # ë°ì´í„° íƒ€ì…ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    load_in_4bit=load_in_4bit,  # 4bit ì–‘ìí™” ë¡œë“œ ì—¬ë¶€ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    # token = \"hf_...\", # ê²Œì´íŠ¸ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° í† í°ì„ ì‚¬ìš©í•˜ì„¸ìš”. ì˜ˆ: meta-llama/Llama-2-7b-hf,\n",
    "    device_map={'':device_string}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2024.8 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    # r=16,\n",
    "    r=32,  # 0ë³´ë‹¤ í° ì–´ë–¤ ìˆ«ìë„ ì„ íƒ ê°€ëŠ¥! 8, 16, 32, 64, 128ì´ ê¶Œì¥ë©ë‹ˆë‹¤. # ì–¼ë§ˆë‚˜ ì••ì¶•í• ì§€, ë§ì´ ì••ì¶•í•  ìˆ˜ë¡ íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ì‘ì•„ì§‘ë‹ˆë‹¤.\n",
    "    lora_alpha=32,  # LoRA ì•ŒíŒŒ ê°’ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    lora_dropout=0.05,  # ë“œë¡­ì•„ì›ƒì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],  # íƒ€ê²Ÿ ëª¨ë“ˆì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "    bias=\"none\",  # ë°”ì´ì–´ìŠ¤ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "    # True ë˜ëŠ” \"unsloth\"ë¥¼ ì‚¬ìš©í•˜ì—¬ ë§¤ìš° ê¸´ ì»¨í…ìŠ¤íŠ¸ì— ëŒ€í•´ VRAMì„ 30% ëœ ì‚¬ìš©í•˜ê³ , 2ë°° ë” í° ë°°ì¹˜ í¬ê¸°ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=123,  # ë‚œìˆ˜ ìƒíƒœë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    use_rslora=False,  # ìˆœìœ„ ì•ˆì •í™” LoRAë¥¼ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "    loftq_config=None,  # LoftQë¥¼ ì§€ì›í•©ë‹ˆë‹¤.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# EOS_TOKENì€ ë¬¸ì¥ì˜ ëì„ ë‚˜íƒ€ë‚´ëŠ” í† í°ì…ë‹ˆë‹¤. ì´ í† í°ì„ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "# AlpacaPromptë¥¼ ì‚¬ìš©í•˜ì—¬ ì§€ì‹œì‚¬í•­ì„ í¬ë§·íŒ…í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "\n",
    "# ì£¼ì–´ì§„ ì˜ˆì‹œë“¤ì„ í¬ë§·íŒ…í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"QUESTION\"]  # ì§€ì‹œì‚¬í•­ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    outputs = examples[\"ANSWER\"]  # ì¶œë ¥ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    texts = []  # í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n",
    "    for instruction, output in zip(instructions, outputs):\n",
    "        # EOS_TOKENì„ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ìƒì„±ì´ ë¬´í•œíˆ ì§„í–‰ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "        text = alpaca_prompt.format(instruction, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\n",
    "        \"text\": texts,  # í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    }\n",
    "\n",
    "# JSONL íŒŒì¼ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data\n",
    "\n",
    "# JSONL íŒŒì¼ ê²½ë¡œ\n",
    "file_path = '/home/jaesung/pulmuone/instruction_tuning_2/v4_completion/data/qa_pair_for_completion.jsonl'\n",
    "\n",
    "# JSONL íŒŒì¼ ë¡œë“œ\n",
    "data = load_jsonl(file_path)\n",
    "\n",
    "# pandas DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Dataset ê°ì²´ë¡œ ë³€í™˜\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# DatasetDict ê°ì²´ë¡œ ê²°í•©\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['QUESTION', 'ANSWER', '__index_level_0__'],\n",
      "        num_rows: 10940\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['QUESTION', 'ANSWER', '__index_level_0__'],\n",
      "        num_rows: 2736\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_dict['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['QUESTION', 'ANSWER', '__index_level_0__'],\n",
       "    num_rows: 10940\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10940/10940 [00:00<00:00, 59651.37 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„°ì…‹ì— formatting_prompts_func í•¨ìˆ˜ë¥¼ ì ìš©í•©ë‹ˆë‹¤. ë°°ì¹˜ ì²˜ë¦¬ë¥¼ í™œì„±í™”í•©ë‹ˆë‹¤.\n",
    "dataset = dataset.map(\n",
    "    formatting_prompts_func,\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaesung/anaconda3/envs/alpaca/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/jaesung/anaconda3/envs/alpaca/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Map (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10940/10940 [00:02<00:00, 4329.57 examples/s]\n",
      "Map (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10940/10940 [00:02<00:00, 4306.42 examples/s]\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "from accelerate import notebook_launcher\n",
    "\n",
    "tokenizer.padding_side = \"right\"  # í† í¬ë‚˜ì´ì €ì˜ íŒ¨ë”©ì„ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "# SFTTrainerë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ í•™ìŠµ ì„¤ì •\n",
    "trainer = SFTTrainer(\n",
    "    model=model,  # í•™ìŠµí•  ëª¨ë¸\n",
    "    tokenizer=tokenizer,  # í† í¬ë‚˜ì´ì €\n",
    "    train_dataset=dataset,  # í•™ìŠµ ë°ì´í„°ì…‹\n",
    "    eval_dataset=dataset,\n",
    "    dataset_text_field=\"text\",  # ë°ì´í„°ì…‹ì—ì„œ í…ìŠ¤íŠ¸ í•„ë“œì˜ ì´ë¦„\n",
    "    max_seq_length=max_seq_length,  # ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´\n",
    "    dataset_num_proc=2,  # ë°ì´í„° ì²˜ë¦¬ì— ì‚¬ìš©í•  í”„ë¡œì„¸ìŠ¤ ìˆ˜\n",
    "    packing=False,  # ì§§ì€ ì‹œí€€ìŠ¤ì— ëŒ€í•œ í•™ìŠµ ì†ë„ë¥¼ 5ë°° ë¹ ë¥´ê²Œ í•  ìˆ˜ ìˆìŒ,\n",
    "\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=2,  # ê° ë””ë°”ì´ìŠ¤ë‹¹ í›ˆë ¨ ë°°ì¹˜ í¬ê¸°\n",
    "        gradient_accumulation_steps=4,\n",
    "        # gradient_accumulation_steps=2,  # ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  ë‹¨ê³„\n",
    "        warmup_steps=5,  # ì›œì—… ìŠ¤í… ìˆ˜\n",
    "        num_train_epochs=3,  # í›ˆë ¨ ì—í­ ìˆ˜\n",
    "        max_steps=38,  # ìµœëŒ€ ìŠ¤í… ìˆ˜\n",
    "        do_eval=True,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        logging_steps=1,  # logging ìŠ¤í… ìˆ˜\n",
    "        learning_rate=2e-4,  # í•™ìŠµë¥ \n",
    "        fp16=not torch.cuda.is_bf16_supported(),  # fp16 ì‚¬ìš© ì—¬ë¶€, bf16ì´ ì§€ì›ë˜ì§€ ì•ŠëŠ” ê²½ìš°ì—ë§Œ ì‚¬ìš©\n",
    "        bf16=torch.cuda.is_bf16_supported(),  # bf16 ì‚¬ìš© ì—¬ë¶€, bf16ì´ ì§€ì›ë˜ëŠ” ê²½ìš°ì—ë§Œ ì‚¬ìš©\n",
    "        optim=\"adamw_8bit\",  # ìµœì í™” ì•Œê³ ë¦¬ì¦˜\n",
    "        weight_decay=0.01,  # ê°€ì¤‘ì¹˜ ê°ì†Œ\n",
    "        lr_scheduler_type=\"cosine\",  # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ìœ í˜•\n",
    "        seed=123,  # ëœë¤ ì‹œë“œ\n",
    "        output_dir=\"outputs\",  # ì¶œë ¥ ë””ë ‰í† ë¦¬\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA A10. Max memory = 21.988 GB.\n",
      "5.781 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "# í˜„ì¬ ë©”ëª¨ë¦¬ ìƒíƒœë¥¼ ë³´ì—¬ì£¼ëŠ” ì½”ë“œ\n",
    "gpu_stats = torch.cuda.get_device_properties(0)  # GPU ì†ì„± ê°€ì ¸ì˜¤ê¸°\n",
    "start_gpu_memory = round(\n",
    "    torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3\n",
    ")  # ì‹œì‘ ì‹œ ì˜ˆì•½ëœ GPU ë©”ëª¨ë¦¬ ê³„ì‚°\n",
    "max_memory = round(\n",
    "    gpu_stats.total_memory / 1024 / 1024 / 1024, 3\n",
    ")  # GPUì˜ ìµœëŒ€ ë©”ëª¨ë¦¬ ê³„ì‚°\n",
    "print(\n",
    "    f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\"\n",
    ")  # GPU ì´ë¦„ê³¼ ìµœëŒ€ ë©”ëª¨ë¦¬ ì¶œë ¥\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")  # ì˜ˆì•½ëœ ë©”ëª¨ë¦¬ ì–‘ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 10,940 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 38\n",
      " \"-____-\"     Number of trainable parameters = 83,886,080\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 9:28:49, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.533100</td>\n",
       "      <td>3.544315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.425000</td>\n",
       "      <td>3.486726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.373600</td>\n",
       "      <td>3.183954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.178400</td>\n",
       "      <td>2.787812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.747700</td>\n",
       "      <td>2.456101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.474500</td>\n",
       "      <td>2.088660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.207700</td>\n",
       "      <td>1.770539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.524500</td>\n",
       "      <td>1.578229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.361100</td>\n",
       "      <td>1.503049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.304900</td>\n",
       "      <td>1.440570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.386700</td>\n",
       "      <td>1.394267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.124900</td>\n",
       "      <td>1.330091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.363600</td>\n",
       "      <td>1.292368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.301500</td>\n",
       "      <td>1.255865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.119000</td>\n",
       "      <td>1.232563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.199300</td>\n",
       "      <td>1.204866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.118900</td>\n",
       "      <td>1.172677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.076400</td>\n",
       "      <td>1.152578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.019300</td>\n",
       "      <td>1.150680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.181800</td>\n",
       "      <td>1.136062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.310400</td>\n",
       "      <td>1.114020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.988600</td>\n",
       "      <td>1.097485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.210600</td>\n",
       "      <td>1.086179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.968200</td>\n",
       "      <td>1.077115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.916300</td>\n",
       "      <td>1.068567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.264500</td>\n",
       "      <td>1.060168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.912200</td>\n",
       "      <td>1.053435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.166400</td>\n",
       "      <td>1.048616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.044400</td>\n",
       "      <td>1.044908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.230800</td>\n",
       "      <td>1.041666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>1.038719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.963600</td>\n",
       "      <td>1.035910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1.033671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.162800</td>\n",
       "      <td>1.031687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.108100</td>\n",
       "      <td>1.030358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.768300</td>\n",
       "      <td>1.029529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.326200</td>\n",
       "      <td>1.029125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.880800</td>\n",
       "      <td>1.029055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()  # ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ê³  í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34133.3211 seconds used for training.\n",
      "568.89 minutes used for training.\n",
      "Peak reserved memory = 9.615 GB.\n",
      "Peak reserved memory for training = 3.834 GB.\n",
      "Peak reserved memory % of max memory = 43.728 %.\n",
      "Peak reserved memory for training % of max memory = 17.437 %.\n"
     ]
    }
   ],
   "source": [
    "# ìµœì¢… ë©”ëª¨ë¦¬ ë° ì‹œê°„ í†µê³„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "used_memory = round(\n",
    "    torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3\n",
    ")  # ì‚¬ìš©ëœ ìµœëŒ€ ë©”ëª¨ë¦¬ë¥¼ GB ë‹¨ìœ„ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "used_memory_for_lora = round(\n",
    "    used_memory - start_gpu_memory, 3\n",
    ")  # LoRAë¥¼ ìœ„í•´ ì‚¬ìš©ëœ ë©”ëª¨ë¦¬ë¥¼ GB ë‹¨ìœ„ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "used_percentage = round(\n",
    "    used_memory / max_memory * 100, 3\n",
    ")  # ìµœëŒ€ ë©”ëª¨ë¦¬ ëŒ€ë¹„ ì‚¬ìš©ëœ ë©”ëª¨ë¦¬ì˜ ë¹„ìœ¨ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "lora_percentage = round(\n",
    "    used_memory_for_lora / max_memory * 100, 3\n",
    ")  # ìµœëŒ€ ë©”ëª¨ë¦¬ ëŒ€ë¹„ LoRAë¥¼ ìœ„í•´ ì‚¬ìš©ëœ ë©”ëª¨ë¦¬ì˜ ë¹„ìœ¨ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "print(\n",
    "    f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\"\n",
    ")  # í›ˆë ¨ì— ì‚¬ìš©ëœ ì‹œê°„ì„ ì´ˆ ë‹¨ìœ„ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(\n",
    "    # í›ˆë ¨ì— ì‚¬ìš©ëœ ì‹œê°„ì„ ë¶„ ë‹¨ìœ„ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
    ")\n",
    "print(\n",
    "    f\"Peak reserved memory = {used_memory} GB.\"\n",
    ")  # ì˜ˆì•½ëœ ìµœëŒ€ ë©”ëª¨ë¦¬ë¥¼ GB ë‹¨ìœ„ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(\n",
    "    f\"Peak reserved memory for training = {used_memory_for_lora} GB.\"\n",
    ")  # í›ˆë ¨ì„ ìœ„í•´ ì˜ˆì•½ëœ ìµœëŒ€ ë©”ëª¨ë¦¬ë¥¼ GB ë‹¨ìœ„ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(\n",
    "    f\"Peak reserved memory % of max memory = {used_percentage} %.\"\n",
    ")  # ìµœëŒ€ ë©”ëª¨ë¦¬ ëŒ€ë¹„ ì˜ˆì•½ëœ ë©”ëª¨ë¦¬ì˜ ë¹„ìœ¨ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(\n",
    "    f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\"\n",
    ")  # ìµœëŒ€ ë©”ëª¨ë¦¬ ëŒ€ë¹„ í›ˆë ¨ì„ ìœ„í•´ ì˜ˆì•½ëœ ë©”ëª¨ë¦¬ì˜ ë¹„ìœ¨ì„ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"beomi/Llama-3-Open-Ko-8B-Instruct-preview\" # ë³‘í•©ì„ ìˆ˜í–‰í•  ë² ì´ìŠ¤ ëª¨ë¸\n",
    "huggingface_token = \"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\"  # HuggingFace í† í°\n",
    "huggingface_repo = \"Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38\"  # ëª¨ë¸ì„ ì—…ë¡œë“œí•  repository\n",
    "save_method = (\n",
    "    \"merged_16bit\"  # \"merged_4bit\", \"merged_4bit_forced\", \"merged_16bit\", \"lora\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 365.44 out of 503.13 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [00:00<00:00, 31.23it/s]We will save to Disk and not RAM now.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:05<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving to organization with address passionMan/Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38\n",
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
      "Unsloth: Saving to organization with address passionMan/Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38\n",
      "Unsloth: Uploading all files... Please wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 2.18M/4.98G [00:00<07:04, 11.7MB/s]\n",
      "model-00001-of-00004.safetensors:   0%|          | 3.39M/4.98G [00:00<09:01, 9.19MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 4.75M/4.98G [00:00<15:11, 5.45MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 8.40M/4.98G [00:01<08:51, 9.35MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 11.6M/4.98G [00:01<06:41, 12.4MB/s]\n",
      "model-00001-of-00004.safetensors:   0%|          | 14.4M/4.98G [00:01<05:12, 15.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 24.7M/4.98G [00:01<04:33, 18.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 32.0M/4.98G [00:02<04:44, 17.4MB/s]\n",
      "model-00001-of-00004.safetensors:   1%|          | 38.1M/4.98G [00:02<03:34, 23.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|          | 42.1M/4.98G [00:03<05:47, 14.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 45.0M/4.98G [00:03<06:02, 13.6MB/s]\n",
      "model-00001-of-00004.safetensors:   1%|          | 47.4M/4.98G [00:03<05:59, 13.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|          | 49.5M/4.98G [00:04<09:13, 8.90MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 54.7M/4.98G [00:04<06:35, 12.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 58.0M/4.98G [00:04<06:00, 13.7MB/s]\n",
      "model-00001-of-00004.safetensors:   1%|          | 60.0M/4.98G [00:04<08:58, 9.14MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 61.5M/4.98G [00:05<08:36, 9.51MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|â–         | 76.5M/4.98G [00:05<04:48, 17.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|â–         | 80.9M/4.98G [00:06<05:13, 15.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|â–         | 99.2M/4.98G [00:06<03:40, 22.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|â–         | 104M/4.98G [00:07<03:34, 22.7MB/s] \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|â–         | 107M/4.98G [00:07<05:40, 14.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|â–         | 110M/4.98G [00:07<05:36, 14.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|â–         | 113M/4.98G [00:08<09:17, 8.73MB/s]\n",
      "model-00001-of-00004.safetensors:   2%|â–         | 122M/4.98G [00:08<05:13, 15.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|â–         | 128M/4.98G [00:09<05:14, 15.4MB/s]\n",
      "model-00001-of-00004.safetensors:   3%|â–         | 133M/4.98G [00:09<04:16, 18.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|â–         | 137M/4.98G [00:09<04:04, 19.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|â–         | 143M/4.98G [00:10<06:09, 13.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|â–         | 158M/4.98G [00:11<04:41, 17.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|â–         | 164M/4.98G [00:11<04:59, 16.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|â–         | 168M/4.98G [00:11<04:29, 17.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|â–         | 174M/4.98G [00:12<06:47, 11.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|â–         | 176M/4.98G [00:13<11:03, 7.24MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|â–         | 189M/4.98G [00:13<04:45, 16.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|â–         | 204M/4.98G [00:14<03:21, 23.6MB/s]\n",
      "model-00001-of-00004.safetensors:   4%|â–         | 209M/4.98G [00:14<03:50, 20.7MB/s]\n",
      "model-00001-of-00004.safetensors:   4%|â–         | 215M/4.98G [00:14<03:25, 23.2MB/s]\n",
      "model-00001-of-00004.safetensors:   4%|â–         | 219M/4.98G [00:15<05:09, 15.4MB/s]\n",
      "model-00001-of-00004.safetensors:   4%|â–         | 222M/4.98G [00:15<05:11, 15.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|â–         | 225M/4.98G [00:16<08:33, 9.26MB/s]\n",
      "model-00001-of-00004.safetensors:   5%|â–         | 235M/4.98G [00:16<04:34, 17.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|â–Œ         | 252M/4.98G [00:16<02:55, 26.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|â–Œ         | 268M/4.98G [00:17<02:49, 27.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|â–Œ         | 294M/4.98G [00:18<02:43, 28.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|â–Œ         | 303M/4.98G [00:18<02:10, 35.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|â–Œ         | 309M/4.98G [00:18<02:51, 27.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|â–‹         | 318M/4.98G [00:18<02:10, 35.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   7%|â–‹         | 335M/4.98G [00:19<02:10, 35.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   7%|â–‹         | 341M/4.98G [00:19<02:39, 29.1MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|â–‹         | 348M/4.98G [00:19<02:21, 32.7MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   7%|â–‹         | 364M/4.98G [00:24<09:17, 8.28MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|â–Š         | 384M/4.98G [00:24<04:53, 15.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|â–Š         | 391M/4.98G [00:25<04:55, 15.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|â–Š         | 396M/4.98G [00:25<04:08, 18.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|â–Š         | 402M/4.98G [00:25<04:30, 16.9MB/s]\n",
      "model-00001-of-00004.safetensors:   8%|â–Š         | 408M/4.98G [00:25<03:41, 20.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|â–Š         | 413M/4.98G [00:25<03:14, 23.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   9%|â–Š         | 426M/4.98G [00:26<02:42, 28.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|â–‰         | 443M/4.98G [00:26<02:18, 32.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|â–‰         | 458M/4.98G [00:27<02:29, 30.2MB/s]\n",
      "model-00001-of-00004.safetensors:   9%|â–‰         | 464M/4.98G [00:27<02:16, 33.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|â–‰         | 469M/4.98G [00:27<02:55, 25.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|â–‰         | 475M/4.98G [00:27<02:25, 30.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|â–‰         | 492M/4.98G [00:28<02:04, 36.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|â–ˆ         | 498M/4.98G [00:29<03:42, 20.1MB/s]\n",
      "model-00001-of-00004.safetensors:  10%|â–ˆ         | 505M/4.98G [00:29<03:01, 24.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|â–ˆ         | 511M/4.98G [00:29<02:31, 29.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|â–ˆ         | 516M/4.98G [00:29<03:02, 24.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|â–ˆ         | 522M/4.98G [00:29<02:37, 28.3MB/s]\n",
      "model-00001-of-00004.safetensors:  11%|â–ˆ         | 538M/4.98G [00:30<02:20, 31.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|â–ˆ         | 544M/4.98G [00:30<03:09, 23.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|â–ˆ         | 550M/4.98G [00:30<02:54, 25.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|â–ˆ         | 555M/4.98G [00:32<06:38, 11.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|â–ˆ         | 557M/4.98G [00:32<06:23, 11.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|â–ˆ         | 560M/4.98G [00:32<06:12, 11.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|â–ˆâ–        | 562M/4.98G [00:33<09:56, 7.40MB/s]\n",
      "model-00001-of-00004.safetensors:  11%|â–ˆâ–        | 568M/4.98G [00:33<06:12, 11.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|â–ˆâ–        | 575M/4.98G [00:33<04:15, 17.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|â–ˆâ–        | 578M/4.98G [00:33<05:13, 14.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|â–ˆâ–        | 588M/4.98G [00:34<03:08, 23.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  12%|â–ˆâ–        | 593M/4.98G [00:34<03:49, 19.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|â–ˆâ–        | 603M/4.98G [00:34<02:29, 29.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  12%|â–ˆâ–        | 609M/4.98G [00:34<03:07, 23.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|â–ˆâ–        | 616M/4.98G [00:35<02:25, 30.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|â–ˆâ–        | 622M/4.98G [00:35<02:11, 33.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|â–ˆâ–        | 627M/4.98G [00:36<06:31, 11.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|â–ˆâ–        | 632M/4.98G [00:36<05:14, 13.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|â–ˆâ–        | 637M/4.98G [00:36<04:13, 17.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|â–ˆâ–        | 650M/4.98G [00:37<03:15, 22.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|â–ˆâ–        | 655M/4.98G [00:37<02:47, 25.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|â–ˆâ–        | 670M/4.98G [00:37<02:19, 30.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|â–ˆâ–        | 675M/4.98G [00:38<03:08, 22.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|â–ˆâ–        | 687M/4.98G [00:38<02:02, 35.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|â–ˆâ–        | 693M/4.98G [00:38<02:49, 25.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|â–ˆâ–        | 702M/4.98G [00:38<02:06, 33.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|â–ˆâ–        | 714M/4.98G [00:39<02:20, 30.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|â–ˆâ–        | 720M/4.98G [00:39<03:05, 23.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|â–ˆâ–        | 734M/4.98G [00:40<02:01, 35.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|â–ˆâ–        | 740M/4.98G [00:40<02:51, 24.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|â–ˆâ–        | 746M/4.98G [00:40<02:28, 28.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|â–ˆâ–Œ        | 752M/4.98G [00:41<03:06, 22.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|â–ˆâ–Œ        | 765M/4.98G [00:41<01:54, 36.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  16%|â–ˆâ–Œ        | 778M/4.98G [00:41<02:08, 32.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|â–ˆâ–Œ        | 783M/4.98G [00:41<01:58, 35.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  16%|â–ˆâ–Œ        | 794M/4.98G [00:42<02:20, 29.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  16%|â–ˆâ–Œ        | 800M/4.98G [00:42<02:57, 23.5MB/s]\n",
      "model-00001-of-00004.safetensors:  16%|â–ˆâ–‹        | 813M/4.98G [00:42<02:08, 32.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|â–ˆâ–‹        | 817M/4.98G [00:43<03:03, 22.7MB/s]\n",
      "model-00001-of-00004.safetensors:  17%|â–ˆâ–‹        | 829M/4.98G [00:43<02:05, 33.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|â–ˆâ–‹        | 847M/4.98G [00:44<02:08, 32.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|â–ˆâ–‹        | 857M/4.98G [00:44<02:36, 26.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|â–ˆâ–‹        | 864M/4.98G [00:44<02:03, 33.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|â–ˆâ–‹        | 868M/4.98G [00:45<03:03, 22.4MB/s]\n",
      "model-00001-of-00004.safetensors:  18%|â–ˆâ–Š        | 874M/4.98G [00:45<02:27, 27.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  18%|â–ˆâ–Š        | 880M/4.98G [00:45<03:00, 22.7MB/s]\n",
      "model-00001-of-00004.safetensors:  18%|â–ˆâ–Š        | 890M/4.98G [00:45<02:05, 32.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|â–ˆâ–Š        | 896M/4.98G [00:46<02:45, 24.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  18%|â–ˆâ–Š        | 906M/4.98G [00:46<01:58, 34.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  18%|â–ˆâ–Š        | 911M/4.98G [00:46<01:50, 36.7MB/s]\n",
      "model-00001-of-00004.safetensors:  18%|â–ˆâ–Š        | 916M/4.98G [00:46<02:34, 26.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|â–ˆâ–Š        | 926M/4.98G [00:46<01:52, 36.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  19%|â–ˆâ–Š        | 932M/4.98G [00:47<02:37, 25.7MB/s]\n",
      "model-00001-of-00004.safetensors:  19%|â–ˆâ–‰        | 938M/4.98G [00:47<02:12, 30.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  19%|â–ˆâ–‰        | 944M/4.98G [00:47<02:59, 22.5MB/s]\n",
      "model-00001-of-00004.safetensors:  19%|â–ˆâ–‰        | 959M/4.98G [00:48<01:55, 34.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  19%|â–ˆâ–‰        | 970M/4.98G [00:48<02:19, 28.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|â–ˆâ–‰        | 975M/4.98G [00:48<02:03, 32.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|â–ˆâ–‰        | 988M/4.98G [00:49<02:12, 30.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|â–ˆâ–‰        | 992M/4.98G [00:49<02:59, 22.2MB/s]\n",
      "model-00001-of-00004.safetensors:  20%|â–ˆâ–ˆ        | 1.00G/4.98G [00:49<02:20, 28.3MB/s]\n",
      "model-00001-of-00004.safetensors:  20%|â–ˆâ–ˆ        | 1.00G/4.98G [00:49<02:11, 30.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|â–ˆâ–ˆ        | 1.01G/4.98G [00:50<03:20, 19.8MB/s]\n",
      "model-00001-of-00004.safetensors:  21%|â–ˆâ–ˆ        | 1.02G/4.98G [00:50<02:00, 32.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  21%|â–ˆâ–ˆ        | 1.03G/4.98G [00:51<02:20, 28.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  21%|â–ˆâ–ˆ        | 1.04G/4.98G [00:51<03:57, 16.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|â–ˆâ–ˆ        | 1.05G/4.98G [00:51<02:58, 22.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|â–ˆâ–ˆ        | 1.05G/4.98G [00:51<02:35, 25.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|â–ˆâ–ˆâ–       | 1.07G/4.98G [00:52<02:09, 30.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  22%|â–ˆâ–ˆâ–       | 1.08G/4.98G [00:53<02:03, 31.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|â–ˆâ–ˆâ–       | 1.09G/4.98G [00:53<02:45, 23.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|â–ˆâ–ˆâ–       | 1.10G/4.98G [00:53<02:12, 29.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|â–ˆâ–ˆâ–       | 1.10G/4.98G [00:53<02:04, 31.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|â–ˆâ–ˆâ–       | 1.10G/4.98G [00:54<02:44, 23.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|â–ˆâ–ˆâ–       | 1.12G/4.98G [00:54<01:46, 36.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  23%|â–ˆâ–ˆâ–       | 1.12G/4.98G [00:54<02:26, 26.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|â–ˆâ–ˆâ–       | 1.13G/4.98G [00:54<01:58, 32.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|â–ˆâ–ˆâ–       | 1.14G/4.98G [00:54<01:50, 34.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  23%|â–ˆâ–ˆâ–       | 1.14G/4.98G [00:55<02:47, 22.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|â–ˆâ–ˆâ–       | 1.15G/4.98G [00:55<02:17, 27.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|â–ˆâ–ˆâ–       | 1.15G/4.98G [00:55<01:57, 32.7MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  23%|â–ˆâ–ˆâ–       | 1.16G/4.98G [00:59<15:37, 4.07MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|â–ˆâ–ˆâ–       | 1.16G/4.98G [00:59<11:27, 5.55MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  23%|â–ˆâ–ˆâ–       | 1.17G/4.98G [00:59<08:42, 7.30MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  24%|â–ˆâ–ˆâ–       | 1.18G/4.98G [01:00<05:22, 11.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  24%|â–ˆâ–ˆâ–       | 1.18G/4.98G [01:00<04:08, 15.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  24%|â–ˆâ–ˆâ–       | 1.20G/4.98G [01:00<02:53, 21.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  24%|â–ˆâ–ˆâ–       | 1.21G/4.98G [01:01<02:18, 27.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|â–ˆâ–ˆâ–       | 1.23G/4.98G [01:01<01:55, 32.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|â–ˆâ–ˆâ–       | 1.24G/4.98G [01:02<02:00, 31.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|â–ˆâ–ˆâ–Œ       | 1.26G/4.98G [01:03<01:47, 34.7MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  26%|â–ˆâ–ˆâ–Œ       | 1.27G/4.98G [01:03<02:09, 28.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  26%|â–ˆâ–ˆâ–Œ       | 1.28G/4.98G [01:03<02:03, 30.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  26%|â–ˆâ–ˆâ–Œ       | 1.29G/4.98G [01:04<02:22, 25.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  26%|â–ˆâ–ˆâ–Œ       | 1.29G/4.98G [01:04<02:05, 29.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  26%|â–ˆâ–ˆâ–‹       | 1.31G/4.98G [01:04<02:03, 29.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  26%|â–ˆâ–ˆâ–‹       | 1.31G/4.98G [01:05<03:10, 19.3MB/s]\n",
      "model-00001-of-00004.safetensors:  27%|â–ˆâ–ˆâ–‹       | 1.32G/4.98G [01:05<01:55, 31.7MB/s]\n",
      "model-00004-of-00004.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.17G/1.17G [01:05<00:00, 17.8MB/s]\n",
      "model-00001-of-00004.safetensors:  27%|â–ˆâ–ˆâ–‹       | 1.34G/4.98G [01:06<01:44, 34.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  27%|â–ˆâ–ˆâ–‹       | 1.36G/4.98G [01:06<01:52, 32.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  28%|â–ˆâ–ˆâ–Š       | 1.39G/4.98G [01:07<01:50, 32.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  28%|â–ˆâ–ˆâ–Š       | 1.39G/4.98G [01:08<02:22, 25.1MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|â–ˆâ–ˆâ–Š       | 1.41G/4.98G [01:08<01:39, 35.9MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|â–ˆâ–ˆâ–Š       | 1.41G/4.98G [01:08<02:10, 27.3MB/s]\n",
      "model-00001-of-00004.safetensors:  28%|â–ˆâ–ˆâ–Š       | 1.42G/4.98G [01:08<01:45, 33.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  30%|â–ˆâ–ˆâ–‰       | 1.47G/4.98G [01:10<01:50, 31.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  30%|â–ˆâ–ˆâ–‰       | 1.48G/4.98G [01:10<02:11, 26.6MB/s]\n",
      "model-00001-of-00004.safetensors:  30%|â–ˆâ–ˆâ–‰       | 1.49G/4.98G [01:11<02:02, 28.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  30%|â–ˆâ–ˆâ–ˆ       | 1.50G/4.98G [01:11<02:04, 28.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  30%|â–ˆâ–ˆâ–ˆ       | 1.52G/4.98G [01:12<01:54, 30.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  31%|â–ˆâ–ˆâ–ˆ       | 1.53G/4.98G [01:12<01:41, 34.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  31%|â–ˆâ–ˆâ–ˆ       | 1.55G/4.98G [01:13<01:35, 35.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  31%|â–ˆâ–ˆâ–ˆâ–      | 1.56G/4.98G [01:13<02:03, 27.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  32%|â–ˆâ–ˆâ–ˆâ–      | 1.58G/4.98G [01:14<01:28, 38.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  32%|â–ˆâ–ˆâ–ˆâ–      | 1.60G/4.98G [01:14<01:27, 38.7MB/s]\n",
      "model-00001-of-00004.safetensors:  32%|â–ˆâ–ˆâ–ˆâ–      | 1.61G/4.98G [01:15<01:53, 29.7MB/s]\n",
      "model-00001-of-00004.safetensors:  32%|â–ˆâ–ˆâ–ˆâ–      | 1.61G/4.98G [01:15<01:43, 32.6MB/s]\n",
      "model-00001-of-00004.safetensors:  34%|â–ˆâ–ˆâ–ˆâ–      | 1.70G/4.98G [01:17<01:23, 39.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  34%|â–ˆâ–ˆâ–ˆâ–      | 1.71G/4.98G [01:18<01:39, 33.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  35%|â–ˆâ–ˆâ–ˆâ–      | 1.73G/4.98G [01:19<01:25, 37.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  35%|â–ˆâ–ˆâ–ˆâ–      | 1.73G/4.98G [01:19<01:57, 27.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.75G/4.98G [01:20<01:42, 31.5MB/s]\n",
      "model-00001-of-00004.safetensors:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.76G/4.98G [01:20<01:33, 34.4MB/s]\n",
      "model-00001-of-00004.safetensors:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.77G/4.98G [01:20<01:36, 33.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.79G/4.98G [01:21<01:41, 31.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 1.81G/4.98G [01:21<01:22, 38.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.82G/4.98G [01:22<01:44, 30.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.82G/4.98G [01:22<02:22, 22.1MB/s]\n",
      "model-00001-of-00004.safetensors:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.83G/4.98G [01:22<01:47, 29.2MB/s]\n",
      "model-00001-of-00004.safetensors:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.84G/4.98G [01:22<01:31, 34.3MB/s]\n",
      "model-00001-of-00004.safetensors:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.85G/4.98G [01:23<01:39, 31.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.87G/4.98G [01:23<01:31, 34.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.88G/4.98G [01:24<01:28, 34.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.89G/4.98G [01:24<01:48, 28.6MB/s]\n",
      "model-00001-of-00004.safetensors:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.90G/4.98G [01:25<01:17, 39.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.91G/4.98G [01:25<01:50, 27.8MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 1.92G/4.98G [01:25<01:27, 35.0MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 1.92G/4.98G [01:25<01:56, 26.2MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.93G/4.98G [01:26<01:38, 30.9MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.93G/4.98G [01:26<01:28, 34.5MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.94G/4.98G [01:26<02:01, 25.0MB/s]\n",
      "model-00001-of-00004.safetensors:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.95G/4.98G [01:26<01:33, 32.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.96G/4.98G [01:27<01:39, 30.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 1.98G/4.98G [01:27<01:38, 30.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2.00G/4.98G [01:28<01:15, 39.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2.01G/4.98G [01:28<01:18, 37.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2.03G/4.98G [01:29<01:20, 36.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2.05G/4.98G [01:30<02:09, 22.7MB/s]\n",
      "model-00001-of-00004.safetensors:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.06G/4.98G [01:30<01:35, 30.7MB/s]\n",
      "model-00001-of-00004.safetensors:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.07G/4.98G [01:30<01:48, 26.9MB/s]\n",
      "model-00001-of-00004.safetensors:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.08G/4.98G [01:30<01:23, 34.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.08G/4.98G [01:31<02:10, 22.1MB/s]\n",
      "model-00001-of-00004.safetensors:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.09G/4.98G [01:31<01:21, 35.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.11G/4.98G [01:32<02:01, 23.7MB/s]\n",
      "model-00001-of-00004.safetensors:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.11G/4.98G [01:32<01:48, 26.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.13G/4.98G [01:33<01:45, 26.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.13G/4.98G [01:33<02:13, 21.2MB/s]\n",
      "model-00001-of-00004.safetensors:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.14G/4.98G [01:33<01:50, 25.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.16G/4.98G [01:34<01:32, 30.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.17G/4.98G [01:34<01:22, 34.0MB/s]\n",
      "model-00001-of-00004.safetensors:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.18G/4.98G [01:35<01:49, 25.6MB/s]\n",
      "model-00001-of-00004.safetensors:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.18G/4.98G [01:35<01:42, 27.2MB/s]\n",
      "model-00001-of-00004.safetensors:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.19G/4.98G [01:35<01:35, 29.3MB/s]\n",
      "model-00001-of-00004.safetensors:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.19G/4.98G [01:35<02:27, 18.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.20G/4.98G [01:36<01:38, 28.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.21G/4.98G [01:36<03:19, 13.9MB/s]\n",
      "model-00001-of-00004.safetensors:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.22G/4.98G [01:37<01:47, 25.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2.24G/4.98G [01:37<01:21, 33.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2.26G/4.98G [01:38<01:15, 36.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2.26G/4.98G [01:38<01:46, 25.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2.28G/4.98G [01:39<01:24, 32.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2.30G/4.98G [01:39<01:13, 36.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2.31G/4.98G [01:40<01:31, 29.2MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2.32G/4.98G [01:40<01:21, 32.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2.33G/4.98G [01:40<01:17, 34.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2.35G/4.98G [01:41<01:17, 34.2MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2.35G/4.98G [01:41<01:30, 29.1MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2.36G/4.98G [01:41<01:13, 35.7MB/s]\n",
      "model-00001-of-00004.safetensors:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2.37G/4.98G [01:42<01:23, 31.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2.38G/4.98G [01:42<01:11, 36.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2.39G/4.98G [01:42<01:45, 24.6MB/s]\n",
      "model-00001-of-00004.safetensors:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2.40G/4.98G [01:42<01:15, 34.1MB/s]\n",
      "model-00001-of-00004.safetensors:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2.40G/4.98G [01:43<01:47, 24.0MB/s]\n",
      "model-00001-of-00004.safetensors:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2.41G/4.98G [01:43<01:29, 28.8MB/s]\n",
      "model-00001-of-00004.safetensors:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2.41G/4.98G [01:43<01:25, 30.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2.42G/4.98G [01:44<02:35, 16.5MB/s]\n",
      "model-00001-of-00004.safetensors:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2.43G/4.98G [01:44<01:42, 24.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2.44G/4.98G [01:44<01:47, 23.6MB/s]\n",
      "model-00001-of-00004.safetensors:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2.44G/4.98G [01:45<01:30, 28.1MB/s]\n",
      "model-00001-of-00004.safetensors:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2.46G/4.98G [01:45<01:23, 30.0MB/s]\n",
      "model-00001-of-00004.safetensors:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2.46G/4.98G [01:45<01:17, 32.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2.47G/4.98G [01:46<01:53, 22.2MB/s]\n",
      "model-00001-of-00004.safetensors:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2.47G/4.98G [01:46<01:33, 26.8MB/s]\n",
      "model-00001-of-00004.safetensors:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2.48G/4.98G [01:46<01:21, 30.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.49G/4.98G [01:46<01:40, 24.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.50G/4.98G [01:47<01:59, 20.7MB/s]\n",
      "model-00001-of-00004.safetensors:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.50G/4.98G [01:47<01:26, 28.6MB/s]\n",
      "model-00001-of-00004.safetensors:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.51G/4.98G [01:47<01:38, 25.1MB/s]\n",
      "model-00001-of-00004.safetensors:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.53G/4.98G [01:48<01:04, 37.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.53G/4.98G [01:48<01:57, 20.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.54G/4.98G [01:49<02:28, 16.4MB/s]\n",
      "model-00001-of-00004.safetensors:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.54G/4.98G [01:49<02:53, 14.1MB/s]\n",
      "model-00001-of-00004.safetensors:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.54G/4.98G [01:49<02:55, 13.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2.54G/4.98G [01:50<04:37, 8.76MB/s]\n",
      "model-00001-of-00004.safetensors:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.55G/4.98G [01:50<02:47, 14.5MB/s]\n",
      "model-00001-of-00004.safetensors:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.56G/4.98G [01:50<02:25, 16.7MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.56G/4.98G [01:50<02:28, 16.3MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.57G/4.98G [01:51<01:45, 22.8MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.57G/4.98G [01:51<01:30, 26.6MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.59G/4.98G [01:51<01:31, 26.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.60G/4.98G [01:52<01:29, 26.6MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.61G/4.98G [01:52<01:19, 29.7MB/s]\n",
      "model-00001-of-00004.safetensors:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.61G/4.98G [01:52<01:43, 22.8MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.62G/4.98G [01:52<01:27, 27.1MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.63G/4.98G [01:53<01:51, 21.0MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.63G/4.98G [01:53<01:20, 29.1MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.64G/4.98G [01:53<01:10, 33.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.64G/4.98G [01:53<01:40, 23.2MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.65G/4.98G [01:54<01:10, 33.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.66G/4.98G [01:54<01:13, 31.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.68G/4.98G [01:55<01:01, 37.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.70G/4.98G [01:55<01:04, 35.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.71G/4.98G [01:56<01:11, 31.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.73G/4.98G [01:56<01:26, 26.1MB/s]\n",
      "model-00001-of-00004.safetensors:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2.73G/4.98G [01:56<01:12, 31.0MB/s]\n",
      "model-00001-of-00004.safetensors:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.75G/4.98G [01:57<01:06, 33.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.77G/4.98G [01:57<00:57, 38.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.78G/4.98G [01:58<01:00, 36.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2.80G/4.98G [01:59<01:13, 29.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.80G/4.98G [01:59<01:56, 18.7MB/s]\n",
      "model-00001-of-00004.safetensors:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.81G/4.98G [02:00<01:25, 25.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.83G/4.98G [02:00<01:14, 28.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.85G/4.98G [02:01<01:01, 34.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.91G/4.98G [02:03<01:05, 31.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.93G/4.98G [02:03<00:59, 34.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.94G/4.98G [02:04<00:56, 35.9MB/s]\n",
      "model-00001-of-00004.safetensors:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.96G/4.98G [02:04<00:53, 37.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.97G/4.98G [02:05<01:12, 27.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.99G/4.98G [02:05<00:53, 37.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3.01G/4.98G [02:06<01:01, 31.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3.02G/4.98G [02:07<01:19, 24.7MB/s]\n",
      "model-00001-of-00004.safetensors:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3.02G/4.98G [02:07<01:07, 29.1MB/s]\n",
      "model-00001-of-00004.safetensors:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3.03G/4.98G [02:07<01:30, 21.5MB/s]\n",
      "model-00001-of-00004.safetensors:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3.03G/4.98G [02:07<01:12, 26.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.05G/4.98G [02:08<00:58, 33.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.07G/4.98G [02:08<00:53, 35.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.08G/4.98G [02:09<00:48, 39.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.10G/4.98G [02:10<00:59, 31.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.12G/4.98G [02:10<00:50, 36.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.13G/4.98G [02:10<01:00, 30.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.15G/4.98G [02:11<00:56, 32.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.16G/4.98G [02:12<00:57, 31.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.18G/4.98G [02:12<00:49, 36.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.19G/4.98G [02:13<00:59, 29.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.22G/4.98G [02:13<00:48, 36.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3.23G/4.98G [02:14<00:50, 34.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3.25G/4.98G [02:14<00:44, 39.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3.26G/4.98G [02:15<00:48, 35.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3.27G/4.98G [02:15<00:49, 34.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3.29G/4.98G [02:16<00:46, 36.3MB/s]\n",
      "model-00001-of-00004.safetensors:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3.30G/4.98G [02:16<01:01, 27.3MB/s]\n",
      "model-00001-of-00004.safetensors:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3.31G/4.98G [02:16<00:43, 38.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3.49G/4.98G [02:22<00:37, 39.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3.49G/4.98G [02:23<00:46, 32.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3.51G/4.98G [02:23<00:42, 34.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3.53G/4.98G [02:24<00:43, 33.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.55G/4.98G [02:24<00:41, 34.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.56G/4.98G [02:25<00:37, 37.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.57G/4.98G [02:25<00:49, 28.4MB/s]\n",
      "model-00001-of-00004.safetensors:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.58G/4.98G [02:25<00:38, 36.2MB/s]\n",
      "model-00001-of-00004.safetensors:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.60G/4.98G [02:26<00:34, 39.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.61G/4.98G [02:26<00:49, 27.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.63G/4.98G [02:27<00:35, 38.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.64G/4.98G [02:27<00:44, 30.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.67G/4.98G [02:28<00:43, 29.9MB/s]\n",
      "model-00001-of-00004.safetensors:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.69G/4.98G [02:29<00:33, 38.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.70G/4.98G [02:29<00:42, 30.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 3.73G/4.98G [02:30<00:31, 39.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3.73G/4.98G [02:30<00:38, 31.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3.76G/4.98G [02:31<00:32, 37.6MB/s]\n",
      "model-00001-of-00004.safetensors:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3.76G/4.98G [02:31<00:36, 33.1MB/s]\n",
      "model-00001-of-00004.safetensors:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3.77G/4.98G [02:31<00:33, 36.5MB/s]\n",
      "model-00001-of-00004.safetensors:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3.79G/4.98G [02:32<00:32, 36.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.81G/4.98G [02:32<00:27, 42.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.81G/4.98G [02:33<00:38, 29.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.83G/4.98G [02:33<00:33, 33.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3.85G/4.98G [02:34<00:30, 36.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.87G/4.98G [02:34<00:28, 39.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.89G/4.98G [02:35<00:30, 35.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.90G/4.98G [02:36<00:33, 31.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.90G/4.98G [02:36<00:49, 21.6MB/s]\n",
      "model-00001-of-00004.safetensors:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3.92G/4.98G [02:36<00:31, 33.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.94G/4.98G [02:37<00:27, 38.6MB/s]\n",
      "model-00001-of-00004.safetensors:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.94G/4.98G [02:37<00:35, 29.4MB/s]\n",
      "model-00001-of-00004.safetensors:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.95G/4.98G [02:37<00:31, 32.2MB/s]\n",
      "model-00001-of-00004.safetensors:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.96G/4.98G [02:38<00:30, 33.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.97G/4.98G [02:38<00:45, 22.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3.98G/4.98G [02:38<00:32, 30.8MB/s]\n",
      "model-00001-of-00004.safetensors:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4.00G/4.98G [02:39<00:25, 38.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4.01G/4.98G [02:39<00:32, 30.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4.02G/4.98G [02:40<00:28, 33.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4.04G/4.98G [02:40<00:27, 34.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.06G/4.98G [02:41<00:26, 34.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.07G/4.98G [02:41<00:25, 35.6MB/s]\n",
      "model-00001-of-00004.safetensors:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.09G/4.98G [02:42<00:23, 38.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.11G/4.98G [02:42<00:20, 42.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.12G/4.98G [02:43<00:36, 23.8MB/s]\n",
      "model-00001-of-00004.safetensors:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.12G/4.98G [02:43<00:32, 25.9MB/s]\n",
      "model-00001-of-00004.safetensors:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.15G/4.98G [02:44<00:24, 34.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.17G/4.98G [02:45<00:22, 35.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.19G/4.98G [02:45<00:24, 32.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.19G/4.98G [02:46<00:32, 24.2MB/s]\n",
      "model-00001-of-00004.safetensors:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.20G/4.98G [02:46<00:33, 23.1MB/s]\n",
      "model-00001-of-00004.safetensors:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.20G/4.98G [02:46<00:42, 18.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.20G/4.98G [02:47<01:10, 11.0MB/s]\n",
      "model-00001-of-00004.safetensors:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.21G/4.98G [02:47<01:07, 11.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.21G/4.98G [02:48<01:47, 7.15MB/s]\n",
      "model-00001-of-00004.safetensors:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.22G/4.98G [02:48<00:38, 19.3MB/s]\n",
      "model-00001-of-00004.safetensors:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.23G/4.98G [02:49<00:44, 17.0MB/s]\n",
      "model-00001-of-00004.safetensors:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4.23G/4.98G [02:49<00:31, 23.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4.24G/4.98G [02:49<00:40, 18.0MB/s]\n",
      "model-00001-of-00004.safetensors:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4.25G/4.98G [02:49<00:27, 26.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4.27G/4.98G [02:50<00:22, 31.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 4.29G/4.98G [02:51<00:20, 33.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4.30G/4.98G [02:51<00:20, 33.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4.31G/4.98G [02:52<00:22, 29.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4.34G/4.98G [02:52<00:18, 35.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4.35G/4.98G [02:53<00:19, 32.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 4.35G/4.98G [02:53<00:27, 22.4MB/s]\n",
      "model-00001-of-00004.safetensors:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4.37G/4.98G [02:54<00:24, 25.2MB/s]\n",
      "model-00001-of-00004.safetensors:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4.38G/4.98G [02:54<00:17, 33.6MB/s]\n",
      "model-00001-of-00004.safetensors:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4.38G/4.98G [02:54<00:16, 36.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4.39G/4.98G [02:54<00:22, 25.8MB/s]\n",
      "model-00001-of-00004.safetensors:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4.39G/4.98G [02:54<00:19, 29.5MB/s]\n",
      "model-00001-of-00004.safetensors:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4.40G/4.98G [02:54<00:16, 35.1MB/s]\n",
      "model-00001-of-00004.safetensors:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4.40G/4.98G [02:55<00:23, 24.2MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4.41G/4.98G [02:55<00:19, 28.8MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 4.41G/4.98G [02:55<00:17, 32.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4.42G/4.98G [02:56<00:29, 19.1MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4.43G/4.98G [02:56<00:17, 31.9MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4.44G/4.98G [02:56<00:23, 23.3MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4.44G/4.98G [02:56<00:19, 28.0MB/s]\n",
      "model-00001-of-00004.safetensors:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4.45G/4.98G [02:57<00:24, 22.0MB/s]\n",
      "model-00001-of-00004.safetensors:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4.46G/4.98G [02:57<00:16, 32.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 4.48G/4.98G [02:57<00:14, 34.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4.49G/4.98G [02:58<00:12, 38.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4.51G/4.98G [02:58<00:12, 36.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4.52G/4.98G [02:59<00:14, 31.4MB/s]\n",
      "model-00001-of-00004.safetensors:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4.53G/4.98G [02:59<00:17, 25.9MB/s]\n",
      "model-00001-of-00004.safetensors:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4.54G/4.98G [02:59<00:13, 32.8MB/s]\n",
      "model-00001-of-00004.safetensors:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.54G/4.98G [02:59<00:11, 36.3MB/s]\n",
      "model-00001-of-00004.safetensors:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.56G/4.98G [03:00<00:11, 36.7MB/s]\n",
      "model-00001-of-00004.safetensors:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.56G/4.98G [03:00<00:15, 26.8MB/s]\n",
      "model-00001-of-00004.safetensors:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.59G/4.98G [03:01<00:09, 38.8MB/s]\n",
      "model-00001-of-00004.safetensors:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.60G/4.98G [03:01<00:13, 27.8MB/s]\n",
      "model-00001-of-00004.safetensors:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.60G/4.98G [03:02<00:14, 25.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.61G/4.98G [03:02<00:24, 15.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.62G/4.98G [03:03<00:25, 14.0MB/s]\n",
      "model-00001-of-00004.safetensors:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.62G/4.98G [03:04<00:24, 14.3MB/s]\n",
      "model-00001-of-00004.safetensors:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.63G/4.98G [03:04<00:16, 20.5MB/s]\n",
      "model-00001-of-00004.safetensors:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.64G/4.98G [03:04<00:13, 25.3MB/s]\n",
      "model-00001-of-00004.safetensors:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.64G/4.98G [03:04<00:15, 21.6MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.66G/4.98G [03:05<00:14, 21.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.67G/4.98G [03:05<00:10, 30.7MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.67G/4.98G [03:05<00:09, 33.6MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.68G/4.98G [03:06<00:12, 23.7MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.68G/4.98G [03:06<00:10, 27.3MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.69G/4.98G [03:06<00:13, 21.0MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.70G/4.98G [03:06<00:09, 28.4MB/s]\n",
      "model-00001-of-00004.safetensors:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.70G/4.98G [03:06<00:09, 30.5MB/s]\n",
      "model-00001-of-00004.safetensors:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.71G/4.98G [03:07<00:14, 19.3MB/s]\n",
      "model-00001-of-00004.safetensors:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.71G/4.98G [03:07<00:09, 27.1MB/s]\n",
      "model-00001-of-00004.safetensors:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.72G/4.98G [03:07<00:08, 29.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 4.72G/4.98G [03:07<00:12, 20.7MB/s]\n",
      "model-00001-of-00004.safetensors:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4.73G/4.98G [03:08<00:08, 29.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4.75G/4.98G [03:08<00:06, 34.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4.77G/4.98G [03:09<00:08, 23.5MB/s]\n",
      "model-00001-of-00004.safetensors:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 4.78G/4.98G [03:09<00:05, 35.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 4.80G/4.98G [03:10<00:05, 34.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 4.80G/4.98G [03:10<00:06, 27.5MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 4.82G/4.98G [03:11<00:06, 24.5MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 4.83G/4.98G [03:11<00:04, 34.4MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 4.83G/4.98G [03:11<00:04, 35.9MB/s]\n",
      "model-00001-of-00004.safetensors:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 4.84G/4.98G [03:11<00:05, 25.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 4.84G/4.98G [03:12<00:04, 30.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4.85G/4.98G [03:12<00:04, 26.2MB/s]\n",
      "model-00001-of-00004.safetensors:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4.86G/4.98G [03:12<00:04, 27.8MB/s]\n",
      "model-00001-of-00004.safetensors:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4.86G/4.98G [03:12<00:03, 29.6MB/s]\n",
      "model-00001-of-00004.safetensors:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4.87G/4.98G [03:13<00:04, 21.9MB/s]\n",
      "model-00001-of-00004.safetensors:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4.87G/4.98G [03:13<00:03, 26.8MB/s]\n",
      "model-00001-of-00004.safetensors:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4.88G/4.98G [03:13<00:03, 31.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4.89G/4.98G [03:13<00:03, 28.7MB/s]\n",
      "model-00001-of-00004.safetensors:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4.90G/4.98G [03:14<00:03, 22.7MB/s]\n",
      "model-00001-of-00004.safetensors:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 4.91G/4.98G [03:14<00:02, 31.8MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4.92G/4.98G [03:15<00:04, 13.4MB/s]\n",
      "model-00001-of-00004.safetensors:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4.92G/4.98G [03:15<00:02, 21.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4.94G/4.98G [03:16<00:01, 26.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4.96G/4.98G [03:16<00:00, 33.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4.97G/4.98G [03:17<00:00, 34.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.98G/4.98G [03:17<00:00, 25.2MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00003-of-00004.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.92G/4.92G [03:26<00:00, 23.8MB/s]\n",
      "model-00002-of-00004.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.00G/5.00G [03:32<00:00, 23.5MB/s]\n",
      "\n",
      "\n",
      "Upload 4 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [03:32<00:00, 53.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Saved merged model to https://huggingface.co/None/Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38\n"
     ]
    }
   ],
   "source": [
    "# Hub ì— ì—…ë¡œë“œ\n",
    "model.push_to_hub_merged(\n",
    "    huggingface_repo,\n",
    "    tokenizer,\n",
    "    save_method=save_method,\n",
    "    token=huggingface_token,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model reload and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.43.3.\n",
      "   \\\\   /|    GPU: NVIDIA RTX A5000. Max memory: 23.677 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.1.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.22.post7+cu118. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 4096  # ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ë‚´ë¶€ì ìœ¼ë¡œ RoPE ìŠ¤ì¼€ì¼ë§ì„ ìë™ìœ¼ë¡œ ì§€ì›í•©ë‹ˆë‹¤!\n",
    "# ìë™ ê°ì§€ë¥¼ ìœ„í•´ Noneì„ ì‚¬ìš©í•©ë‹ˆë‹¤. Tesla T4, V100ì€ Float16, Ampere+ëŠ” Bfloat16ì„ ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "dtype = None\n",
    "# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ 4bit ì–‘ìí™”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. Falseì¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
    "load_in_4bit = True\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    # model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n",
    "    model_name=\"/home/jaesung/jaesung/pulmuone/text-generation-webui/models/Llama-3-Open-Ko-8B-Instruct-PM1-completion-v2-60-gguf\",\n",
    "    max_seq_length=max_seq_length,  # ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    dtype=dtype,  # ë°ì´í„° íƒ€ì…ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    load_in_4bit=load_in_4bit,  # 4bit ì–‘ìí™” ë¡œë“œ ì—¬ë¶€ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    # token = \"hf_...\", # ê²Œì´íŠ¸ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° í† í°ì„ ì‚¬ìš©í•˜ì„¸ìš”. ì˜ˆ: meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# EOS_TOKENì€ ë¬¸ì¥ì˜ ëì„ ë‚˜íƒ€ë‚´ëŠ” í† í°ì…ë‹ˆë‹¤. ì´ í† í°ì„ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "# AlpacaPromptë¥¼ ì‚¬ìš©í•˜ì—¬ ì§€ì‹œì‚¬í•­ì„ í¬ë§·íŒ…í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "\n",
    "# ì£¼ì–´ì§„ ì˜ˆì‹œë“¤ì„ í¬ë§·íŒ…í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"QUESTION\"]  # ì§€ì‹œì‚¬í•­ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    outputs = examples[\"ANSWER\"]  # ì¶œë ¥ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    texts = []  # í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n",
    "    for instruction, output in zip(instructions, outputs):\n",
    "        # EOS_TOKENì„ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ìƒì„±ì´ ë¬´í•œíˆ ì§„í–‰ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "        text = alpaca_prompt.format(instruction, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\n",
    "        \"text\": texts,  # í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    }\n",
    "\n",
    "# JSONL íŒŒì¼ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data\n",
    "\n",
    "# JSONL íŒŒì¼ ê²½ë¡œ\n",
    "file_path = '/home/jaesung/pulmuone/instruction_tuning_2/v4_completion/data/qa_pair_for_completion.jsonl'\n",
    "\n",
    "# JSONL íŒŒì¼ ë¡œë“œ\n",
    "data = load_jsonl(file_path)\n",
    "\n",
    "# pandas DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Dataset ê°ì²´ë¡œ ë³€í™˜\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# DatasetDict ê°ì²´ë¡œ ê²°í•©\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13676/13676 [00:00<00:00, 56412.33 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„°ì…‹ì— formatting_prompts_func í•¨ìˆ˜ë¥¼ ì ìš©í•©ë‹ˆë‹¤. ë°°ì¹˜ ì²˜ë¦¬ë¥¼ í™œì„±í™”í•©ë‹ˆë‹¤.\n",
    "dataset = dataset.map(\n",
    "    formatting_prompts_func,\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "import string\n",
    "\n",
    "class StopOnToken(StoppingCriteria):\n",
    "    def __init__(self, stop_token_id):\n",
    "        self.stop_token_id = stop_token_id  # ì •ì§€ í† í° IDë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        return (\n",
    "            self.stop_token_id in input_ids[0]\n",
    "        )  # ì…ë ¥ëœ ID ì¤‘ ì •ì§€ í† í° IDê°€ ìˆìœ¼ë©´ ì •ì§€í•©ë‹ˆë‹¤.\n",
    "\n",
    "class StopOnRepetitionPattern(StoppingCriteria):\n",
    "    def __init__(self, repetition_limit=3, tokenizer=None):\n",
    "        self.repetition_limit = repetition_limit\n",
    "        self.repetition_count = {}\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def extract_comma_segment(self, text):\n",
    "        # ì½¤ë§ˆë¡œ ë¶„ë¦¬ëœ êµ¬ ì¤‘ ë§ˆì§€ë§‰ êµ¬ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "        segments = text.split(',')\n",
    "        return segments[-1].strip().lower()\n",
    "    \n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        # í˜„ì¬ê¹Œì§€ ìƒì„±ëœ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ë””ì½”ë”©í•©ë‹ˆë‹¤.\n",
    "        generated_text = self.tokenizer.decode(input_ids[0], skip_special_tokens=True).strip()\n",
    "        comma_segment = self.extract_comma_segment(generated_text)\n",
    "        \n",
    "        if not comma_segment:\n",
    "            return False\n",
    "        \n",
    "        # ë§ˆì§€ë§‰ êµ¬ê°„ì—ì„œ ë‹¨ì–´ë¥¼ ë¶„ë¦¬\n",
    "        words = comma_segment.split()\n",
    "        \n",
    "        if len(words) == 1:  # ë§ˆì§€ë§‰ êµ¬ê°„ì— ë‹¨ì–´ê°€ í•˜ë‚˜ë§Œ ìˆë‹¤ë©´\n",
    "            word = words[0]\n",
    "            if word in self.repetition_count:\n",
    "                self.repetition_count[word] += 1\n",
    "            else:\n",
    "                self.repetition_count[word] = 1\n",
    "            \n",
    "            # ë§Œì•½ íŠ¹ì • ë‹¨ì–´ê°€ repetition_limit ì´ìƒ ë°˜ë³µë˜ë©´ ìƒì„±ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\n",
    "            if self.repetition_count[word] >= self.repetition_limit:\n",
    "                return True\n",
    "        else:\n",
    "            # ë‹¤ë¥¸ êµ¬ê°„ì´ ìƒì„±ë˜ë©´ ì¹´ìš´íŠ¸ ì´ˆê¸°í™”\n",
    "            self.repetition_count = {}\n",
    "        \n",
    "        return False\n",
    "    \n",
    "# end_tokenì„ ì„¤ì •\n",
    "stop_token = \"<|end_of_text|>\"  # end_tokenìœ¼ë¡œ ì‚¬ìš©í•  í† í°ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "stop_token_id = tokenizer.encode(stop_token, add_special_tokens=False)[\n",
    "    0\n",
    "]  # end_tokenì˜ IDë¥¼ ì¸ì½”ë”©í•©ë‹ˆë‹¤.\n",
    "\n",
    "# Stopping criteria ì„¤ì •\n",
    "stopping_criteria = StoppingCriteriaList(\n",
    "    [StopOnToken(stop_token_id),\n",
    "    StopOnRepetitionPattern(repetition_limit=5, tokenizer=tokenizer)\n",
    "    ] # ë™ì¼í•œ ë‹¨ì–´ê°€ 3ë²ˆ ë°˜ë³µë˜ë©´ ì •ì§€í•©ë‹ˆë‹¤.\n",
    ")  # ì •ì§€ ì¡°ê±´ì„ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QUESTION': {'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"ë°€ê°€ë£¨ì¤‘ë ¥1ë“±ê¸‰, ì–‘íŒŒë¶„, í‘œê³ ë²„ì„¯ë¶„ë§\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ì„¤íƒ•, ì˜¥ìˆ˜ìˆ˜ì „ë¶„, ì •ì œì†Œê¸ˆ, í‘í›„ì¶”ë¶„ë§\"',\n",
       "  'instruction': 'ë³µí•©ì¡°ë¯¸ì‹í’ˆ ì¹´í…Œê³ ë¦¬ì˜ í¬ë¦¼ì†ŒìŠ¤ë¶„ë§(ë‚´ì¸„ëŸ´ìŠ¤í‘¸ë“œ)ì— ì‚¬ìš©ë˜ëŠ” ëª‡ ê°€ì§€ ì¬ë£Œì…ë‹ˆë‹¤. ëˆ„ë½ëœ ì¬ë£Œë¥¼ ì°¾ì•„ë³´ì„¸ìš”.'},\n",
       " 'ANSWER': 'ì²´ë‹¤ì¹˜ì¦ˆíŒŒìš°ë”, í¬ë¦¼ë² ì´ìŠ¤, ë¶„ë§ìœ í¬ë¦¼, ë§í† ë±ìŠ¤íŠ¸ë¦°, ê±´ì¡°ê°ìë¶„ë§, ë§ˆëŠ˜ë¶„ë§',\n",
       " '__index_level_0__': 9955}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['test'][401]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"ì¹˜í‚¨í…ë”, í°ìŒ€ë² ì´ìŠ¤ë°¥\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ë¬¼ë°¤, ì´ë“ ë˜ë ì•„\"', 'instruction': 'ì¦‰ì„ì¡°ë¦¬ì‹í’ˆê°€ì—´ì„­ì·¨ëƒ‰ë™ì‹í’ˆ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ëª¨ì§œë ë¼ë¸Œë¦¬ë˜(ëƒ‰ë™)_ìŠ¤ìœ„íŠ¸í…ë”ì˜ ì¼ë¶€ ì¬ë£Œê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ì‹ì¬ë£Œë¥¼ ì¶”ì¸¡í•´ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì¹˜í‚¨í…ë”, í°ìŒ€ë² ì´ìŠ¤ë°¥, ëª¨ì§œë ë¼ì¹˜ì¦ˆ, ì´ë“ ë˜ë ì•„, íŒŒí”„ë¦¬ì¹´, ì–‘íŒŒ, ë§ˆëŠ˜, ì •ì œìˆ˜, ë°€ê°€ë£¨, ì†Œë§¥ì „ë¶„, ì •ì œì†Œê¸ˆ, ë°±ì„¤íƒ•, ì •ì œìˆ˜<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "# FastLanguageModelì„ ì´ìš©í•˜ì—¬ ì¶”ë¡  ì†ë„ë¥¼ 2ë°° ë¹ ë¥´ê²Œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "    [\n",
    "        alpaca_prompt.format(\n",
    "            dataset_dict['test'][10]['QUESTION'],\n",
    "\n",
    "           # {'instruction': 'ì´ ë‘ë¶€ë¥¼ ë§Œë“¤ ë•Œ ì‚¬ìš©í•  ëª‡ ê°€ì§€ ì¬ë£Œê°€ ì´ë¯¸ ì •í•´ì¡Œì–´. ì—¬ê¸°ì— ì–´ìš¸ë¦´ ë§Œí•œ ë‹¤ë¥¸ ì¬ë£Œë¥¼ ì œì•ˆí•´ì¤„ ìˆ˜ ìˆë‹ˆ?', 'ì œê³µëœ ì¬ë£Œ': 'ëŒ€ë‘', 'ì¹´í…Œê³ ë¦¬': 'ë‘ë¶€'}, # ì§€ì‹œì‚¬í•­\n",
    "            \"\",  # ì¶œë ¥ - ìƒì„±ì„ ìœ„í•´ ì´ ë¶€ë¶„ì„ ë¹„ì›Œë‘¡ë‹ˆë‹¤!\n",
    "        )\n",
    "    ],\n",
    "    return_tensors=\"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(\n",
    "    **inputs,\n",
    "    streamer=text_streamer,\n",
    "    max_new_tokens=4096,  # ìµœëŒ€ ìƒì„± í† í° ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    stopping_criteria=stopping_criteria  # ìƒì„±ì„ ë©ˆì¶œ ê¸°ì¤€ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    ")\n",
    "\n",
    "# output_list = tokenizer.batch_decode(_, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QUESTION': {'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"\"',\n",
       "  'instruction': 'ë†ì‚°ë¬¼ ì¹´í…Œê³ ë¦¬ì˜ ë¬´ë†ì•½êµ­ì‚°ì½©ìƒˆì˜¤ë¦¬ì•Œì½©ë‚˜ë¬¼_300gì— ì‚¬ìš©ë˜ëŠ” ëª‡ ê°€ì§€ ì¬ë£Œì…ë‹ˆë‹¤. ëˆ„ë½ëœ ì¬ë£Œë¥¼ ì°¾ì•„ë³´ì„¸ìš”.'},\n",
       " 'ANSWER': 'ë‚˜ë¬¼ì½©',\n",
       " '__index_level_0__': 3643}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['test'][70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['QUESTION', 'ANSWER', '__index_level_0__'],\n",
       "    num_rows: 2736\n",
       "})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"\"', 'instruction': 'ìˆ™ë©´ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ë½€ëª¨ë„ë¡œí† ë§ˆí† íŒŒìŠ¤íƒ€_190319ì˜ ì¼ë¶€ ì¬ë£Œê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ì‹ì¬ë£Œë¥¼ ì¶”ì¸¡í•´ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í† ë§ˆí† , íŒŒìŠ¤íƒ€ë©´, ë§ˆëŠ˜, ì–‘íŒŒ, ì •ì œìˆ˜, ì˜¬ë ˆì˜¤ë ˆì§„, ì •ì œì†Œê¸ˆ, ì •ì œìˆ˜<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"êµ­ì‚°ì½©ê°„ì¥, í’€ë¬´ì›ì ˆë‹¨ë‘ë¶€, í•´ì°¬ë“¤ì•Œì°¬ê³ ì¶”ì¥ê·¸ë¦°\"\\nì¼ë°˜ ì¬ë£Œ: \"ì•„ë¯¸ë…¸ë² ì´ìŠ¤\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ê³ ì¶§ê°€ë£¨, ëŒ€íŒŒ, ë¼ì§€ê³ ê¸°, ë¬¼ì—¿, ë°±ì„¤íƒ•, ìƒê°•, ì •ì œìˆ˜, ì½©ë°œíš¨ë§›ë‚´ê¸°ì§„, í™ê³ ì¶”\"', 'instruction': 'ì†ŒìŠ¤ë¥˜ ì¹´í…Œê³ ë¦¬ì˜ ì´ì§€ì¿¡ë§ˆíŒŒì†ŒìŠ¤ë‘ë¶€ì— ì‚¬ìš©ë˜ëŠ” ëª‡ ê°€ì§€ ì¬ë£Œì…ë‹ˆë‹¤. ëˆ„ë½ëœ ì¬ë£Œë¥¼ ì°¾ì•„ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ë‘ë¶€, ë§ˆíŒŒë‘ë¶€, ì •ì œì†Œê¸ˆ, ì •ì œìˆ˜, ì–‘ì¡°ê°„ì¥, ì–‘íŒŒ, ì •ì œìˆ˜<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"ì‚°ë„ì¡°ì ˆì œ, ì•Œì½˜ì—ì“°\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"dìì¼ë¡œì˜¤ìŠ¤, ê³ ì¶”, ë‚œë°±ì•¡, ë‹¹ë©´, ëŒ€ë‘ìœ , ë§ˆëŠ˜, ëª…íƒœra, ì–‘íŒŒ, ìœ ì‚°ê· ë°°ì–‘ì•¡í˜¼í•©ë¶„ë§, ì „ë¶„ê°€ê³µí’ˆ, ì •ë°±ë‹¹, ì •ì œì—¼, íƒ€ì´ë¯¸, í•¨ìˆ˜ê²°ì •í¬ë„ë‹¹ng, íš¨ëª¨ì¶”ì¶œë¬¼í˜¼í•©ë¶„ë§\"', 'instruction': 'ì–´ë¬µ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ì•Œë˜ìŠ¤ì¹¸íŠ¹ê¸‰ë§‘ì€ì–´ë¬µì „ê³¨ì˜ ì¼ë¶€ ì¬ë£Œê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ì‹ì¬ë£Œë¥¼ ì¶”ì¸¡í•´ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì–´ë¬µ, ëŒ€ë‘ë‹¨ë°±, ì •ì œìˆ˜, ì •ì œì†Œê¸ˆ, ì •ì œìˆ˜<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"í´ë¡œë ë¼ë¶„ë§\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"\"', 'instruction': 'ê³¡ë¥˜ê°€ê³µí’ˆ ì¹´í…Œê³ ë¦¬ì˜ ì¹¼ìŠ˜ì™ì™ì°¹ìŒ€í´ë¡œë ë¼ì˜ ì‹ì¬ë£Œì˜ ì¼ë¶€ì…ë‹ˆë‹¤. ë¹ ì§„ ì‹ì¬ë£Œë¥¼ ë§ì¶”ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì™ì™ì°¹ìŒ€, ì°¹ìŒ€<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"ë°”ì§€ë½ì¡°ë¯¸ì—‘ê¸°ìŠ¤\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ê²Œì¶”ì¶œë†ì¶•ì•¡1í˜¸, ì •ì œìˆ˜\"', 'instruction': 'ìœ¡ìˆ˜ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ë°”ì§€ë½ìœ¡ìˆ˜ì˜ ë ˆì‹œí”¼ì—ì„œ ëª‡ ê°€ì§€ ì¬ë£Œê°€ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì–´ë–¤ ì¬ë£Œê°€ ë¹ ì¡ŒëŠ”ì§€ ë§ì¶°ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ë°”ì§€ë½ì—‘ê¸°ìŠ¤, ë°”ì§€ë½ì¶”ì¶œë†ì¶•ì•¡, ì •ì œì—¼, ì •ì œìˆ˜<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"ë§›ë‚´ê¸°ë² ì´ìŠ¤, í˜¼í•©ì¡°ë¯¸ë¶„\"\\nê³µí†µ ì¬ë£Œ: \"ì˜¬ë¦¬ë¸Œìœ \"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ê³ ì¶”, ê·¸ë ˆì´í‹°ë“œíŒŒë§ˆì‚°ì¹˜ì¦ˆ, ë°”ì§€ë½ì—‘ê¸°ìŠ¤, ì”íƒ„ê²€, íƒ€ë§ˆë¦°ë“œê²€, í˜„ë¯¸ìœ , í›„ì¶”ê°€ë£¨\"', 'instruction': 'ì†ŒìŠ¤ë¥˜ ì¹´í…Œê³ ë¦¬ì˜ ë°”ë¥¸ì„ ì•Œë¦¬ì˜¤ì˜¬ë¦¬ì˜¤ì†ŒìŠ¤_180806ì˜ ì‹ì¬ë£Œì˜ ì¼ë¶€ì…ë‹ˆë‹¤. ë¹ ì§„ ì‹ì¬ë£Œë¥¼ ë§ì¶”ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ë°”ë¥¸ì„ ì•Œë¦¬ì˜¤ì˜¬ë¦¬ì˜¤ì†ŒìŠ¤_180806<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"ë³¶ìŒì°¸ê¹¨ë¶„ë§\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ì •ì œìˆ˜\"', 'instruction': 'ì†ŒìŠ¤ë¥˜ ì¹´í…Œê³ ë¦¬ì˜ ìŒ€ì½©êµ­ë¬¼ì— ì‚¬ìš©ë˜ëŠ” ëª‡ ê°€ì§€ ì¬ë£Œì…ë‹ˆë‹¤. ëˆ„ë½ëœ ì¬ë£Œë¥¼ ì°¾ì•„ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì½©ë‚˜ë¬¼êµ­ë¬¼<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"arconsb\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ì”íƒ„ê²€, ì •ì œì†Œê¸ˆ, ì •ì œìˆ˜, í™”ì´ë°”ì†”2lë‚œì†Œí™”ì„±ë§í† ë±ìŠ¤íŠ¸ë¦°\"', 'instruction': 'ì¦‰ì„ì¡°ë¦¬ì‹í’ˆ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ì£ì£½ì˜ ì¼ë¶€ ì¬ë£Œê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ì‹ì¬ë£Œë¥¼ ì¶”ì¸¡í•´ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì£, ì •ì œìˆ˜<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"ë³¶ì€ê²€ì€ì½©ë¶„ë§, ë³¶ìŒê²€ì •ê¹¨ë¶„ë§\"\\nì¼ë°˜ ì¬ë£Œ: \"27ì¢…ê³¼ì•¼ì±„í˜¼í•©ë†ì¶•ë¶„ë§, ë©€í‹°ë¹„íƒ€ë¯¼ë¯¸ë„¤ë„ë¯¹ìŠ¤, ë¶„ë¦¬ìœ ì²­ë‹¨ë°±ì§ˆ, ì˜¬ë¦¬ê³ ë‹¹orafticrf\"\\nê³µí†µ ì¬ë£Œ: \"ì˜¤íŠ¸ë³¼, ì½”ì½”ë„›ìŠˆê°€\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ë‚œì†Œí™”ì„±ë§í† ë±ìŠ¤íŠ¸ë¦°, íš¨ì†Œì²˜ë¦¬ìŠ¤í…Œë¹„ì•„\"', 'instruction': 'ì²´ì¤‘ì¡°ì ˆì‹ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” í¬ì¼“ì‰ì´í¬-í‘ì„ìë§›ì˜ ë ˆì‹œí”¼ì—ì„œ ëª‡ ê°€ì§€ ì¬ë£Œê°€ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì–´ë–¤ ì¬ë£Œê°€ ë¹ ì¡ŒëŠ”ì§€ ë§ì¶°ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "í‘ì„ìë§›, í‘ì„ìë¶„ë§, ì •ì œìˆ˜, ì •ì œì—¼, ì •ì œìˆ˜<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"\"', 'instruction': 'ì‹ìœ¡ì¶”ì¶œê°€ê³µí’ˆ ì¹´í…Œê³ ë¦¬ì˜ í‚¤ì¦ˆTHEë½€ì–€í•œìš°ê³ ê¸°ê³°íƒ•ì— ì‚¬ìš©ë˜ëŠ” ëª‡ ê°€ì§€ ì¬ë£Œì…ë‹ˆë‹¤. ëˆ„ë½ëœ ì¬ë£Œë¥¼ ì°¾ì•„ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "í•œìš°ê³°íƒ•, ë¼ì§€ê³ ê¸°, ì–‘íŒŒ, ëŒ€íŒŒ, ë§ˆëŠ˜, ìƒê°•, ì •ì œìˆ˜, ì •ì œì—¼, ë°±ì„¤íƒ•, ì •ì œì†Œê¸ˆ, ì •ì œìˆ˜<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"\"', 'instruction': 'í¬ì¥ìœ¡ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ë¬´í•­ìƒì œí•œìš°ì˜ ì¼ë¶€ ì¬ë£Œê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ì‹ì¬ë£Œë¥¼ ì¶”ì¸¡í•´ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "í•œìš°ë“±ì‹¬, í•œìš°ê°ˆë¹„, í•œìš°ì–‘ì§€, í•œìš°ì–‘ì§€ê°ˆë¹„, ì–‘ì§€ê°ˆë¹„, ì–‘ì§€ë“±ì‹¬<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"ë²¨ë¡œì²´ë‹¤í¬ë¦¼ì¹˜ì¦ˆ\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ë°€ê°€ë£¨, ë¹µê°€ë£¨, ì •ì œìˆ˜\"', 'instruction': 'ê¸°íƒ€ê°€ê³µí’ˆ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ì²´ë‹¤í¬ë¦¼ì¹˜ì¦ˆìŠ¤í‹±ì˜ ì¼ë¶€ ì¬ë£Œê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ì‹ì¬ë£Œë¥¼ ì¶”ì¸¡í•´ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì²´ë‹¤í¬ë¦¼ì¹˜ì¦ˆìŠ¤í‹±<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"ë‚˜ê°€ì‚¬ë¼ì‹œì¦ˆë‹yw, í™í•©ì—‘ê¸°ìŠ¤ë¶„ë§ì—ìŠ¤\"\\nê³µí†µ ì¬ë£Œ: \"ì‚¬ê³¨ì¶”ì¶œë¬¼15, ì•¼ì±„ì§¬ë½•ë² ì´ìŠ¤\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ì„¤íƒ•, ì •ì œìˆ˜, ì¹˜í‚¨ì—‘ê¸°ìŠ¤\"', 'instruction': 'ì†ŒìŠ¤ ì¹´í…Œê³ ë¦¬ì˜ í’€ìŠ¤í‚¤ì¹œ_ë‚˜ê°€ì‚¬ë¼ì§¬ë½•ì†ŒìŠ¤ì˜ ì‹ì¬ë£Œì˜ ì¼ë¶€ì…ë‹ˆë‹¤. ë¹ ì§„ ì‹ì¬ë£Œë¥¼ ë§ì¶”ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ë‚˜ê°€ì‚¬ë¼ì‹œì¦ˆë‹, í™í•©ì—‘ê¸°ìŠ¤ë¶„ë§, í’€ìŠ¤í‚¤ì¹œ_ë‚˜ê°€ì‚¬ë¼ì§¬ë½•ì†ŒìŠ¤<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"\"', 'instruction': 'ë‘ë¶€ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ì†Œê°€ì°Œê°œë‘ë¶€3kgì˜ ë ˆì‹œí”¼ì—ì„œ ëª‡ ê°€ì§€ ì¬ë£Œê°€ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì–´ë–¤ ì¬ë£Œê°€ ë¹ ì¡ŒëŠ”ì§€ ë§ì¶°ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì†Œê°€ì°Œê°œë‘ë¶€<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"\"', 'instruction': 'ì‹ ì„ í¸ì˜ì‹í’ˆ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ë°”ë¥¸ì„ ìì—°ë‹´ì€ì²­í¬ë„(íŠ¹,1kg,ëƒ‰ì¥)ìˆ˜ì…ì‚°ì˜ ì¼ë¶€ ì¬ë£Œê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ì‹ì¬ë£Œë¥¼ ì¶”ì¸¡í•´ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì²­í¬ë„<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ê³ ì¶§ê°€ë£¨, ë‚œë°±ì•¡, ëŒ€ë‘ë‹¨ë°±, ì„¤íƒ•, ì†Œë§¥ì „ë¶„, ì²­ì–‘ê³ ì¶”, íš¨ëª¨ì¶”ì¶œë¬¼í˜¼í•©ë¶„ë§\"', 'instruction': 'ì–´ë¬µ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ì¹˜ì¦ˆì¸ë”ì–´ë¬µ_í•«ìŠ¤íŒŒì´ì‹œì˜ ë ˆì‹œí”¼ì—ì„œ ëª‡ ê°€ì§€ ì¬ë£Œê°€ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì–´ë–¤ ì¬ë£Œê°€ ë¹ ì¡ŒëŠ”ì§€ ë§ì¶°ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì¹˜ì¦ˆ, ë°€ê°€ë£¨, ì •ì œìˆ˜, ì •ì œì—¼, í›„ì¶”ê°€ë£¨, ì •ì œìˆ˜<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ê°ˆìƒ‰ì„¤íƒ•, ê³ ì¶”ê¸°ë¦„1, ë°œíš¨ë†ì¶•ì•¡, ì°¸ê¸°ë¦„, íŒŒí”„ë¦¬ì¹´ì¶”ì¶œìƒ‰ì†Œ, í˜¼í•©ì œì œ, í‘í›„ì¶”ë¶„ë§\"', 'instruction': 'ì†ŒìŠ¤ë¥˜ ì¹´í…Œê³ ë¦¬ì˜ ì¤‘ì‹ë¶ˆë§›ì†ŒìŠ¤(ì–´ë¬µë³¶ìŒìš©ì†ŒìŠ¤)ì— ì‚¬ìš©ë˜ëŠ” ëª‡ ê°€ì§€ ì¬ë£Œì…ë‹ˆë‹¤. ëˆ„ë½ëœ ì¬ë£Œë¥¼ ì°¾ì•„ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì–´ë¬µë³¶ìŒìš©ì†ŒìŠ¤, ê³ ì¶”ë¶„ë§, ì •ì œìˆ˜, ì •ì œì†Œê¸ˆ, ì„¤íƒ•, ì •ì œì—¼, ì •ì œìˆ˜<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"ì•„ì„¸ë¡œë¼ë†ì¶•ê³¼ì¦™\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ì—´ëŒ€í˜¼í•©ê³¼ì¼ë†ì¶•ì•¡, ì •ì œìˆ˜\"', 'instruction': 'ê³¼ì±„ì£¼ìŠ¤ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ì•„ì„ìƒ·íŒŒì›ŒCì˜ ë ˆì‹œí”¼ì—ì„œ ëª‡ ê°€ì§€ ì¬ë£Œê°€ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì–´ë–¤ ì¬ë£Œê°€ ë¹ ì¡ŒëŠ”ì§€ ë§ì¶°ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì•„ì„ìƒ·íŒŒì›ŒC<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ê±´ì¡°ê°ìë¶„ë§, ê²°ì •ê³¼ë‹¹, ë‹¹ê·¼, ì–‘íŒŒ, í”Œë ˆì¸ì†ŒìŠ¤, í˜¼í•©ì œì œ, íš¨ëª¨ì¶”ì¶œë¬¼\"', 'instruction': 'ì¦‰ì„ì„­ì·¨ì‹í’ˆ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” [í‘¸ë“œë¨¸ìŠ¤]ê°ììƒëŸ¬ë“œFMì˜ ì¼ë¶€ ì¬ë£Œê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ì‹ì¬ë£Œë¥¼ ì¶”ì¸¡í•´ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ê°ì, ìƒê°•, ì •ì œìˆ˜, ì •ì œì—¼, ì„¤íƒ•, ë°€ê°€ë£¨, ë°€ë¶„í•´ì¶”ì¶œë¬¼<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"\"', 'instruction': 'ë‘ë¶€ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ì†Œê°€í¬ê³ ë‹¨ë‹¨í•œë‘ë¶€500gì˜ ë ˆì‹œí”¼ì—ì„œ ëª‡ ê°€ì§€ ì¬ë£Œê°€ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì–´ë–¤ ì¬ë£Œê°€ ë¹ ì¡ŒëŠ”ì§€ ë§ì¶°ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ê³ êµ¬ë§ˆì „ë¶„, ëŒ€ë‘ë‹¨ë°±, ì •ì œìˆ˜, ì •ì œì—¼<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"\"', 'instruction': 'ë¹™ê³¼ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ì•„ì´ìŠ¤íë¸Œì»¤í”¼ë§›(ë§¤ë¨¸ë“œìš©)ì˜ ë ˆì‹œí”¼ì—ì„œ ëª‡ ê°€ì§€ ì¬ë£Œê°€ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì–´ë–¤ ì¬ë£Œê°€ ë¹ ì¡ŒëŠ”ì§€ ë§ì¶°ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì»¤í”¼, ì»¤í”¼ì¶”ì¶œë¬¼, ì»¤í”¼ë†ì¶•ì•¡, ì»¤ï¿½\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"\"', 'instruction': 'ê³¼ì±„ì£¼ìŠ¤ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ì•„ì„ë¦¬ì–¼ìœ ê¸°ë†ì‚¬ê³¼ì˜ ë ˆì‹œí”¼ì—ì„œ ëª‡ ê°€ì§€ ì¬ë£Œê°€ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì–´ë–¤ ì¬ë£Œê°€ ë¹ ì¡ŒëŠ”ì§€ ë§ì¶°ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì•„ì„ë¦¬ì–¼ìœ ê¸°ë†ì‚¬ê³¼<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"ì‚°ë„ì¡°ì ˆì œ, ì—°ìœ¡ëª…íƒœaa\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"dìì¼ë¡œì˜¤ìŠ¤, ê³ ì¶”, ë‹¹ë©´, ëŒ€ë‘ìœ , ë‘ë¶€, ëª…íƒœra, ë¶„ë¦¬ë‹¨ë°±ëŒ€ë‘yx2001, ì†Œë§¥ì „ë¶„, ì–‘íŒŒ, ì „ë¶„ê°€ê³µí’ˆ, ì •ë°±ë‹¹, ì •ì œì—¼, íƒ€ì´ë¯¸, í•¨ìˆ˜ê²°ì •í¬ë„ë‹¹ng, í˜¼í•©ì œì œ\"', 'instruction': 'ì–´ë¬µ ì¹´í…Œê³ ë¦¬ì˜ ì•Œë˜ìŠ¤ì¹¸íŠ¹ê¸‰ì§„í•œì–´ë¬µì „ê³¨ì— ì‚¬ìš©ë˜ëŠ” ëª‡ ê°€ì§€ ì¬ë£Œì…ë‹ˆë‹¤. ëˆ„ë½ëœ ì¬ë£Œë¥¼ ì°¾ì•„ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì–´ë¬µ, ëŒ€ë‘, ì •ì œìˆ˜, ì •ì œì†Œê¸ˆ, ì •ì œì—¼, ì •ì œìˆ˜, ì •\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"ì ˆì„ì˜¤ì´\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"êµ¬ì—°ì‚°, ê¸°íƒ€ê³¼ë‹¹, ë°€ë¶„í•´ì¶”ì¶œë¬¼, ì •ì œì†Œê¸ˆ, ì •ì œìˆ˜, ì –ì‚°ì¹¼ìŠ˜, íš¨ì†Œì²˜ë¦¬ìŠ¤í…Œë¹„ì•„\"', 'instruction': 'ì ˆì„ë¥˜ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ë°”ë¡œì ˆì—¬ê¼¬ë“¤ê¼¬ë“¤í•œì˜¤ì´ì§€ë¬´ì¹¨ì˜ ì¼ë¶€ ì¬ë£Œê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ì‹ì¬ë£Œë¥¼ ì¶”ì¸¡í•´ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ê¼¬ë“¤ê¼¬ë“¤í•œì˜¤ì´ë¬´ì¹¨, ì –ì‚°ì¹¼ìŠ˜, ì •ì œì†Œê¸ˆ<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"íŒŒí”„ë¦¬ì¹´ì¶”ì¶œìƒ‰ì†Œ10ë§Œ\"\\nê³µí†µ ì¬ë£Œ: \"ìˆ¯ë¶ˆí’ë¯¸ì•¡, ì¹ ë¦¬ì˜¤ì¼r\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ê³ ì¶§ê°€ë£¨, ë©€í‹°ë¡¬íŒŒìš°ë”, ì‚¬ê³¨ë†ì¶•ì•¡, ì„¤íƒ•, ì•„ë¯¸ë…¸ë² ì´ìŠ¤p, ì˜¤ì§•ì–´ì—‘ê¸°ìŠ¤p, ì •ì œìˆ˜, í˜¼í•©ì•¼ì±„ì—‘ê¸°ìŠ¤, í‘í›„ì¶”ë¶„ë§\"', 'instruction': 'ì†ŒìŠ¤ë¥˜ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ì§„í•œì–‘ë…ì˜ ì¼ë¶€ ì¬ë£Œê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ì‹ì¬ë£Œë¥¼ ì¶”ì¸¡í•´ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì§„í•œì–‘ë…, ì–‘ë…ë¶„ë§, ì–‘íŒŒ, ì–‘íŒŒë†ì¶•ì•¡, ì •ì œì†Œê¸ˆ, í›„ì¶”ê°€ë£¨, ë§ˆëŠ˜, ë§ˆëŠ˜ë†ì¶•ì•¡, ì–‘ì¡°ê°„ì¥, ì–‘\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ì •ì œì†Œê¸ˆ\"', 'instruction': 'ê¸°íƒ€ìˆ˜ì‚°ë¬¼ê°€ê³µí’ˆ ì¹´í…Œê³ ë¦¬ì˜ ìˆ˜ë¹„ë“œì—°ì–´ì˜¤ë¦¬ì§€ë„ì— ì‚¬ìš©ë˜ëŠ” ëª‡ ê°€ì§€ ì¬ë£Œì…ë‹ˆë‹¤. ëˆ„ë½ëœ ì¬ë£Œë¥¼ ì°¾ì•„ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì—°ì–´, ë°±ì„¤íƒ•, ì •ì œìˆ˜<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"\"', 'instruction': 'ë‘ë¶€ ì¹´í…Œê³ ë¦¬ì˜ ì†Œê°€ì—°ë‘ë¶€125gì— ì‚¬ìš©ë˜ëŠ” ëª‡ ê°€ì§€ ì¬ë£Œì…ë‹ˆë‹¤. ëˆ„ë½ëœ ì¬ë£Œë¥¼ ì°¾ì•„ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì†Œê°€ì—°ë‘ë¶€<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"ìˆ™ì£¼\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ëŒ€ë‘ìœ , ì²­ì–‘ê³ ì¶§ê°€ë£¨\"', 'instruction': 'í–¥ë¯¸ìœ  ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” í—ˆë¸Œí’ë¯¸ìœ (180807)ì˜ ë ˆì‹œí”¼ì—ì„œ ëª‡ ê°€ì§€ ì¬ë£Œê°€ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì–´ë–¤ ì¬ë£Œê°€ ë¹ ì¡ŒëŠ”ì§€ ë§ì¶°ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ìˆ™ì£¼, ëŒ€ë‘ìœ , ì²­ì–‘ê³ ì¶§ê°€ë£¨<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"ìœ ê¸°ë†í™©ì„¤íƒ•\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"\"', 'instruction': 'ê³¼ì±„ì£¼ìŠ¤ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ìœ ê¸°ë†í¬ë„ì£¼ìŠ¤ì˜ ì¼ë¶€ ì¬ë£Œê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ì‹ì¬ë£Œë¥¼ ì¶”ì¸¡í•´ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "í¬ë„ì£¼ìŠ¤, ìœ ê¸°ë†í¬ë„ë†ì¶•ì•¡, ìœ ê¸°ë†í¬ë„ë†ì¶•ì•¡p, ìœ ê¸°ë†í¬ë„ë†ì¶•ì•¡p2, ìœ ê¸°ë†í¬ë„ë†ì¶•ì•¡p3, ìœ \n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"ë Œí‹¸ì½©\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ë‹¨í˜¸ë°•, ìƒˆì†¡ì´ë²„ì„¯, ì–‘ì¡°ê°„ì¥, ì˜¥ìˆ˜ìˆ˜ìœ , ì¹˜í‚¨ìŠ¤í†¡p, ì½©ë°œíš¨ë§›ë‚´ê¸°ì§„\"', 'instruction': 'ì¦‰ì„ì¡°ë¦¬ì‹í’ˆ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ë‹¨í˜¸ë°•ì˜ì–‘ë°¥ì˜ ì¼ë¶€ ì¬ë£Œê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ì‹ì¬ë£Œë¥¼ ì¶”ì¸¡í•´ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì½©ë‚˜ë¬¼, ëŒ€ë‘ìœ , ì–‘íŒŒ, ì–‘ì¡°ê°„ì¥, ì •ì œìˆ˜, ì •ì œì†Œê¸ˆ, ì°¸ê¸°ë¦„<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"\"', 'instruction': 'ë†ì‚°ë¬¼ ì¹´í…Œê³ ë¦¬ì˜ ê±´ì¡°ëŒ€íŒŒì˜ ì‹ì¬ë£Œì˜ ì¼ë¶€ì…ë‹ˆë‹¤. ë¹ ì§„ ì‹ì¬ë£Œë¥¼ ë§ì¶”ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ëŒ€íŒŒ<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"\"', 'instruction': 'ë†ì‚°ë¬¼ ì¹´í…Œê³ ë¦¬ì˜ ì œì£¼ë„ì½©ë¬´ë†ì•½ì•ˆì‹¬ì½©ë‚˜ë¬¼ì˜ ì‹ì¬ë£Œì˜ ì¼ë¶€ì…ë‹ˆë‹¤. ë¹ ì§„ ì‹ì¬ë£Œë¥¼ ë§ì¶”ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì½©ë‚˜ë¬¼<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"ì–‘ìƒì¶”, ì˜¤ì´\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"\"', 'instruction': 'ë†ì‚°ë¬¼ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ì´ì§€ì¿ í‚¹ë¸Œë¦¬ë˜ë§Œë“¤ê¸°_í˜¼í•©ì•¼ì±„ì˜ ë ˆì‹œí”¼ì—ì„œ ëª‡ ê°€ì§€ ì¬ë£Œê°€ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì–´ë–¤ ì¬ë£Œê°€ ë¹ ì¡ŒëŠ”ì§€ ë§ì¶°ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì–‘íŒŒ, ëŒ€íŒŒ, ë§ˆëŠ˜, ìƒê°•, ì–‘ë°°ì¶”<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"ê¸°íƒ€ê°€ê³µí’ˆ, ë²„í„°ë¸”ëœë“œ\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ì •ë°±ë‹¹, ì¹´ë†€ë¼ìœ \"', 'instruction': 'ê¸°íƒ€ê°€ê³µí’ˆ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” íŠ¸ìœ„ìŠ¤íŠ¸ê½ˆë°°ê¸°í¬ë¦¼ì¹˜ì¦ˆ(ì €ë‹¹)ì˜ ì¼ë¶€ ì¬ë£Œê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ì‹ì¬ë£Œë¥¼ ì¶”ì¸¡í•´ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "íŠ¸ìœ„ìŠ¤íŠ¸ê½ˆë°°ê¸°í¬ë¦¼ì¹˜ì¦ˆ(ì €ë‹¹)<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"ê°ê·¤ê³¼ë¦½\"\\nê³µí†µ ì¬ë£Œ: \"ì ì–‘ë°°ì¶”ìƒ‰ì†Œì—˜, ì ìëª½ë†ì¶•ì•¡\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ì–‘ì¡°ì‹ì´ˆ, ì”íƒ„ê²€, ì •ì œì†Œê¸ˆ, íƒ€ë§ˆë¦°ë“œê²€, í•˜ì–€ì„¤íƒ•\"', 'instruction': 'ì†ŒìŠ¤ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ë°”ë¥¸ì„ ìëª½ì¹˜ì•„ì”¨ë“œìƒëŸ¬ë“œì†ŒìŠ¤ì˜ ì¼ë¶€ ì¬ë£Œê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ì‹ì¬ë£Œë¥¼ ì¶”ì¸¡í•´ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ë°”ë¥¸ì„ ìëª½ì¹˜ì•„ì”¨ë“œ, ë°”ë¥¸ì„ ìëª½ë†ì¶•ì•¡, ì •ì œìˆ˜, ì •ì œì†Œê¸ˆ, ì •ì œìˆ˜<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"ë¦¬ì¹˜ë¹µê°€ë£¨\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ëŒ€ë‘ìœ , ì •ë°±ë‹¹, í¬ë¦¼ì¹˜ì¦ˆ, í‘í›„ì¶”ë¶„ë§\"', 'instruction': 'ë¹µë¥˜ ì¹´í…Œê³ ë¦¬ì˜ ëŒ€íŒŒí¬ë¦¼ë³¼ì˜ ì‹ì¬ë£Œì˜ ì¼ë¶€ì…ë‹ˆë‹¤. ë¹ ì§„ ì‹ì¬ë£Œë¥¼ ë§ì¶”ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "í¬ë¦¼ì¹˜ì¦ˆë³¼, ëŒ€íŒŒ, ì •ì œìˆ˜, ë°€ê°€ë£¨, ì •ë°±ë‹¹, ëŒ€ë‘ìœ , í‘í›„ì¶”ë¶„ë§, í¬ë¦¼, ì •ì œì†Œê¸ˆ, ì •ì œìˆ˜<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ë©¥ìŒ€, ë¶„ë¦¬ëŒ€ë‘ë‹¨ë°±, ì¬ì œì†Œê¸ˆ, ì •ì œìˆ˜\"', 'instruction': 'ë–¡ë¥˜ ì¹´í…Œê³ ë¦¬ì˜ ìš°ë¦¬ìŒ€ë‹¨ë°±ì„¤ê¸°ì— ì‚¬ìš©ë˜ëŠ” ëª‡ ê°€ì§€ ì¬ë£Œì…ë‹ˆë‹¤. ëˆ„ë½ëœ ì¬ë£Œë¥¼ ì°¾ì•„ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ìŒ€, ëŒ€ë‘ë‹¨ë°±, ì •ì œì†Œê¸ˆ, ì •ì œìˆ˜<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ë¶„ë§ì…€ë£°ë¡œìŠ¤\"', 'instruction': 'ì¹˜ì¦ˆ ì¹´í…Œê³ ë¦¬ì˜ í‘¸ë“œë¨¸ìŠ¤ë¯¸ì„¸ìŠˆë ˆë“œì— ì‚¬ìš©ë˜ëŠ” ëª‡ ê°€ì§€ ì¬ë£Œì…ë‹ˆë‹¤. ëˆ„ë½ëœ ì¬ë£Œë¥¼ ì°¾ì•„ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ìŠˆë ˆë“œ, ìœ ì‚°ê· ë°œíš¨ë¶„ë§, ì •ì œìˆ˜, ì •ì œì—¼, ë°€ê°€ë£¨, ë°€ë¶„í•´ì¶”ì¶œë¬¼<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"\"', 'instruction': 'ë‘ë¶€ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” êµ­ì‚°ì½©ë‘ë¶€ë¶€ì¹¨ìš©210gì˜ ì¼ë¶€ ì¬ë£Œê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ì‹ì¬ë£Œë¥¼ ì¶”ì¸¡í•´ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì½©, ì •ì œìˆ˜, ì •ì œì†Œê¸ˆ, ì •ì œìˆ˜<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"êµ­ì‚°ì±„ì†Œë°‘êµ­ë¬¼, ë ˆì‹œí‹´, ë°”ì§€ë½ë°‘êµ­ë¬¼p\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"hvphr, ë§ˆëŠ˜, ë§¤ìš´ë§›ë¶„ë§, ë©¸ì¹˜ì¶”ì¶œë†ì¶•ì•¡, ë°œíš¨ë§›ë‚´ê¸°, ë³¶ìŒì–‘ë…ë¶„, ì•„ë¡œë§ˆì¼ë“œ, ì–‘íŒŒ, ì •ë°±ë‹¹, ì •ì œìˆ˜, ì°°ì˜¥ìˆ˜ìˆ˜ì „ë¶„, íŒŒí”„ë¦¬ì¹´ì¶”ì¶œìƒ‰ì†Œ, í¬í¬ì—‘ê¸°ìŠ¤p, í˜¸ë°•ì‚°ì´ë‚˜íŠ¸ë¥¨\"', 'instruction': 'ì†ŒìŠ¤ë¥˜ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ì •í†µìˆœë‘ë¶€ì°Œê°œì–‘ë…(19ë…„)ì˜ ë ˆì‹œí”¼ì—ì„œ ëª‡ ê°€ì§€ ì¬ë£Œê°€ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì–´ë–¤ ì¬ë£Œê°€ ë¹ ì¡ŒëŠ”ì§€ ë§ì¶°ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ìˆœë‘ë¶€, ì–‘ì¡°ê°„ì¥, ì–‘íŒŒ, ëŒ€ë‘ìœ , ì •ì œì†Œê¸ˆ, ì •ì œìˆ˜, ì •ì œì—¼, ì •ì œìˆ˜, ì •\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"ê³ ì¶§ì, ìš”ë¦¬í”ŒëŸ¬ìŠ¤, ì¡°ë¯¸ê³ ì¶”ë§›ë¶„\"\\nì¼ë°˜ ì¬ë£Œ: \"ì†Œë¸Œì‚°ì¹¼ë¥¨, ì§„ê°„ì¥\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ë¬¼ì—¿, ë°±ì„¤íƒ•, ì”íƒ„ê²€, ì •ì œì†Œê¸ˆ\"', 'instruction': 'ì ˆì„ë¥˜ ì¹´í…Œê³ ë¦¬ì˜ ë¬´ë§ë­ì´ì˜ ì‹ì¬ë£Œì˜ ì¼ë¶€ì…ë‹ˆë‹¤. ë¹ ì§„ ì‹ì¬ë£Œë¥¼ ë§ì¶”ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ë¬´ë§ë­ì´, ê³ ì¶§ê°€ë£¨, ì •ì œìˆ˜, ì •ì œì†Œê¸ˆ<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"ê³ ë¡œì¼€ìš©ë¯¹ìŠ¤, í–„\"\\nê³µí†µ ì¬ë£Œ: \"ê°€ê³µë²„í„°\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ëŒ€ë‘ìœ , ë§ˆìš”ë„¤ì¦ˆ, ë¹µê°€ë£¨, ìƒì´ìŠ¤íŠ¸, ì •ë°±ë‹¹, ì²­í”¼ë§, í‘í›„ì¶”\"', 'instruction': 'ë¹µë¥˜ ì¹´í…Œê³ ë¦¬ì˜ ëª¨ì§œë ë¼ê³ ë¡œì¼€ë² ì´ì»¨í¬í…Œì´í† ì˜ ì‹ì¬ë£Œì˜ ì¼ë¶€ì…ë‹ˆë‹¤. ë¹ ì§„ ì‹ì¬ë£Œë¥¼ ë§ì¶”ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ë² ì´ì»¨, ë² ì´ì»¨ì—‘ê¸°ìŠ¤, ë°€ê°€ë£¨, ì •ì œìˆ˜, ì •ì œì†Œê¸ˆ, ì„¤íƒ•, ë°€ë¶„í•´ì¶”ì¶œë¬¼, ì •ì œì—¼, ì •ì œìˆ˜<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"ë¸”ë£¨ë² ë¦¬í–¥, í™ì‚¼ë†ì¶•ì•¡\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ë°±ì„¤íƒ•, ì•¡ìƒê³¼ë‹¹, ì •ì œìˆ˜\"', 'instruction': 'ì¸ì‚¼í™ì‚¼ìŒë£Œ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ë°”ë¥¸ì„ ìŠ¤ìœ—í™í¬ë„ì˜ ë ˆì‹œí”¼ì—ì„œ ëª‡ ê°€ì§€ ì¬ë£Œê°€ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì–´ë–¤ ì¬ë£Œê°€ ë¹ ì¡ŒëŠ”ì§€ ë§ì¶°ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "í™ì‚¼ë†ì¶•ì•¡, í™ì‚¼ë†ì¶•ì•¡ë¶„ë§, ì •ì œìˆ˜, ë°±ì„¤íƒ•, ì•¡ìƒê³¼ë‹¹, ë¸”ë£¨ë² ë¦¬í–¥<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"ì‚°ë„ì¡°ì ˆì œ, ìœ ì‚°ê· ë°œíš¨ë¶„ë§\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ì›ìœ , ì •ì œì†Œê¸ˆ\"', 'instruction': 'ìƒì¹˜ì¦ˆ ì¹´í…Œê³ ë¦¬ì˜ ì •í†µë¦¬ì½”íƒ€ì¹˜ì¦ˆ_500gì˜ ì‹ì¬ë£Œì˜ ì¼ë¶€ì…ë‹ˆë‹¤. ë¹ ì§„ ì‹ì¬ë£Œë¥¼ ë§ì¶”ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ë¦¬ì½”íƒ€ì¹˜ì¦ˆ, ìœ ì‚°ê· ë°œíš¨ë¶„ë§<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"ìœ ê¸°ì‚¬ê³¼í“¨ë ˆ\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"\"', 'instruction': 'ê³¼ì±„ì£¼ìŠ¤ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ì•„ì„ë¦¬ì–¼ìœ ê¸°ë†í¬ë„ì˜ ì¼ë¶€ ì¬ë£Œê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ì‹ì¬ë£Œë¥¼ ì¶”ì¸¡í•´ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ì•„ì„ë¦¬ì–¼ìœ ê¸°ë†í¬ë„í“¨ë ˆ<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"êµ¬ì—°ì‚°ì² ì•”ëª¨ëŠ„\"\\nê³µí†µ ì¬ë£Œ: \"ê°€ê³µë²„í„°\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"êµ¬ì—°ì‚°ë‚˜íŠ¸ë¥¨, ìœ ì²­ë¶„ë§, ì •ì œìˆ˜, í¬ë¦¼ì¹˜ì¦ˆ\"', 'instruction': 'ê°€ê³µì¹˜ì¦ˆ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” í’€ìŠ¤í‚¤ì¦ˆê³ ì¹¼ìŠ˜ìŠ¬ë¼ì´ìŠ¤ì¹˜ì¦ˆì˜ ë ˆì‹œí”¼ì—ì„œ ëª‡ ê°€ì§€ ì¬ë£Œê°€ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì–´ë–¤ ì¬ë£Œê°€ ë¹ ì¡ŒëŠ”ì§€ ë§ì¶°ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "í’€ìŠ¤í‚¤ì¦ˆê³ ì¹¼ìŠ˜ìŠ¬ë¼ì´ìŠ¤ì¹˜ì¦ˆ, í’€ìŠ¤í‚¤ì¦ˆê³ ì¹¼ìŠ˜ìŠ¬ë¼ì´ìŠ¤ì¹˜ì¦ˆ(ì†ŒìŠ¤)<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"ê³¡ë¥˜ê°€ê³µí’ˆ, ë¼ì§€ê³ ê¸°, ë°±ì„¤íƒ•, ë¶€ì¶”, ìƒê°•, ìƒê°•ë¶„ë§, ì‡ ê³ ê¸°ì¶”ì¶œë¶„ë§, ì–‘ë°°ì¶”, ì–‘íŒŒ, ìœ í™”ìœ ì§€í”¼, ì •ì œì†Œê¸ˆ, í‘í›„ì¶”ë¶„ë§\"', 'instruction': 'ë§Œë‘ë¥˜ ì¹´í…Œê³ ë¦¬ì˜ P-ìœ¡ì¦™ë“¬ë¿ë§Œë‘ì— ì‚¬ìš©ë˜ëŠ” ëª‡ ê°€ì§€ ì¬ë£Œì…ë‹ˆë‹¤. ëˆ„ë½ëœ ì¬ë£Œë¥¼ ì°¾ì•„ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ë¼ì§€ê³ ê¸°ì¶”ì¶œë¶„ë§, ìƒê°•, ìƒê°•ë¶„ë§, ì–‘ë°°ì¶”, ì–‘íŒŒ, ì •ì œì†Œê¸ˆ, í‘í›„ì¶”ë¶„ë§<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"\"\\nê³µí†µ ì¬ë£Œ: \"ìš°ì—‰\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"dìì¼ë¡œì˜¤ìŠ¤, ëŒ€ë‘ë‹¨ë°±, ì •ë°±ë‹¹, í¬ë„ë‹¹, íš¨ëª¨ì¶”ì¶œë¬¼\"', 'instruction': 'ì–´ë¬µ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ì•Œë˜ìŠ¤ì¹¸íŠ¹ê¸‰ìš°ì—‰ë§ì´ì–´ë¬µì˜ ì¼ë¶€ ì¬ë£Œê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ì‹ì¬ë£Œë¥¼ ì¶”ì¸¡í•´ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ìš°ì—‰, ëŒ€ë‘ë‹¨ë°±, ì •ì œìˆ˜, ì •ë°±ë‹¹, ì •ì œì—¼, ì •ì œìˆ˜, íš¨ëª¨ì¶”ì¶œë¬¼<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"ë…¹ì°¨ìˆ˜ì œë¹„, í˜¸ë°•ìˆ˜ì œë¹„\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"\"', 'instruction': 'ìˆ™ë©´ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” í’€ìŠ¤í‚¤ì¹œì‚¼ìƒ‰ìŒ€ìˆ˜ì œë¹„ì˜ ì¼ë¶€ ì¬ë£Œê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ì‹ì¬ë£Œë¥¼ ì¶”ì¸¡í•´ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "í’€ìŠ¤í‚¤ì¹œì‚¼ìƒ‰ìŒ€ìˆ˜ì œë¹„<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'input': 'í•µì‹¬ ì¬ë£Œ: \"\"\\nì¼ë°˜ ì¬ë£Œ: \"ì˜¤ë Œì§€í–¥501007\"\\nê³µí†µ ì¬ë£Œ: \"\"\\në§¤ìš° ìì£¼ ë“±ì¥í•˜ëŠ” ì¬ë£Œ: \"êµ¬ì—°ì‚°ë‚˜íŠ¸ë¥¨, ë¹„íƒ€ë¯¼c, ì •ì œìˆ˜, í™”ì´ë°”ì†”2l\"', 'instruction': 'ê³¼ì±„ìŒë£Œ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ” ê°ê·¤ì£¼ìŠ¤ì˜ ì¼ë¶€ ì¬ë£Œê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ì‹ì¬ë£Œë¥¼ ì¶”ì¸¡í•´ë³´ì„¸ìš”.'}\n",
      "\n",
      "### Response:\n",
      "ê°ê·¤ë†ì¶•ì•¡, ê°ê·¤ë†ì¶•ì•¡p, ì •ì œìˆ˜<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from transformers import TextStreamer\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "length = 50 # length of random list\n",
    "random_list = [random.randint(0, len(dataset_dict['test'])) for _ in range(length)]\n",
    "\n",
    "q_list = []; a_list = []; output_list = []\n",
    "for n in random_list:\n",
    "    q = dataset_dict['test'][n]['QUESTION']\n",
    "    a = dataset_dict['test'][n]['ANSWER']\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        [\n",
    "            alpaca_prompt.format(\n",
    "                q,  # ì§€ì‹œì‚¬í•­\n",
    "                \"\",  # ì¶œë ¥ - ìƒì„±ì„ ìœ„í•´ ì´ ë¶€ë¶„ì„ ë¹„ì›Œë‘¡ë‹ˆë‹¤!\n",
    "            )\n",
    "        ],\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    text_streamer = TextStreamer(tokenizer)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        streamer=text_streamer,\n",
    "        max_new_tokens=4096,  # ìµœëŒ€ ìƒì„± í† í° ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "        stopping_criteria=stopping_criteria  # ìƒì„±ì„ ë©ˆì¶œ ê¸°ì¤€ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    )\n",
    "\n",
    "    q_list.append(q)\n",
    "    a_list.append(a)\n",
    "    output_tmp = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    output_list.append(output_tmp[0].split('\\n')[-1].split(', '))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10792857142857143\n"
     ]
    }
   ],
   "source": [
    "# [answer (a_list) ì™€ pred (output_list) ì˜ êµì§‘í•© / answer (a_list) ì˜ ê¸¸ì´]\n",
    "score_list = []\n",
    "for a, p in zip(a_list, output_list):\n",
    "    a = a.split(', ')\n",
    "    cnt = 0\n",
    "    for pp in p:\n",
    "        if pp in a:\n",
    "            cnt += 1\n",
    "    score_list.append(cnt/len(a))\n",
    "\n",
    "print(sum(score_list)/len(score_list)) # mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantization ë°©ì‹ ì„¤ì •\n",
    "quantization_method = \"q8_0\"  # \"f16\" \"q8_0\" \"q4_k_m\" \"q5_k_m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Entering directory '/home/jaesung/pulmuone/instruction_tuning_2/v4_completion/modeling/llama.cpp'\n",
      "I ccache not found. Consider installing it for faster compilation.\n",
      "I llama.cpp build info: \n",
      "I UNAME_S:   Linux\n",
      "I UNAME_P:   x86_64\n",
      "I UNAME_M:   x86_64\n",
      "I CFLAGS:    -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion \n",
      "I CXXFLAGS:  -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE \n",
      "I NVCCFLAGS: -std=c++11 -O3 -g \n",
      "I LDFLAGS:    \n",
      "I CC:        cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "I CXX:       c++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "\n",
      "rm -vrf *.dot libllava.a llama-baby-llama llama-batched llama-batched-bench llama-bench llama-benchmark-matmult llama-cli llama-convert-llama2c-to-ggml llama-embedding llama-eval-callback llama-export-lora llama-gbnf-validator llama-gguf llama-gguf-hash llama-gguf-split llama-gritlm llama-imatrix llama-infill llama-llava-cli llama-minicpmv-cli llama-lookahead llama-lookup llama-lookup-create llama-lookup-merge llama-lookup-stats llama-parallel llama-passkey llama-perplexity llama-q8dot llama-quantize llama-quantize-stats llama-retrieval llama-save-load-state llama-server llama-simple llama-speculative llama-tokenize llama-vdot llama-cvector-generator tests/test-c.o tests/test-autorelease tests/test-backend-ops tests/test-chat-template tests/test-double-float tests/test-grad0 tests/test-grammar-integration tests/test-grammar-parser tests/test-json-schema-to-grammar tests/test-llama-grammar tests/test-model-load-cancel tests/test-opt tests/test-quantize-fns tests/test-quantize-perf tests/test-rope tests/test-sampling tests/test-tokenizer-0 tests/test-tokenizer-1-bpe tests/test-tokenizer-1-spm\n",
      "rm -rvf src/*.o\n",
      "rm -rvf tests/*.o\n",
      "rm -rvf examples/*.o\n",
      "rm -rvf common/*.o\n",
      "rm -rvf *.a\n",
      "rm -rvf *.dll\n",
      "rm -rvf *.so\n",
      "rm -rvf *.dot\n",
      "rm -rvf ggml/*.a\n",
      "rm -rvf ggml/*.dll\n",
      "rm -rvf ggml/*.so\n",
      "rm -vrf ggml/src/*.o\n",
      "rm -rvf ggml/src/llamafile/*.o\n",
      "rm -rvf common/build-info.cpp\n",
      "rm -vrf ggml/src/ggml-metal-embed.metal\n",
      "rm -vrf ggml/src/ggml-cuda/*.o\n",
      "rm -vrf ggml/src/ggml-cuda/template-instances/*.o\n",
      "rm -rvf libllava.a llama-baby-llama llama-batched llama-batched-bench llama-bench llama-benchmark-matmult llama-cli llama-convert-llama2c-to-ggml llama-embedding llama-eval-callback llama-export-lora llama-gbnf-validator llama-gguf llama-gguf-hash llama-gguf-split llama-gritlm llama-imatrix llama-infill llama-llava-cli llama-minicpmv-cli llama-lookahead llama-lookup llama-lookup-create llama-lookup-merge llama-lookup-stats llama-parallel llama-passkey llama-perplexity llama-q8dot llama-quantize llama-quantize-stats llama-retrieval llama-save-load-state llama-server llama-simple llama-speculative llama-tokenize llama-vdot llama-cvector-generator tests/test-c.o\n",
      "rm -rvf tests/test-autorelease tests/test-backend-ops tests/test-chat-template tests/test-double-float tests/test-grad0 tests/test-grammar-integration tests/test-grammar-parser tests/test-json-schema-to-grammar tests/test-llama-grammar tests/test-model-load-cancel tests/test-opt tests/test-quantize-fns tests/test-quantize-perf tests/test-rope tests/test-sampling tests/test-tokenizer-0 tests/test-tokenizer-1-bpe tests/test-tokenizer-1-spm\n",
      "rm -f vulkan-shaders-gen ggml/src/ggml-vulkan-shaders.hpp ggml/src/ggml-vulkan-shaders.cpp\n",
      "rm -rvf main quantize quantize-stats perplexity imatrix embedding vdot q8dot convert-llama2c-to-ggml simple batched batched-bench save-load-state server gguf gguf-split eval-callback llama-bench libllava.a llava-cli baby-llama retrieval speculative infill tokenize benchmark-matmult parallel export-lora lookahead lookup passkey gritlm\n",
      "find examples pocs -type f -name \"*.o\" -delete\n",
      "make: Leaving directory '/home/jaesung/pulmuone/instruction_tuning_2/v4_completion/modeling/llama.cpp'\n",
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 412.55 out of 503.13 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 15.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Converting llama model. Can use fast conversion = False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
      "   \\\\   /|    [0] Installing llama.cpp will take 3 minutes.\n",
      "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits will take 3 minutes.\n",
      "\\        /    [2] Converting GGUF 16bits to ['q8_0'] will take 10 minutes each.\n",
      " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
      "\n",
      "Unsloth: [0] Installing llama.cpp. This will take 3 minutes...\n",
      "Unsloth: [1] Converting model at Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38-gguf into q8_0 GGUF format.\n",
      "The output location will be ./Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38-gguf/unsloth.Q8_0.gguf\n",
      "This will take 3 minutes...\n",
      "INFO:hf-to-gguf:Loading model: Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38-gguf\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:token_embd.weight,           torch.bfloat16 --> Q8_0, shape = {4096, 128256}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00004-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:output.weight,               torch.bfloat16 --> Q8_0, shape = {4096, 128256}\n",
      "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:output_norm.weight,          torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:gguf: context length = 8192\n",
      "INFO:hf-to-gguf:gguf: embedding length = 4096\n",
      "INFO:hf-to-gguf:gguf: feed forward length = 14336\n",
      "INFO:hf-to-gguf:gguf: head count = 32\n",
      "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
      "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
      "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
      "INFO:hf-to-gguf:gguf: file type = 7\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "INFO:gguf.vocab:Adding 280147 merge(s).\n",
      "INFO:gguf.vocab:Setting special token type bos to 128000\n",
      "INFO:gguf.vocab:Setting special token type eos to 128001\n",
      "INFO:gguf.vocab:Setting special token type pad to 128255\n",
      "INFO:gguf.vocab:Setting chat_template to {% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
      "\n",
      "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "' }}{% endif %}\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38-gguf/unsloth.Q8_0.gguf: n_tensors = 291, total_size = 8.5G\n",
      "Writing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8.53G/8.53G [01:27<00:00, 98.0Mbyte/s]\n",
      "INFO:hf-to-gguf:Model successfully exported to Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38-gguf/unsloth.Q8_0.gguf\n",
      "Unsloth: Conversion completed! Output location: ./Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38-gguf/unsloth.Q8_0.gguf\n",
      "Unsloth: Uploading GGUF to Huggingface Hub...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unsloth.Q8_0.gguf: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8.54G/8.54G [05:05<00:00, 28.0MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GGUF to https://huggingface.co/passionMan/Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v6-38-gguf\n"
     ]
    }
   ],
   "source": [
    "# Hub ì— GGUF ì—…ë¡œë“œ\n",
    "model.push_to_hub_gguf(\n",
    "    huggingface_repo + \"-gguf\",\n",
    "    tokenizer,\n",
    "    quantization_method=quantization_method,\n",
    "    token=huggingface_token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpaca_kernel",
   "language": "python",
   "name": "alpaca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
