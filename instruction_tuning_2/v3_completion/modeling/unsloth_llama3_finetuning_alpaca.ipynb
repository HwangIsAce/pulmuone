{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## unsloth_env_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# CUDA 장치의 주요 버전과 부 버전을 가져옵니다.\n",
    "major_version, minor_version = torch.cuda.get_device_capability()\n",
    "major_version, minor_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[unsloth]\n",
    "\n",
    "unsloth 패키지는 대형 언어 모델(LLM)인 Llama 3.1, Mistral, Phi 및 Gemma의 미세 조정을 기존 방법보다 2-5배 빠르게 하고 메모리 사용량을 80%까지 줄이는 데 사용되는 도구입니다. 이 패키지는 OpenAI의 Triton 언어로 작성된 커스텀 GPU 커널을 사용하여 성능을 최적화합니다. 이를 통해 정확도 손실 없이 효율적으로 모델을 훈련할 수 있습니다.\n",
    "\n",
    "주요 기능\n",
    "성능: 특정 경우에는 최대 30배 빠르게 미세 조정할 수 있으며, 메모리 사용량을 크게 줄여 더 큰 배치 크기와 효율적인 훈련이 가능합니다.\n",
    "호환성: NVIDIA, Intel, AMD 등 다양한 GPU를 지원합니다.\n",
    "메모리 최적화: 메모리 사용량을 줄이기 위해 수동 미분 및 체인 매트릭스 곱셈 최적화를 수행합니다.\n",
    "오픈 소스: 무료 오픈 소스 버전이 있으며, 프로 버전에서는 다중 GPU 지원 및 더 빠른 훈련 속도를 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Colab에서 torch 2.2.1을 사용하고 있으므로, 패키지 충돌을 방지하기 위해 별도로 설치해야 합니다.\n",
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "if major_version >= 8:\n",
    "    # 새로운 GPU(예: Ampere, Hopper GPUs - RTX 30xx, RTX 40xx, A100, H100, L40)에 사용하세요.\n",
    "    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n",
    "else:\n",
    "    # 오래된 GPU(예: V100, Tesla T4, RTX 20xx)에 사용하세요.\n",
    "    !pip install --no-deps xformers trl peft accelerate bitsandbytes\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaesung/anaconda3/envs/alpaca/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.44.0.\n",
      "   \\\\   /|    GPU: NVIDIA A10. Max memory: 21.988 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27.post2. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.35s/it]\n",
      "beomi/Llama-3-Open-Ko-8B-Instruct-preview does not have a padding token! Will use pad_token = <|reserved_special_token_250|>.\n",
      "<string>:209: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:210: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:211: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:209: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:210: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:211: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from accelerate import PartialState\n",
    "\n",
    "device_string = PartialState().process_index\n",
    "\n",
    "max_seq_length = 4096  # 최대 시퀀스 길이를 설정합니다. 내부적으로 RoPE 스케일링을 자동으로 지원합니다!\n",
    "# 자동 감지를 위해 None을 사용합니다. Tesla T4, V100은 Float16, Ampere+는 Bfloat16을 사용하세요.\n",
    "dtype = None\n",
    "# 메모리 사용량을 줄이기 위해 4bit 양자화를 사용합니다. False일 수도 있습니다.\n",
    "load_in_4bit = True\n",
    "\n",
    "# 4배 빠른 다운로드와 메모리 부족 문제를 방지하기 위해 지원하는 4bit 사전 양자화 모델입니다.\n",
    "fourbit_models = [\n",
    "    \"unsloth/mistral-7b-bnb-4bit\",\n",
    "    \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n",
    "    \"unsloth/llama-2-7b-bnb-4bit\",\n",
    "    \"unsloth/gemma-7b-bnb-4bit\",\n",
    "    \"unsloth/gemma-7b-it-bnb-4bit\",  # Gemma 7b의 Instruct 버전\n",
    "    \"unsloth/gemma-2b-bnb-4bit\",\n",
    "    \"unsloth/gemma-2b-it-bnb-4bit\",  # Gemma 2b의 Instruct 버전\n",
    "    \"unsloth/llama-3-8b-bnb-4bit\",  # Llama-3 8B\n",
    "]  # 더 많은 모델은 https://huggingface.co/unsloth 에서 확인할 수 있습니다.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    # model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n",
    "    model_name=\"beomi/Llama-3-Open-Ko-8B-Instruct-preview\",  # 모델 이름을 설정합니다.\n",
    "    max_seq_length=max_seq_length,  # 최대 시퀀스 길이를 설정합니다.\n",
    "    dtype=dtype,  # 데이터 타입을 설정합니다.\n",
    "    load_in_4bit=load_in_4bit,  # 4bit 양자화 로드 여부를 설정합니다.\n",
    "    # token = \"hf_...\", # 게이트된 모델을 사용하는 경우 토큰을 사용하세요. 예: meta-llama/Llama-2-7b-hf,\n",
    "    device_map={'':device_string}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2024.8 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    # r=16,\n",
    "    r=32,  # 0보다 큰 어떤 숫자도 선택 가능! 8, 16, 32, 64, 128이 권장됩니다. # 얼마나 압축할지, 많이 압축할 수록 파라미터 수가 작아집니다.\n",
    "    lora_alpha=32,  # LoRA 알파 값을 설정합니다.\n",
    "    lora_dropout=0.05,  # 드롭아웃을 지원합니다.\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],  # 타겟 모듈을 지정합니다.\n",
    "    bias=\"none\",  # 바이어스를 지원합니다.\n",
    "    # True 또는 \"unsloth\"를 사용하여 매우 긴 컨텍스트에 대해 VRAM을 30% 덜 사용하고, 2배 더 큰 배치 크기를 지원합니다.\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=123,  # 난수 상태를 설정합니다.\n",
    "    use_rslora=False,  # 순위 안정화 LoRA를 지원합니다.\n",
    "    loftq_config=None,  # LoftQ를 지원합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# EOS_TOKEN은 문장의 끝을 나타내는 토큰입니다. 이 토큰을 추가해야 합니다.\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "# AlpacaPrompt를 사용하여 지시사항을 포맷팅하는 함수입니다.\n",
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "\n",
    "# 주어진 예시들을 포맷팅하는 함수입니다.\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"QUESTION\"]  # 지시사항을 가져옵니다.\n",
    "    outputs = examples[\"ANSWER\"]  # 출력값을 가져옵니다.\n",
    "    texts = []  # 포맷팅된 텍스트를 저장할 리스트입니다.\n",
    "    for instruction, output in zip(instructions, outputs):\n",
    "        # EOS_TOKEN을 추가해야 합니다. 그렇지 않으면 생성이 무한히 진행될 수 있습니다.\n",
    "        text = alpaca_prompt.format(instruction, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\n",
    "        \"text\": texts,  # 포맷팅된 텍스트를 반환합니다.\n",
    "    }\n",
    "\n",
    "# JSONL 파일 로드 함수\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data\n",
    "\n",
    "# JSONL 파일 경로\n",
    "file_path = '/home/jaesung/pulmuone/alpaca_rec_turning/completion/data/qa_pair_for_completion.jsonl'\n",
    "\n",
    "# JSONL 파일 로드\n",
    "data = load_jsonl(file_path)\n",
    "\n",
    "# pandas DataFrame으로 변환\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Dataset 객체로 변환\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# DatasetDict 객체로 결합\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['QUESTION', 'ANSWER', '__index_level_0__'],\n",
      "        num_rows: 3398\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['QUESTION', 'ANSWER', '__index_level_0__'],\n",
      "        num_rows: 850\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_dict['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['QUESTION', 'ANSWER', '__index_level_0__'],\n",
       "    num_rows: 3398\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3398/3398 [00:00<00:00, 47143.69 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋에 formatting_prompts_func 함수를 적용합니다. 배치 처리를 활성화합니다.\n",
    "dataset = dataset.map(\n",
    "    formatting_prompts_func,\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaesung/anaconda3/envs/alpaca/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/jaesung/anaconda3/envs/alpaca/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Map (num_proc=2): 100%|██████████| 3398/3398 [00:01<00:00, 2449.11 examples/s]\n",
      "Map (num_proc=2): 100%|██████████| 3398/3398 [00:01<00:00, 2457.10 examples/s]\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "from accelerate import notebook_launcher\n",
    "\n",
    "tokenizer.padding_side = \"right\"  # 토크나이저의 패딩을 오른쪽으로 설정합니다.\n",
    "\n",
    "# SFTTrainer를 사용하여 모델 학습 설정\n",
    "trainer = SFTTrainer(\n",
    "    model=model,  # 학습할 모델\n",
    "    tokenizer=tokenizer,  # 토크나이저\n",
    "    train_dataset=dataset,  # 학습 데이터셋\n",
    "    eval_dataset=dataset,\n",
    "    dataset_text_field=\"text\",  # 데이터셋에서 텍스트 필드의 이름\n",
    "    max_seq_length=max_seq_length,  # 최대 시퀀스 길이\n",
    "    dataset_num_proc=2,  # 데이터 처리에 사용할 프로세스 수\n",
    "    packing=False,  # 짧은 시퀀스에 대한 학습 속도를 5배 빠르게 할 수 있음,\n",
    "\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=2,  # 각 디바이스당 훈련 배치 크기\n",
    "        gradient_accumulation_steps=4,\n",
    "        # gradient_accumulation_steps=2,  # 그래디언트 누적 단계\n",
    "        warmup_steps=5,  # 웜업 스텝 수\n",
    "        num_train_epochs=3,  # 훈련 에폭 수\n",
    "        max_steps=30,  # 최대 스텝 수\n",
    "        do_eval=True,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        logging_steps=1,  # logging 스텝 수\n",
    "        learning_rate=2e-4,  # 학습률\n",
    "        fp16=not torch.cuda.is_bf16_supported(),  # fp16 사용 여부, bf16이 지원되지 않는 경우에만 사용\n",
    "        bf16=torch.cuda.is_bf16_supported(),  # bf16 사용 여부, bf16이 지원되는 경우에만 사용\n",
    "        optim=\"adamw_8bit\",  # 최적화 알고리즘\n",
    "        weight_decay=0.01,  # 가중치 감소\n",
    "        lr_scheduler_type=\"cosine\",  # 학습률 스케줄러 유형\n",
    "        seed=123,  # 랜덤 시드\n",
    "        output_dir=\"outputs\",  # 출력 디렉토리\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA A10. Max memory = 21.988 GB.\n",
      "5.781 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "# 현재 메모리 상태를 보여주는 코드\n",
    "gpu_stats = torch.cuda.get_device_properties(0)  # GPU 속성 가져오기\n",
    "start_gpu_memory = round(\n",
    "    torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3\n",
    ")  # 시작 시 예약된 GPU 메모리 계산\n",
    "max_memory = round(\n",
    "    gpu_stats.total_memory / 1024 / 1024 / 1024, 3\n",
    ")  # GPU의 최대 메모리 계산\n",
    "print(\n",
    "    f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\"\n",
    ")  # GPU 이름과 최대 메모리 출력\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")  # 예약된 메모리 양 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 3,398 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 30\n",
      " \"-____-\"     Number of trainable parameters = 83,886,080\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 2:24:50, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.425300</td>\n",
       "      <td>3.427506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.372200</td>\n",
       "      <td>3.378253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.415900</td>\n",
       "      <td>3.102912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.139000</td>\n",
       "      <td>2.672275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.613200</td>\n",
       "      <td>2.317697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.258200</td>\n",
       "      <td>1.977137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.890200</td>\n",
       "      <td>1.667182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.633600</td>\n",
       "      <td>1.468275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.339600</td>\n",
       "      <td>1.325193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.306600</td>\n",
       "      <td>1.263174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.094300</td>\n",
       "      <td>1.191186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.240100</td>\n",
       "      <td>1.112632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.101700</td>\n",
       "      <td>1.058933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.955300</td>\n",
       "      <td>1.023601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>1.001187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.003300</td>\n",
       "      <td>0.969656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.970200</td>\n",
       "      <td>0.943163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.830700</td>\n",
       "      <td>0.916818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.803000</td>\n",
       "      <td>0.895498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.006300</td>\n",
       "      <td>0.877060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.791400</td>\n",
       "      <td>0.861690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.948800</td>\n",
       "      <td>0.846395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.885300</td>\n",
       "      <td>0.833700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.795100</td>\n",
       "      <td>0.821995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.895100</td>\n",
       "      <td>0.813229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.844900</td>\n",
       "      <td>0.807363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.796400</td>\n",
       "      <td>0.803985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.740200</td>\n",
       "      <td>0.802055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.022400</td>\n",
       "      <td>0.801061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.847900</td>\n",
       "      <td>0.800832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()  # 모델을 훈련시키고 통계를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8694.7836 seconds used for training.\n",
      "144.91 minutes used for training.\n",
      "Peak reserved memory = 9.637 GB.\n",
      "Peak reserved memory for training = 3.856 GB.\n",
      "Peak reserved memory % of max memory = 43.828 %.\n",
      "Peak reserved memory for training % of max memory = 17.537 %.\n"
     ]
    }
   ],
   "source": [
    "# 최종 메모리 및 시간 통계를 보여줍니다.\n",
    "used_memory = round(\n",
    "    torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3\n",
    ")  # 사용된 최대 메모리를 GB 단위로 계산합니다.\n",
    "used_memory_for_lora = round(\n",
    "    used_memory - start_gpu_memory, 3\n",
    ")  # LoRA를 위해 사용된 메모리를 GB 단위로 계산합니다.\n",
    "used_percentage = round(\n",
    "    used_memory / max_memory * 100, 3\n",
    ")  # 최대 메모리 대비 사용된 메모리의 비율을 계산합니다.\n",
    "lora_percentage = round(\n",
    "    used_memory_for_lora / max_memory * 100, 3\n",
    ")  # 최대 메모리 대비 LoRA를 위해 사용된 메모리의 비율을 계산합니다.\n",
    "print(\n",
    "    f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\"\n",
    ")  # 훈련에 사용된 시간을 초 단위로 출력합니다.\n",
    "print(\n",
    "    # 훈련에 사용된 시간을 분 단위로 출력합니다.\n",
    "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
    ")\n",
    "print(\n",
    "    f\"Peak reserved memory = {used_memory} GB.\"\n",
    ")  # 예약된 최대 메모리를 GB 단위로 출력합니다.\n",
    "print(\n",
    "    f\"Peak reserved memory for training = {used_memory_for_lora} GB.\"\n",
    ")  # 훈련을 위해 예약된 최대 메모리를 GB 단위로 출력합니다.\n",
    "print(\n",
    "    f\"Peak reserved memory % of max memory = {used_percentage} %.\"\n",
    ")  # 최대 메모리 대비 예약된 메모리의 비율을 출력합니다.\n",
    "print(\n",
    "    f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\"\n",
    ")  # 최대 메모리 대비 훈련을 위해 예약된 메모리의 비율을 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"beomi/Llama-3-Open-Ko-8B-Instruct-preview\" # 병합을 수행할 베이스 모델\n",
    "huggingface_token = \"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\"  # HuggingFace 토큰\n",
    "huggingface_repo = \"Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v4-30\"  # 모델을 업로드할 repository\n",
    "save_method = (\n",
    "    \"merged_16bit\"  # \"merged_4bit\", \"merged_4bit_forced\", \"merged_16bit\", \"lora\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 366.57 out of 503.13 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 22/32 [00:00<00:00, 32.28it/s]We will save to Disk and not RAM now.\n",
      "100%|██████████| 32/32 [00:05<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving to organization with address passionMan/Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v4-30\n",
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
      "Unsloth: Saving to organization with address passionMan/Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v4-30\n",
      "Unsloth: Uploading all files... Please wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 16.4k/4.98G [00:00<12:00:40, 115kB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 393k/4.98G [00:00<46:34, 1.78MB/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 2.64M/4.98G [00:00<13:24, 6.18MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 3.65M/4.98G [00:00<13:47, 6.01MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 9.11M/4.98G [00:00<05:28, 15.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 10.8M/4.98G [00:01<08:48, 9.40MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 12.4M/4.98G [00:01<08:52, 9.32MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 13.9M/4.98G [00:01<08:39, 9.56MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 16.0M/4.98G [00:02<13:45, 6.01MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 20.6M/4.98G [00:02<08:06, 10.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 24.0M/4.98G [00:02<06:29, 12.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 25.7M/4.98G [00:02<07:24, 11.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 27.9M/4.98G [00:03<13:01, 6.33MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 29.9M/4.98G [00:03<11:10, 7.37MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 42.5M/4.98G [00:04<05:43, 14.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 52.2M/4.98G [00:05<04:55, 16.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 58.4M/4.98G [00:05<04:17, 19.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 60.9M/4.98G [00:06<10:22, 7.90MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|▏         | 62.8M/4.98G [00:06<09:18, 8.79MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|▏         | 64.6M/4.98G [00:07<13:09, 6.22MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|▏         | 70.3M/4.98G [00:07<07:35, 10.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 76.2M/4.98G [00:07<05:02, 16.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 80.0M/4.98G [00:07<05:32, 14.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 84.2M/4.98G [00:07<04:38, 17.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 88.5M/4.98G [00:07<03:46, 21.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 91.7M/4.98G [00:08<08:36, 9.45MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 94.1M/4.98G [00:09<09:00, 9.03MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 96.0M/4.98G [00:09<12:07, 6.71MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 102M/4.98G [00:09<07:33, 10.8MB/s] \n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 107M/4.98G [00:09<05:36, 14.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 112M/4.98G [00:10<04:12, 19.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 115M/4.98G [00:10<05:08, 15.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 121M/4.98G [00:10<04:31, 17.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 123M/4.98G [00:11<09:50, 8.22MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 125M/4.98G [00:11<09:06, 8.88MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 127M/4.98G [00:11<08:59, 9.00MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 128M/4.98G [00:12<13:37, 5.93MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 134M/4.98G [00:12<07:13, 11.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 141M/4.98G [00:12<04:33, 17.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 156M/4.98G [00:13<03:07, 25.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 160M/4.98G [00:13<03:40, 21.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 166M/4.98G [00:13<03:02, 26.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 173M/4.98G [00:13<02:17, 34.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▎         | 178M/4.98G [00:14<03:14, 24.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▎         | 182M/4.98G [00:14<02:56, 27.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 192M/4.98G [00:14<02:22, 33.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 196M/4.98G [00:14<03:18, 24.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 199M/4.98G [00:14<03:25, 23.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 202M/4.98G [00:14<03:31, 22.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 205M/4.98G [00:15<03:22, 23.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 208M/4.98G [00:15<05:27, 14.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 213M/4.98G [00:15<03:54, 20.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 216M/4.98G [00:15<03:47, 20.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 219M/4.98G [00:15<03:39, 21.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 222M/4.98G [00:15<03:24, 23.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▍         | 230M/4.98G [00:16<04:09, 19.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▍         | 237M/4.98G [00:16<03:21, 23.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▍         | 248M/4.98G [00:17<04:34, 17.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▌         | 252M/4.98G [00:17<03:59, 19.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▌         | 255M/4.98G [00:17<03:33, 22.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▌         | 258M/4.98G [00:18<04:35, 17.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▌         | 262M/4.98G [00:18<03:55, 20.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▌         | 269M/4.98G [00:18<03:12, 24.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▌         | 272M/4.98G [00:18<04:59, 15.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 278M/4.98G [00:19<03:32, 22.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 282M/4.98G [00:19<03:15, 24.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 285M/4.98G [00:19<03:03, 25.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 288M/4.98G [00:19<04:37, 16.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 301M/4.98G [00:19<02:57, 26.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 304M/4.98G [00:20<04:49, 16.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 310M/4.98G [00:20<03:43, 20.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▋         | 314M/4.98G [00:20<03:20, 23.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▋         | 318M/4.98G [00:20<03:05, 25.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▋         | 321M/4.98G [00:21<04:41, 16.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 326M/4.98G [00:21<03:54, 19.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 329M/4.98G [00:21<03:31, 22.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 333M/4.98G [00:21<03:12, 24.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 342M/4.98G [00:22<03:51, 20.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 345M/4.98G [00:22<03:29, 22.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 350M/4.98G [00:22<03:06, 24.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 353M/4.98G [00:23<06:07, 12.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 356M/4.98G [00:23<05:21, 14.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 360M/4.98G [00:23<04:25, 17.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 364M/4.98G [00:23<03:50, 20.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 367M/4.98G [00:23<03:23, 22.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 370M/4.98G [00:23<04:41, 16.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 377M/4.98G [00:24<03:31, 21.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 381M/4.98G [00:24<02:58, 25.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 384M/4.98G [00:24<04:33, 16.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 391M/4.98G [00:24<03:21, 22.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 395M/4.98G [00:24<02:52, 26.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 399M/4.98G [00:24<02:53, 26.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 402M/4.98G [00:25<04:33, 16.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 406M/4.98G [00:25<03:57, 19.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 409M/4.98G [00:25<03:30, 21.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 413M/4.98G [00:25<03:09, 24.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 416M/4.98G [00:26<04:52, 15.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 422M/4.98G [00:26<03:40, 20.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▊         | 430M/4.98G [00:26<02:45, 27.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▊         | 433M/4.98G [00:26<05:01, 15.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 438M/4.98G [00:27<04:14, 17.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 441M/4.98G [00:27<03:45, 20.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 446M/4.98G [00:27<03:14, 23.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 449M/4.98G [00:27<05:57, 12.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 452M/4.98G [00:28<05:11, 14.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 455M/4.98G [00:28<04:29, 16.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 460M/4.98G [00:28<03:47, 19.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 463M/4.98G [00:28<03:38, 20.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 466M/4.98G [00:28<05:14, 14.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 468M/4.98G [00:28<04:48, 15.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 472M/4.98G [00:29<04:07, 18.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 476M/4.98G [00:29<03:49, 19.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 482M/4.98G [00:29<05:23, 13.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 484M/4.98G [00:29<04:49, 15.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 488M/4.98G [00:29<04:05, 18.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 491M/4.98G [00:30<03:48, 19.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 495M/4.98G [00:30<03:30, 21.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 497M/4.98G [00:30<05:34, 13.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|█         | 500M/4.98G [00:30<04:42, 15.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|█         | 504M/4.98G [00:30<03:58, 18.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|█         | 507M/4.98G [00:30<03:46, 19.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|█         | 511M/4.98G [00:31<03:24, 21.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|█         | 513M/4.98G [00:31<06:32, 11.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|█         | 516M/4.98G [00:31<05:21, 13.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|█         | 520M/4.98G [00:31<04:26, 16.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 523M/4.98G [00:32<03:58, 18.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 527M/4.98G [00:32<03:34, 20.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 530M/4.98G [00:32<05:26, 13.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 532M/4.98G [00:32<04:54, 15.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 536M/4.98G [00:32<04:04, 18.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 540M/4.98G [00:32<03:38, 20.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 543M/4.98G [00:33<03:25, 21.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 546M/4.98G [00:33<05:17, 14.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 548M/4.98G [00:33<04:42, 15.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 556M/4.98G [00:33<03:31, 20.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█▏        | 560M/4.98G [00:34<04:50, 15.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█▏        | 566M/4.98G [00:34<03:36, 20.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█▏        | 569M/4.98G [00:34<03:22, 21.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 572M/4.98G [00:34<03:10, 23.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 575M/4.98G [00:34<03:02, 24.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 578M/4.98G [00:35<04:37, 15.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 582M/4.98G [00:35<04:11, 17.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 585M/4.98G [00:35<03:39, 20.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 588M/4.98G [00:35<03:27, 21.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 592M/4.98G [00:35<03:11, 22.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 594M/4.98G [00:35<04:33, 16.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 598M/4.98G [00:36<03:59, 18.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 601M/4.98G [00:36<03:35, 20.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 605M/4.98G [00:36<03:15, 22.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 608M/4.98G [00:36<03:06, 23.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 610M/4.98G [00:36<04:13, 17.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 618M/4.98G [00:36<03:16, 22.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 621M/4.98G [00:37<03:11, 22.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 624M/4.98G [00:37<05:20, 13.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 628M/4.98G [00:37<04:07, 17.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 632M/4.98G [00:37<03:38, 19.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 640M/4.98G [00:38<03:03, 23.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 643M/4.98G [00:38<04:20, 16.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 646M/4.98G [00:38<03:55, 18.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 649M/4.98G [00:38<03:31, 20.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 653M/4.98G [00:38<03:12, 22.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 656M/4.98G [00:39<05:01, 14.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 660M/4.98G [00:39<03:56, 18.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 665M/4.98G [00:39<03:25, 21.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 669M/4.98G [00:39<03:10, 22.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▎        | 672M/4.98G [00:40<05:02, 14.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▎        | 678M/4.98G [00:40<03:51, 18.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▎        | 682M/4.98G [00:40<03:32, 20.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 685M/4.98G [00:40<03:12, 22.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 696M/4.98G [00:41<03:34, 19.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 699M/4.98G [00:41<03:17, 21.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 702M/4.98G [00:41<03:01, 23.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 705M/4.98G [00:41<05:00, 14.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 708M/4.98G [00:41<04:18, 16.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 712M/4.98G [00:42<03:43, 19.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 715M/4.98G [00:42<03:23, 20.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 718M/4.98G [00:42<03:05, 23.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 721M/4.98G [00:42<05:01, 14.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 724M/4.98G [00:42<04:10, 17.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 728M/4.98G [00:42<03:37, 19.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 731M/4.98G [00:43<03:16, 21.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 734M/4.98G [00:43<03:00, 23.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 737M/4.98G [00:43<04:57, 14.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 742M/4.98G [00:43<03:55, 18.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 746M/4.98G [00:43<03:29, 20.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 750M/4.98G [00:44<03:09, 22.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 752M/4.98G [00:44<04:47, 14.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 758M/4.98G [00:44<03:42, 19.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 762M/4.98G [00:44<03:14, 21.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 765M/4.98G [00:44<03:08, 22.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 774M/4.98G [00:45<03:39, 19.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 778M/4.98G [00:45<03:18, 21.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 782M/4.98G [00:45<02:58, 23.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 785M/4.98G [00:46<04:57, 14.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 793M/4.98G [00:46<03:26, 20.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 797M/4.98G [00:46<03:05, 22.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 800M/4.98G [00:46<04:45, 14.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 806M/4.98G [00:47<03:36, 19.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▋        | 809M/4.98G [00:47<03:16, 21.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▋        | 813M/4.98G [00:47<02:59, 23.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▋        | 816M/4.98G [00:47<04:48, 14.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 822M/4.98G [00:47<03:36, 19.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 826M/4.98G [00:48<03:09, 21.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 830M/4.98G [00:48<02:52, 24.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 833M/4.98G [00:48<04:12, 16.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 838M/4.98G [00:48<03:29, 19.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 841M/4.98G [00:48<03:06, 22.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 845M/4.98G [00:48<02:48, 24.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 848M/4.98G [00:49<04:00, 17.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 854M/4.98G [00:49<03:01, 22.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 857M/4.98G [00:49<02:45, 24.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 862M/4.98G [00:49<02:29, 27.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 866M/4.98G [00:50<03:54, 17.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 870M/4.98G [00:50<03:23, 20.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 875M/4.98G [00:50<02:52, 23.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 880M/4.98G [00:50<03:58, 17.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 885M/4.98G [00:50<03:09, 21.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 888M/4.98G [00:50<02:57, 23.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 892M/4.98G [00:51<02:39, 25.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 896M/4.98G [00:51<03:38, 18.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 907M/4.98G [00:51<02:21, 28.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 912M/4.98G [00:51<02:11, 30.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 916M/4.98G [00:52<03:07, 21.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 918M/4.98G [00:52<03:04, 22.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▊        | 922M/4.98G [00:52<02:45, 24.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▊        | 927M/4.98G [00:52<02:20, 28.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 934M/4.98G [00:52<03:08, 21.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 939M/4.98G [00:53<02:39, 25.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 944M/4.98G [00:53<02:32, 26.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 947M/4.98G [00:53<03:42, 18.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 950M/4.98G [00:53<03:33, 18.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 954M/4.98G [00:53<03:06, 21.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 957M/4.98G [00:53<02:49, 23.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 966M/4.98G [00:54<03:27, 19.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 970M/4.98G [00:54<02:59, 22.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|█▉        | 974M/4.98G [00:54<02:43, 24.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|█▉        | 977M/4.98G [00:55<03:56, 16.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|█▉        | 982M/4.98G [00:55<03:04, 21.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|█▉        | 986M/4.98G [00:55<02:45, 24.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|█▉        | 989M/4.98G [00:55<02:31, 26.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|█▉        | 992M/4.98G [00:55<03:48, 17.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|██        | 998M/4.98G [00:55<02:51, 23.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|██        | 1.00G/4.98G [00:56<02:34, 25.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|██        | 1.01G/4.98G [00:56<02:14, 29.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|██        | 1.01G/4.98G [00:57<06:43, 9.83MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|██        | 1.01G/4.98G [00:57<06:17, 10.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.02G/4.98G [00:57<04:01, 16.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.03G/4.98G [00:58<03:07, 21.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.04G/4.98G [00:58<02:35, 25.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.04G/4.98G [00:58<03:18, 19.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.05G/4.98G [00:58<03:00, 21.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.05G/4.98G [00:59<02:32, 25.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.06G/4.98G [00:59<02:23, 27.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██▏       | 1.06G/4.98G [00:59<03:26, 19.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██▏       | 1.06G/4.98G [00:59<03:10, 20.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██▏       | 1.07G/4.98G [00:59<02:30, 25.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.07G/4.98G [00:59<02:23, 27.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.07G/4.98G [01:00<03:34, 18.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.08G/4.98G [01:00<03:05, 21.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.08G/4.98G [01:00<02:40, 24.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.09G/4.98G [01:00<03:36, 18.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.09G/4.98G [01:00<02:41, 24.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.10G/4.98G [01:01<02:41, 24.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.10G/4.98G [01:01<02:20, 27.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.11G/4.98G [01:01<03:19, 19.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.11G/4.98G [01:01<02:57, 21.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.12G/4.98G [01:01<02:17, 28.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.12G/4.98G [01:02<03:28, 18.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.13G/4.98G [01:02<03:00, 21.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.13G/4.98G [01:02<02:19, 27.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.14G/4.98G [01:03<03:36, 17.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.14G/4.98G [01:03<03:01, 21.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.15G/4.98G [01:03<02:30, 25.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.15G/4.98G [01:03<02:11, 29.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.16G/4.98G [01:03<02:54, 21.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.16G/4.98G [01:03<02:49, 22.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.16G/4.98G [01:03<02:38, 24.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.17G/4.98G [01:03<02:13, 28.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.17G/4.98G [01:04<03:33, 17.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  24%|██▎       | 1.17G/4.98G [01:04<02:50, 22.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  24%|██▎       | 1.18G/4.98G [01:04<02:34, 24.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  24%|██▎       | 1.18G/4.98G [01:04<02:23, 26.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.18G/4.98G [01:05<03:49, 16.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.19G/4.98G [01:05<02:51, 22.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.20G/4.98G [01:05<02:25, 25.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.20G/4.98G [01:05<03:28, 18.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.21G/4.98G [01:05<02:51, 22.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.21G/4.98G [01:06<02:34, 24.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.21G/4.98G [01:06<02:23, 26.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.22G/4.98G [01:06<03:42, 16.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|██▍       | 1.22G/4.98G [01:06<02:58, 21.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|██▍       | 1.23G/4.98G [01:06<02:44, 22.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|██▍       | 1.23G/4.98G [01:06<02:33, 24.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|██▍       | 1.23G/4.98G [01:07<04:05, 15.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|██▍       | 1.24G/4.98G [01:07<03:06, 20.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|██▍       | 1.24G/4.98G [01:07<02:47, 22.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|██▌       | 1.24G/4.98G [01:07<02:34, 24.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|██▌       | 1.25G/4.98G [01:08<03:57, 15.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|██▌       | 1.25G/4.98G [01:08<03:00, 20.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|██▌       | 1.26G/4.98G [01:08<02:29, 24.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|██▌       | 1.26G/4.98G [01:08<03:42, 16.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.27G/4.98G [01:09<03:02, 20.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.27G/4.98G [01:09<02:42, 22.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.28G/4.98G [01:09<02:27, 25.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.28G/4.98G [01:09<03:41, 16.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.29G/4.98G [01:09<02:54, 21.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.29G/4.98G [01:09<02:38, 23.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.29G/4.98G [01:09<02:28, 24.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors: 100%|██████████| 1.17G/1.17G [01:10<00:00, 16.5MB/s]\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.30G/4.98G [01:10<05:31, 11.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  26%|██▋       | 1.31G/4.98G [01:11<02:56, 20.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  26%|██▋       | 1.31G/4.98G [01:11<04:01, 15.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  26%|██▋       | 1.32G/4.98G [01:11<03:02, 20.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.32G/4.98G [01:11<02:41, 22.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.33G/4.98G [01:11<02:25, 25.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.33G/4.98G [01:12<03:47, 16.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.34G/4.98G [01:12<02:41, 22.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.34G/4.98G [01:12<02:23, 25.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.35G/4.98G [01:13<03:41, 16.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.35G/4.98G [01:13<03:00, 20.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.36G/4.98G [01:13<02:17, 26.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.37G/4.98G [01:13<02:40, 22.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.37G/4.98G [01:13<02:24, 25.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.37G/4.98G [01:14<02:07, 28.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.39G/4.98G [01:14<02:27, 24.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.39G/4.98G [01:14<02:09, 27.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.39G/4.98G [01:15<03:04, 19.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.40G/4.98G [01:15<02:53, 20.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.40G/4.98G [01:15<02:25, 24.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.41G/4.98G [01:15<03:26, 17.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.41G/4.98G [01:16<02:48, 21.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.42G/4.98G [01:16<02:29, 23.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  29%|██▊       | 1.42G/4.98G [01:16<02:14, 26.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  29%|██▊       | 1.43G/4.98G [01:16<02:33, 23.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.44G/4.98G [01:16<02:04, 28.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.44G/4.98G [01:17<03:07, 18.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.45G/4.98G [01:17<02:30, 23.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.45G/4.98G [01:17<02:13, 26.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.47G/4.98G [01:18<02:22, 24.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  30%|██▉       | 1.47G/4.98G [01:18<03:18, 17.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  30%|██▉       | 1.48G/4.98G [01:18<02:38, 22.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  30%|██▉       | 1.48G/4.98G [01:19<02:22, 24.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  30%|███       | 1.49G/4.98G [01:19<02:23, 24.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  30%|███       | 1.50G/4.98G [01:19<02:11, 26.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  30%|███       | 1.50G/4.98G [01:19<01:57, 29.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  30%|███       | 1.51G/4.98G [01:20<02:54, 19.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  30%|███       | 1.51G/4.98G [01:20<02:19, 24.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  30%|███       | 1.52G/4.98G [01:20<02:07, 27.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.52G/4.98G [01:20<03:14, 17.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.53G/4.98G [01:21<02:12, 26.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.53G/4.98G [01:21<02:02, 28.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.54G/4.98G [01:21<04:47, 12.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.54G/4.98G [01:21<04:05, 14.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.55G/4.98G [01:22<02:46, 20.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  31%|███▏      | 1.56G/4.98G [01:22<02:27, 23.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  31%|███▏      | 1.57G/4.98G [01:23<02:08, 26.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.57G/4.98G [01:23<03:09, 18.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.58G/4.98G [01:23<02:13, 25.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.59G/4.98G [01:24<02:28, 22.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.59G/4.98G [01:24<02:14, 25.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.60G/4.98G [01:24<02:01, 27.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.61G/4.98G [01:24<02:18, 24.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.61G/4.98G [01:25<02:04, 27.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.62G/4.98G [01:25<02:57, 18.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.63G/4.98G [01:25<01:53, 29.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.64G/4.98G [01:26<02:41, 20.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.64G/4.98G [01:26<02:13, 25.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.65G/4.98G [01:26<02:05, 26.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.65G/4.98G [01:26<03:03, 18.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.66G/4.98G [01:26<02:21, 23.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.66G/4.98G [01:27<02:04, 26.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.67G/4.98G [01:27<02:37, 21.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  34%|███▎      | 1.68G/4.98G [01:27<02:03, 26.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.68G/4.98G [01:27<01:51, 29.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.69G/4.98G [01:28<02:01, 27.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.70G/4.98G [01:28<02:57, 18.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.71G/4.98G [01:29<01:48, 30.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.71G/4.98G [01:29<02:37, 20.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  35%|███▍      | 1.73G/4.98G [01:29<01:50, 29.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  35%|███▍      | 1.73G/4.98G [01:30<02:26, 22.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  35%|███▌      | 1.74G/4.98G [01:30<01:47, 30.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  35%|███▌      | 1.75G/4.98G [01:30<02:34, 21.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  35%|███▌      | 1.75G/4.98G [01:30<02:32, 21.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  35%|███▌      | 1.76G/4.98G [01:31<01:47, 29.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  35%|███▌      | 1.76G/4.98G [01:31<02:26, 21.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  35%|███▌      | 1.77G/4.98G [01:31<02:21, 22.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.78G/4.98G [01:31<01:44, 30.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.78G/4.98G [01:32<02:13, 23.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.78G/4.98G [01:32<02:02, 26.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.79G/4.98G [01:32<01:48, 29.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.79G/4.98G [01:32<02:48, 18.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.80G/4.98G [01:32<02:07, 25.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.80G/4.98G [01:32<01:52, 28.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  36%|███▋      | 1.81G/4.98G [01:33<02:36, 20.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  36%|███▋      | 1.81G/4.98G [01:33<02:03, 25.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.82G/4.98G [01:33<01:51, 28.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.82G/4.98G [01:34<02:53, 18.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.84G/4.98G [01:34<01:51, 28.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.85G/4.98G [01:34<01:55, 27.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.85G/4.98G [01:35<01:49, 28.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.87G/4.98G [01:36<02:55, 17.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.88G/4.98G [01:36<02:12, 23.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.88G/4.98G [01:36<01:58, 26.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.89G/4.98G [01:36<01:47, 28.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.89G/4.98G [01:36<02:47, 18.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.89G/4.98G [01:37<02:31, 20.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.90G/4.98G [01:37<01:49, 28.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.91G/4.98G [01:37<02:39, 19.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.91G/4.98G [01:37<02:28, 20.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  39%|███▊      | 1.92G/4.98G [01:37<01:44, 29.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.94G/4.98G [01:38<01:40, 30.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.95G/4.98G [01:39<01:55, 26.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.95G/4.98G [01:39<01:39, 30.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  40%|███▉      | 1.97G/4.98G [01:39<01:33, 32.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  40%|███▉      | 1.98G/4.98G [01:40<01:46, 28.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  40%|███▉      | 1.99G/4.98G [01:40<02:03, 24.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  40%|████      | 2.00G/4.98G [01:41<01:44, 28.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  40%|████      | 2.01G/4.98G [01:41<01:44, 28.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  40%|████      | 2.01G/4.98G [01:41<01:37, 30.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.02G/4.98G [01:42<01:57, 25.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.03G/4.98G [01:42<01:41, 29.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.03G/4.98G [01:42<02:17, 21.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.04G/4.98G [01:42<01:43, 28.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.04G/4.98G [01:42<01:34, 31.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.05G/4.98G [01:43<02:19, 21.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  41%|████▏     | 2.05G/4.98G [01:43<01:52, 25.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  41%|████▏     | 2.06G/4.98G [01:43<01:38, 29.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  41%|████▏     | 2.06G/4.98G [01:43<02:20, 20.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.07G/4.98G [01:44<01:54, 25.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.07G/4.98G [01:44<01:40, 28.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.08G/4.98G [01:44<02:22, 20.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.09G/4.98G [01:44<01:57, 24.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.09G/4.98G [01:44<01:40, 28.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.10G/4.98G [01:45<02:17, 21.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.11G/4.98G [01:45<01:36, 29.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.12G/4.98G [01:46<02:06, 22.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.12G/4.98G [01:46<01:50, 25.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.13G/4.98G [01:46<02:30, 18.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.13G/4.98G [01:46<01:58, 24.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.14G/4.98G [01:46<01:41, 28.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.14G/4.98G [01:47<02:21, 20.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.15G/4.98G [01:47<01:54, 24.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.16G/4.98G [01:47<01:37, 29.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.16G/4.98G [01:47<02:14, 20.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  44%|████▎     | 2.17G/4.98G [01:48<01:50, 25.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  44%|████▎     | 2.17G/4.98G [01:48<01:37, 28.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  44%|████▎     | 2.18G/4.98G [01:48<02:15, 20.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.19G/4.98G [01:48<01:37, 28.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.19G/4.98G [01:49<02:11, 21.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.20G/4.98G [01:49<01:31, 30.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.21G/4.98G [01:50<01:41, 27.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  45%|████▍     | 2.22G/4.98G [01:50<01:28, 31.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  45%|████▍     | 2.23G/4.98G [01:50<01:33, 29.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  45%|████▍     | 2.24G/4.98G [01:50<01:24, 32.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  45%|████▌     | 2.25G/4.98G [01:51<01:44, 26.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  45%|████▌     | 2.25G/4.98G [01:51<01:29, 30.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  45%|████▌     | 2.26G/4.98G [01:51<02:06, 21.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  45%|████▌     | 2.26G/4.98G [01:51<01:41, 26.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.27G/4.98G [01:51<01:31, 29.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.27G/4.98G [01:52<02:06, 21.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.28G/4.98G [01:52<01:41, 26.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.28G/4.98G [01:52<01:30, 29.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.29G/4.98G [01:52<02:09, 20.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.29G/4.98G [01:53<01:41, 26.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.30G/4.98G [01:53<01:36, 27.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|████▋     | 2.30G/4.98G [01:53<02:17, 19.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|████▋     | 2.31G/4.98G [01:53<01:53, 23.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|████▋     | 2.31G/4.98G [01:53<01:45, 25.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.32G/4.98G [01:54<01:37, 27.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.32G/4.98G [01:54<02:23, 18.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.33G/4.98G [01:54<02:00, 21.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.33G/4.98G [01:54<01:37, 27.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.34G/4.98G [01:55<02:23, 18.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.35G/4.98G [01:55<01:31, 28.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.36G/4.98G [01:56<01:44, 24.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.37G/4.98G [01:56<01:33, 28.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.37G/4.98G [01:56<02:00, 21.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.38G/4.98G [01:56<01:40, 25.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.39G/4.98G [01:57<01:48, 23.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.39G/4.98G [01:57<01:36, 26.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.40G/4.98G [01:57<01:27, 29.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.41G/4.98G [01:58<01:36, 26.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  49%|████▊     | 2.41G/4.98G [01:58<01:33, 27.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  49%|████▊     | 2.42G/4.98G [01:58<02:08, 19.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.43G/4.98G [01:58<01:54, 22.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.45G/4.98G [02:00<02:40, 15.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.45G/4.98G [02:00<02:01, 20.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.46G/4.98G [02:00<01:45, 23.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.46G/4.98G [02:00<01:38, 25.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  50%|████▉     | 2.46G/4.98G [02:00<02:32, 16.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  50%|████▉     | 2.47G/4.98G [02:01<01:55, 21.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  50%|████▉     | 2.47G/4.98G [02:01<01:51, 22.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  50%|████▉     | 2.48G/4.98G [02:01<01:36, 26.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  50%|████▉     | 2.48G/4.98G [02:01<02:22, 17.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  50%|█████     | 2.49G/4.98G [02:01<01:55, 21.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  50%|█████     | 2.49G/4.98G [02:02<01:37, 25.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  50%|█████     | 2.50G/4.98G [02:02<02:05, 19.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  50%|█████     | 2.51G/4.98G [02:02<01:48, 22.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  50%|█████     | 2.51G/4.98G [02:02<01:34, 26.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.51G/4.98G [02:03<02:18, 17.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.52G/4.98G [02:03<02:03, 20.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.52G/4.98G [02:03<01:46, 23.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.53G/4.98G [02:03<01:34, 25.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.53G/4.98G [02:03<02:40, 15.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.54G/4.98G [02:04<01:43, 23.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.54G/4.98G [02:04<01:28, 27.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.55G/4.98G [02:04<01:54, 21.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  51%|█████▏    | 2.55G/4.98G [02:04<01:40, 24.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  51%|█████▏    | 2.56G/4.98G [02:05<01:28, 27.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  51%|█████▏    | 2.56G/4.98G [02:05<02:55, 13.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.57G/4.98G [02:05<01:56, 20.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.58G/4.98G [02:06<01:43, 23.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.58G/4.98G [02:06<02:07, 18.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.59G/4.98G [02:06<01:47, 22.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.59G/4.98G [02:06<01:33, 25.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.59G/4.98G [02:07<02:15, 17.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.60G/4.98G [02:07<01:43, 23.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.60G/4.98G [02:07<01:29, 26.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.61G/4.98G [02:07<02:07, 18.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.61G/4.98G [02:07<01:42, 23.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.62G/4.98G [02:08<01:25, 27.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.63G/4.98G [02:08<01:59, 19.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.63G/4.98G [02:08<01:41, 23.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.64G/4.98G [02:08<01:21, 28.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.65G/4.98G [02:09<01:36, 24.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.65G/4.98G [02:09<01:26, 26.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  54%|█████▎    | 2.67G/4.98G [02:10<01:30, 25.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  54%|█████▎    | 2.67G/4.98G [02:10<01:22, 27.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  54%|█████▎    | 2.67G/4.98G [02:10<02:04, 18.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.68G/4.98G [02:10<01:46, 21.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.68G/4.98G [02:10<01:30, 25.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.69G/4.98G [02:11<02:08, 17.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.69G/4.98G [02:11<01:42, 22.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.70G/4.98G [02:11<01:24, 26.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.71G/4.98G [02:12<02:05, 18.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  55%|█████▍    | 2.72G/4.98G [02:12<01:22, 27.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  55%|█████▍    | 2.73G/4.98G [02:13<01:34, 23.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  55%|█████▍    | 2.73G/4.98G [02:13<01:24, 26.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  55%|█████▌    | 2.74G/4.98G [02:13<01:49, 20.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  55%|█████▌    | 2.75G/4.98G [02:13<01:35, 23.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  55%|█████▌    | 2.75G/4.98G [02:13<01:24, 26.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  55%|█████▌    | 2.75G/4.98G [02:14<02:13, 16.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  55%|█████▌    | 2.76G/4.98G [02:14<01:48, 20.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  55%|█████▌    | 2.76G/4.98G [02:14<01:36, 22.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.77G/4.98G [02:14<01:25, 25.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.77G/4.98G [02:14<02:06, 17.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.77G/4.98G [02:15<01:42, 21.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.78G/4.98G [02:15<01:26, 25.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.79G/4.98G [02:15<01:30, 24.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.80G/4.98G [02:16<01:22, 26.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  56%|█████▋    | 2.81G/4.98G [02:16<01:30, 24.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.81G/4.98G [02:16<01:20, 26.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.82G/4.98G [02:17<01:48, 19.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.83G/4.98G [02:17<01:39, 21.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.83G/4.98G [02:17<01:34, 22.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.83G/4.98G [02:18<02:30, 14.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.84G/4.98G [02:18<01:52, 18.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.84G/4.98G [02:18<01:41, 21.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.85G/4.98G [02:18<01:34, 22.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.85G/4.98G [02:18<02:20, 15.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.85G/4.98G [02:19<01:42, 20.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.86G/4.98G [02:19<01:32, 23.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.89G/4.98G [02:20<01:17, 26.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.90G/4.98G [02:21<02:01, 17.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.90G/4.98G [02:21<01:37, 21.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.91G/4.98G [02:21<01:27, 23.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.91G/4.98G [02:21<01:18, 26.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  59%|█████▊    | 2.91G/4.98G [02:21<01:52, 18.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  59%|█████▊    | 2.92G/4.98G [02:21<01:38, 20.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  59%|█████▊    | 2.92G/4.98G [02:22<01:27, 23.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.93G/4.98G [02:22<01:19, 25.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.93G/4.98G [02:22<02:05, 16.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.93G/4.98G [02:22<01:38, 20.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.94G/4.98G [02:22<01:10, 28.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.95G/4.98G [02:23<01:39, 20.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.96G/4.98G [02:23<01:17, 26.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  60%|█████▉    | 2.98G/4.98G [02:24<01:10, 28.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  60%|█████▉    | 2.98G/4.98G [02:24<01:46, 18.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  60%|██████    | 2.99G/4.98G [02:25<01:26, 22.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  60%|██████    | 3.00G/4.98G [02:25<01:29, 22.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  60%|██████    | 3.00G/4.98G [02:25<01:14, 26.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.01G/4.98G [02:26<01:27, 22.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.02G/4.98G [02:26<01:17, 25.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.02G/4.98G [02:26<01:07, 28.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.03G/4.98G [02:27<01:24, 23.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.03G/4.98G [02:27<01:16, 25.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.04G/4.98G [02:27<01:08, 28.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.04G/4.98G [02:27<01:45, 18.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 3.05G/4.98G [02:27<01:28, 21.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  61%|██████▏   | 3.05G/4.98G [02:27<01:17, 25.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  61%|██████▏   | 3.06G/4.98G [02:28<01:28, 21.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.06G/4.98G [02:28<01:21, 23.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.07G/4.98G [02:28<01:13, 25.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.07G/4.98G [02:28<01:35, 19.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.08G/4.98G [02:29<01:30, 21.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.08G/4.98G [02:29<01:15, 25.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.09G/4.98G [02:29<01:09, 27.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.09G/4.98G [02:29<01:42, 18.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.09G/4.98G [02:29<01:27, 21.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.10G/4.98G [02:29<01:11, 26.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.10G/4.98G [02:30<01:56, 16.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.11G/4.98G [02:30<01:26, 21.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.12G/4.98G [02:30<01:07, 27.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.12G/4.98G [02:31<01:39, 18.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.13G/4.98G [02:31<01:08, 26.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.14G/4.98G [02:31<01:39, 18.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.15G/4.98G [02:32<01:04, 28.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.15G/4.98G [02:32<01:29, 20.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  64%|██████▎   | 3.16G/4.98G [02:32<01:02, 29.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  64%|██████▎   | 3.17G/4.98G [02:33<01:39, 18.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.18G/4.98G [02:33<01:09, 26.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.18G/4.98G [02:33<01:02, 28.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.20G/4.98G [02:34<01:01, 28.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.21G/4.98G [02:34<01:15, 23.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  65%|██████▍   | 3.21G/4.98G [02:34<01:03, 27.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  65%|██████▍   | 3.22G/4.98G [02:35<01:32, 19.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  65%|██████▍   | 3.23G/4.98G [02:35<01:17, 22.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  65%|██████▍   | 3.23G/4.98G [02:35<01:06, 26.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  65%|██████▍   | 3.23G/4.98G [02:35<01:31, 19.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  65%|██████▌   | 3.24G/4.98G [02:36<01:11, 24.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  65%|██████▌   | 3.25G/4.98G [02:36<01:01, 28.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  65%|██████▌   | 3.25G/4.98G [02:36<01:29, 19.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  65%|██████▌   | 3.25G/4.98G [02:36<01:23, 20.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  65%|██████▌   | 3.26G/4.98G [02:36<01:10, 24.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.26G/4.98G [02:37<01:02, 27.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.27G/4.98G [02:37<01:34, 18.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.27G/4.98G [02:37<01:21, 21.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.28G/4.98G [02:37<01:05, 26.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.28G/4.98G [02:38<01:36, 17.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.29G/4.98G [02:38<01:14, 22.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.29G/4.98G [02:38<01:08, 24.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  66%|██████▋   | 3.30G/4.98G [02:39<01:24, 19.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  66%|██████▋   | 3.31G/4.98G [02:39<01:16, 21.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.31G/4.98G [02:39<01:10, 23.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.31G/4.98G [02:39<01:46, 15.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.32G/4.98G [02:39<01:27, 18.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.32G/4.98G [02:39<01:18, 21.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.32G/4.98G [02:40<01:12, 22.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.33G/4.98G [02:40<01:49, 15.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.34G/4.98G [02:40<01:06, 24.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.35G/4.98G [02:41<01:37, 16.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.36G/4.98G [02:41<01:05, 24.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.37G/4.98G [02:42<01:08, 23.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.37G/4.98G [02:42<01:02, 25.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.38G/4.98G [02:42<01:17, 20.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.39G/4.98G [02:43<01:06, 24.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.39G/4.98G [02:43<01:02, 25.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.39G/4.98G [02:43<01:35, 16.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.40G/4.98G [02:43<01:29, 17.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.40G/4.98G [02:43<01:19, 19.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.40G/4.98G [02:44<01:13, 21.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.41G/4.98G [02:44<01:53, 13.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  69%|██████▊   | 3.41G/4.98G [02:44<01:30, 17.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.42G/4.98G [02:45<01:09, 22.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.43G/4.98G [02:45<01:50, 14.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.43G/4.98G [02:45<01:18, 19.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.44G/4.98G [02:45<01:13, 20.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.44G/4.98G [02:45<01:08, 22.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.44G/4.98G [02:46<01:38, 15.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.45G/4.98G [02:46<01:29, 17.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.45G/4.98G [02:46<01:16, 20.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.45G/4.98G [02:46<01:11, 21.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.46G/4.98G [02:46<01:06, 23.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.46G/4.98G [02:47<01:35, 15.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  70%|██████▉   | 3.46G/4.98G [02:47<01:28, 17.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  70%|██████▉   | 3.47G/4.98G [02:47<01:07, 22.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  70%|██████▉   | 3.47G/4.98G [02:47<01:47, 14.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  70%|██████▉   | 3.48G/4.98G [02:48<01:10, 21.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  70%|███████   | 3.49G/4.98G [02:48<01:03, 23.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  70%|███████   | 3.49G/4.98G [02:48<01:18, 18.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  70%|███████   | 3.50G/4.98G [02:49<01:08, 21.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  70%|███████   | 3.50G/4.98G [02:49<01:05, 22.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  70%|███████   | 3.50G/4.98G [02:49<01:41, 14.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.51G/4.98G [02:49<01:16, 19.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.51G/4.98G [02:49<01:08, 21.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.52G/4.98G [02:50<01:02, 23.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.52G/4.98G [02:50<01:35, 15.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.54G/4.98G [02:50<00:58, 24.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.54G/4.98G [02:51<01:11, 20.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  71%|███████▏  | 3.55G/4.98G [02:51<01:04, 22.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  71%|███████▏  | 3.56G/4.98G [02:52<01:13, 19.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.56G/4.98G [02:52<01:04, 21.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.57G/4.98G [02:52<01:00, 23.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.57G/4.98G [02:52<01:31, 15.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.57G/4.98G [02:53<01:11, 19.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.58G/4.98G [02:53<00:56, 24.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.59G/4.98G [02:53<01:23, 16.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.60G/4.98G [02:54<00:58, 23.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.60G/4.98G [02:54<00:55, 24.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.60G/4.98G [02:54<01:31, 15.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.61G/4.98G [02:54<01:22, 16.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.61G/4.98G [02:54<01:11, 19.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.62G/4.98G [02:55<00:57, 23.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.62G/4.98G [02:55<01:26, 15.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.62G/4.98G [02:55<01:17, 17.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.63G/4.98G [02:55<00:58, 23.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.63G/4.98G [02:56<01:24, 16.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.65G/4.98G [02:56<00:54, 24.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.66G/4.98G [02:57<00:58, 22.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  74%|███████▎  | 3.66G/4.98G [02:57<00:53, 24.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  74%|███████▎  | 3.66G/4.98G [02:57<01:23, 15.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  74%|███████▎  | 3.67G/4.98G [02:57<01:06, 19.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.67G/4.98G [02:57<01:01, 21.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.68G/4.98G [02:58<00:52, 24.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.68G/4.98G [02:58<01:14, 17.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.69G/4.98G [02:58<00:54, 23.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  75%|███████▍  | 3.71G/4.98G [02:59<00:49, 25.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  75%|███████▍  | 3.72G/4.98G [03:00<01:02, 20.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  75%|███████▍  | 3.72G/4.98G [03:00<00:56, 22.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  75%|███████▍  | 3.72G/4.98G [03:00<00:52, 24.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  75%|███████▍  | 3.73G/4.98G [03:00<01:21, 15.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  75%|███████▌  | 3.73G/4.98G [03:00<00:58, 21.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  75%|███████▌  | 3.74G/4.98G [03:01<00:54, 22.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  75%|███████▌  | 3.74G/4.98G [03:01<00:51, 24.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  75%|███████▌  | 3.74G/4.98G [03:01<00:48, 25.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  75%|███████▌  | 3.75G/4.98G [03:01<01:16, 16.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.76G/4.98G [03:01<00:49, 24.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.77G/4.98G [03:02<00:51, 23.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.77G/4.98G [03:02<00:45, 26.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.79G/4.98G [03:03<00:47, 24.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.79G/4.98G [03:03<00:44, 26.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.79G/4.98G [03:03<01:09, 16.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  76%|███████▋  | 3.80G/4.98G [03:04<00:52, 22.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  76%|███████▋  | 3.81G/4.98G [03:04<00:48, 24.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.81G/4.98G [03:04<01:15, 15.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.81G/4.98G [03:04<01:01, 18.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.82G/4.98G [03:04<00:56, 20.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.82G/4.98G [03:05<00:53, 21.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.82G/4.98G [03:05<01:20, 14.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.83G/4.98G [03:05<01:00, 18.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.84G/4.98G [03:05<00:50, 22.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.84G/4.98G [03:06<01:13, 15.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.85G/4.98G [03:06<00:54, 20.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.86G/4.98G [03:07<01:11, 15.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.86G/4.98G [03:07<00:51, 21.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.87G/4.98G [03:07<00:47, 23.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.87G/4.98G [03:07<00:45, 24.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.89G/4.98G [03:08<00:44, 24.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.90G/4.98G [03:08<00:44, 24.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.90G/4.98G [03:09<01:46, 10.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  79%|███████▊  | 3.91G/4.98G [03:10<01:07, 15.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  79%|███████▊  | 3.92G/4.98G [03:10<00:50, 21.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  79%|███████▉  | 3.92G/4.98G [03:10<01:09, 15.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  79%|███████▉  | 3.93G/4.98G [03:10<00:43, 24.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  79%|███████▉  | 3.94G/4.98G [03:11<01:04, 16.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  79%|███████▉  | 3.95G/4.98G [03:11<00:38, 26.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  79%|███████▉  | 3.96G/4.98G [03:12<00:52, 19.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  80%|███████▉  | 3.97G/4.98G [03:12<00:36, 27.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  80%|███████▉  | 3.98G/4.98G [03:13<00:45, 21.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  80%|████████  | 3.98G/4.98G [03:13<00:36, 27.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  80%|████████  | 3.99G/4.98G [03:13<00:46, 21.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  80%|████████  | 4.00G/4.98G [03:13<00:40, 24.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  80%|████████  | 4.00G/4.98G [03:14<00:37, 26.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  80%|████████  | 4.01G/4.98G [03:14<00:51, 18.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 4.01G/4.98G [03:14<00:41, 23.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 4.02G/4.98G [03:15<00:44, 21.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 4.03G/4.98G [03:15<00:39, 23.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 4.03G/4.98G [03:15<00:36, 26.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 4.04G/4.98G [03:15<00:42, 21.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 4.04G/4.98G [03:16<00:38, 24.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  81%|████████▏ | 4.05G/4.98G [03:16<00:34, 26.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  81%|████████▏ | 4.05G/4.98G [03:16<00:42, 21.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.06G/4.98G [03:16<00:37, 24.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.06G/4.98G [03:16<00:34, 26.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.07G/4.98G [03:17<00:39, 23.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.07G/4.98G [03:17<00:35, 25.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.08G/4.98G [03:17<00:33, 26.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.09G/4.98G [03:18<00:40, 21.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.09G/4.98G [03:18<00:37, 23.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.09G/4.98G [03:18<00:34, 25.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.10G/4.98G [03:18<00:56, 15.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.10G/4.98G [03:18<00:49, 17.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.10G/4.98G [03:18<00:44, 19.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.11G/4.98G [03:19<00:41, 21.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.11G/4.98G [03:19<00:38, 22.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.11G/4.98G [03:19<01:00, 14.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.12G/4.98G [03:19<00:48, 17.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.12G/4.98G [03:19<00:43, 19.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.13G/4.98G [03:20<00:37, 22.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.13G/4.98G [03:20<00:56, 15.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.13G/4.98G [03:20<00:50, 16.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.14G/4.98G [03:21<00:36, 22.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.15G/4.98G [03:21<00:51, 16.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.15G/4.98G [03:21<00:43, 19.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  84%|████████▎ | 4.16G/4.98G [03:21<00:33, 24.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  84%|████████▎ | 4.16G/4.98G [03:22<00:51, 15.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.17G/4.98G [03:22<00:35, 22.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.18G/4.98G [03:23<01:01, 12.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.19G/4.98G [03:23<00:44, 17.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.20G/4.98G [03:24<00:45, 17.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.20G/4.98G [03:24<00:38, 20.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.20G/4.98G [03:24<00:36, 21.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  85%|████████▍ | 4.21G/4.98G [03:25<00:55, 13.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  85%|████████▍ | 4.21G/4.98G [03:25<00:41, 18.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  85%|████████▍ | 4.22G/4.98G [03:25<00:35, 21.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  85%|████████▍ | 4.22G/4.98G [03:25<00:31, 23.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  85%|████████▌ | 4.23G/4.98G [03:26<00:46, 15.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  85%|████████▌ | 4.23G/4.98G [03:26<00:40, 18.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  85%|████████▌ | 4.24G/4.98G [03:26<00:35, 20.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  85%|████████▌ | 4.24G/4.98G [03:26<00:49, 14.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  85%|████████▌ | 4.25G/4.98G [03:27<00:38, 19.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  85%|████████▌ | 4.25G/4.98G [03:27<00:34, 21.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  85%|████████▌ | 4.25G/4.98G [03:27<00:29, 24.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.26G/4.98G [03:27<00:47, 15.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.26G/4.98G [03:27<00:38, 18.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.27G/4.98G [03:28<00:30, 22.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.27G/4.98G [03:28<00:46, 15.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.29G/4.98G [03:28<00:29, 23.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.29G/4.98G [03:29<00:47, 14.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  86%|████████▋ | 4.30G/4.98G [03:29<00:28, 23.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.31G/4.98G [03:30<00:35, 19.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.31G/4.98G [03:30<00:30, 21.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.32G/4.98G [03:30<00:28, 23.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.33G/4.98G [03:31<00:30, 21.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.33G/4.98G [03:31<00:28, 23.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.33G/4.98G [03:31<00:26, 24.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.34G/4.98G [03:31<00:42, 15.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.34G/4.98G [03:31<00:32, 19.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.35G/4.98G [03:32<00:28, 21.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.35G/4.98G [03:32<00:26, 23.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.35G/4.98G [03:32<00:37, 16.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.36G/4.98G [03:32<00:31, 19.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.36G/4.98G [03:32<00:26, 22.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.37G/4.98G [03:32<00:25, 24.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.37G/4.98G [03:33<00:38, 15.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.37G/4.98G [03:33<00:28, 21.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.38G/4.98G [03:33<00:24, 24.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.38G/4.98G [03:34<00:38, 15.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.39G/4.98G [03:34<00:29, 20.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.40G/4.98G [03:34<00:22, 25.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.40G/4.98G [03:34<00:32, 17.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  89%|████████▊ | 4.41G/4.98G [03:35<00:24, 23.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  89%|████████▊ | 4.42G/4.98G [03:35<00:34, 16.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  89%|████████▉ | 4.43G/4.98G [03:36<00:20, 26.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  89%|████████▉ | 4.45G/4.98G [03:36<00:19, 26.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  89%|████████▉ | 4.45G/4.98G [03:37<00:32, 16.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  90%|████████▉ | 4.46G/4.98G [03:37<00:23, 22.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  90%|████████▉ | 4.46G/4.98G [03:37<00:20, 24.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  90%|████████▉ | 4.47G/4.98G [03:38<00:21, 23.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  90%|████████▉ | 4.48G/4.98G [03:38<00:19, 26.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  90%|█████████ | 4.49G/4.98G [03:38<00:23, 20.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  90%|█████████ | 4.49G/4.98G [03:38<00:20, 23.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  90%|█████████ | 4.49G/4.98G [03:39<00:18, 25.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  90%|█████████ | 4.50G/4.98G [03:39<00:22, 20.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  91%|█████████ | 4.51G/4.98G [03:39<00:20, 23.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  91%|█████████ | 4.51G/4.98G [03:39<00:17, 26.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  91%|█████████ | 4.51G/4.98G [03:40<00:43, 10.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  91%|█████████ | 4.53G/4.98G [03:40<00:22, 20.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  91%|█████████ | 4.53G/4.98G [03:41<00:22, 19.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  91%|█████████ | 4.54G/4.98G [03:41<00:18, 24.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  91%|█████████▏| 4.55G/4.98G [03:42<00:19, 21.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.56G/4.98G [03:42<00:16, 25.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.57G/4.98G [03:43<00:13, 30.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.58G/4.98G [03:43<00:17, 23.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.58G/4.98G [03:43<00:14, 26.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.59G/4.98G [03:43<00:13, 29.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.59G/4.98G [03:43<00:19, 19.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.60G/4.98G [03:44<00:15, 25.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.60G/4.98G [03:44<00:13, 28.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.61G/4.98G [03:44<00:18, 19.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.61G/4.98G [03:44<00:14, 25.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.62G/4.98G [03:44<00:12, 28.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.62G/4.98G [03:45<00:16, 20.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.63G/4.98G [03:45<00:13, 25.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.64G/4.98G [03:45<00:10, 32.8MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.64G/4.98G [03:45<00:13, 24.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.65G/4.98G [03:46<00:12, 25.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.65G/4.98G [03:46<00:11, 27.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  94%|█████████▎| 4.66G/4.98G [03:46<00:16, 19.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  94%|█████████▎| 4.66G/4.98G [03:46<00:12, 25.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.67G/4.98G [03:47<00:14, 20.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.68G/4.98G [03:47<00:11, 26.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.68G/4.98G [03:47<00:09, 31.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.69G/4.98G [03:47<00:13, 22.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.69G/4.98G [03:47<00:10, 27.0MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.70G/4.98G [03:47<00:08, 32.6MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  95%|█████████▍| 4.71G/4.98G [03:48<00:09, 27.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  95%|█████████▍| 4.72G/4.98G [03:48<00:07, 32.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  95%|█████████▍| 4.73G/4.98G [03:49<00:08, 27.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  95%|█████████▌| 4.73G/4.98G [03:49<00:07, 33.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  95%|█████████▌| 4.74G/4.98G [03:49<00:08, 26.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  95%|█████████▌| 4.75G/4.98G [03:49<00:07, 31.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  96%|█████████▌| 4.76G/4.98G [03:50<00:08, 26.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  96%|█████████▌| 4.77G/4.98G [03:50<00:06, 32.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  96%|█████████▌| 4.78G/4.98G [03:50<00:07, 26.4MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  96%|█████████▌| 4.78G/4.98G [03:51<00:06, 32.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  96%|█████████▋| 4.79G/4.98G [03:51<00:05, 30.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.81G/4.98G [03:52<00:04, 35.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.83G/4.98G [03:52<00:03, 39.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.84G/4.98G [03:52<00:05, 27.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.84G/4.98G [03:53<00:04, 32.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  97%|█████████▋| 4.85G/4.98G [03:53<00:05, 25.3MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  98%|█████████▊| 4.86G/4.98G [03:53<00:03, 32.7MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  98%|█████████▊| 4.86G/4.98G [03:53<00:03, 37.5MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  98%|█████████▊| 4.87G/4.98G [03:53<00:03, 27.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  98%|█████████▊| 4.88G/4.98G [03:54<00:02, 37.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  99%|█████████▊| 4.91G/4.98G [03:56<00:03, 19.9MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  99%|█████████▉| 4.92G/4.98G [03:57<00:02, 26.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  99%|█████████▉| 4.93G/4.98G [03:57<00:01, 25.1MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors:  99%|█████████▉| 4.94G/4.98G [03:57<00:01, 31.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors: 100%|█████████▉| 4.96G/4.98G [03:58<00:00, 38.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors: 100%|█████████▉| 4.97G/4.98G [03:58<00:00, 32.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors: 100%|█████████▉| 4.98G/4.98G [03:59<00:00, 24.2MB/s]\n",
      "\n",
      "model-00001-of-00004.safetensors: 100%|██████████| 4.98G/4.98G [03:59<00:00, 20.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors: 100%|██████████| 4.92G/4.92G [04:04<00:00, 20.1MB/s]\n",
      "model-00002-of-00004.safetensors: 100%|██████████| 5.00G/5.00G [04:17<00:00, 19.4MB/s]\n",
      "\n",
      "Upload 4 LFS files: 100%|██████████| 4/4 [04:17<00:00, 64.39s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Saved merged model to https://huggingface.co/None/Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v4-30\n"
     ]
    }
   ],
   "source": [
    "# Hub 에 업로드\n",
    "model.push_to_hub_merged(\n",
    "    huggingface_repo,\n",
    "    tokenizer,\n",
    "    save_method=save_method,\n",
    "    token=huggingface_token,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model reload and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.43.3.\n",
      "   \\\\   /|    GPU: NVIDIA RTX A5000. Max memory: 23.677 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.1.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.22.post7+cu118. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 4096  # 최대 시퀀스 길이를 설정합니다. 내부적으로 RoPE 스케일링을 자동으로 지원합니다!\n",
    "# 자동 감지를 위해 None을 사용합니다. Tesla T4, V100은 Float16, Ampere+는 Bfloat16을 사용하세요.\n",
    "dtype = None\n",
    "# 메모리 사용량을 줄이기 위해 4bit 양자화를 사용합니다. False일 수도 있습니다.\n",
    "load_in_4bit = True\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    # model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n",
    "    model_name=\"/home/jaesung/jaesung/pulmuone/text-generation-webui/models/Llama-3-Open-Ko-8B-Instruct-PM1-completion-v2-60-gguf\",\n",
    "    max_seq_length=max_seq_length,  # 최대 시퀀스 길이를 설정합니다.\n",
    "    dtype=dtype,  # 데이터 타입을 설정합니다.\n",
    "    load_in_4bit=load_in_4bit,  # 4bit 양자화 로드 여부를 설정합니다.\n",
    "    # token = \"hf_...\", # 게이트된 모델을 사용하는 경우 토큰을 사용하세요. 예: meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# EOS_TOKEN은 문장의 끝을 나타내는 토큰입니다. 이 토큰을 추가해야 합니다.\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "# AlpacaPrompt를 사용하여 지시사항을 포맷팅하는 함수입니다.\n",
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "\n",
    "# 주어진 예시들을 포맷팅하는 함수입니다.\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"QUESTION\"]  # 지시사항을 가져옵니다.\n",
    "    outputs = examples[\"ANSWER\"]  # 출력값을 가져옵니다.\n",
    "    texts = []  # 포맷팅된 텍스트를 저장할 리스트입니다.\n",
    "    for instruction, output in zip(instructions, outputs):\n",
    "        # EOS_TOKEN을 추가해야 합니다. 그렇지 않으면 생성이 무한히 진행될 수 있습니다.\n",
    "        text = alpaca_prompt.format(instruction, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\n",
    "        \"text\": texts,  # 포맷팅된 텍스트를 반환합니다.\n",
    "    }\n",
    "\n",
    "# JSONL 파일 로드 함수\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data\n",
    "\n",
    "# JSONL 파일 경로\n",
    "file_path = '/home/jaesung/pulmuone/alpaca_rec_turning/completion/data/qa_pair_for_completion.jsonl'\n",
    "\n",
    "# JSONL 파일 로드\n",
    "data = load_jsonl(file_path)\n",
    "\n",
    "# pandas DataFrame으로 변환\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Dataset 객체로 변환\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# DatasetDict 객체로 결합\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4248/4248 [00:00<00:00, 55195.39 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋에 formatting_prompts_func 함수를 적용합니다. 배치 처리를 활성화합니다.\n",
    "dataset = dataset.map(\n",
    "    formatting_prompts_func,\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "import string\n",
    "\n",
    "class StopOnToken(StoppingCriteria):\n",
    "    def __init__(self, stop_token_id):\n",
    "        self.stop_token_id = stop_token_id  # 정지 토큰 ID를 초기화합니다.\n",
    "\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        return (\n",
    "            self.stop_token_id in input_ids[0]\n",
    "        )  # 입력된 ID 중 정지 토큰 ID가 있으면 정지합니다.\n",
    "\n",
    "class StopOnRepetitionPattern(StoppingCriteria):\n",
    "    def __init__(self, repetition_limit=3, tokenizer=None):\n",
    "        self.repetition_limit = repetition_limit\n",
    "        self.repetition_count = {}\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def extract_comma_segment(self, text):\n",
    "        # 콤마로 분리된 구 중 마지막 구를 추출합니다.\n",
    "        segments = text.split(',')\n",
    "        return segments[-1].strip().lower()\n",
    "    \n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        # 현재까지 생성된 전체 텍스트를 디코딩합니다.\n",
    "        generated_text = self.tokenizer.decode(input_ids[0], skip_special_tokens=True).strip()\n",
    "        comma_segment = self.extract_comma_segment(generated_text)\n",
    "        \n",
    "        if not comma_segment:\n",
    "            return False\n",
    "        \n",
    "        # 마지막 구간에서 단어를 분리\n",
    "        words = comma_segment.split()\n",
    "        \n",
    "        if len(words) == 1:  # 마지막 구간에 단어가 하나만 있다면\n",
    "            word = words[0]\n",
    "            if word in self.repetition_count:\n",
    "                self.repetition_count[word] += 1\n",
    "            else:\n",
    "                self.repetition_count[word] = 1\n",
    "            \n",
    "            # 만약 특정 단어가 repetition_limit 이상 반복되면 생성을 중단합니다.\n",
    "            if self.repetition_count[word] >= self.repetition_limit:\n",
    "                return True\n",
    "        else:\n",
    "            # 다른 구간이 생성되면 카운트 초기화\n",
    "            self.repetition_count = {}\n",
    "        \n",
    "        return False\n",
    "    \n",
    "# end_token을 설정\n",
    "stop_token = \"<|end_of_text|>\"  # end_token으로 사용할 토큰을 설정합니다.\n",
    "stop_token_id = tokenizer.encode(stop_token, add_special_tokens=False)[\n",
    "    0\n",
    "]  # end_token의 ID를 인코딩합니다.\n",
    "\n",
    "# Stopping criteria 설정\n",
    "stopping_criteria = StoppingCriteriaList(\n",
    "    [StopOnToken(stop_token_id),\n",
    "    StopOnRepetitionPattern(repetition_limit=5, tokenizer=tokenizer)\n",
    "    ] # 동일한 단어가 3번 반복되면 정지합니다.\n",
    ")  # 정지 조건을 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QUESTION': {'instruction': '아래에 냉동밥에 들어갈 몇 가지 재료가 나열되어 있어. 이 냉동밥에 추가로 사용될 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료가 뭐가 있을까?',\n",
       "  '제공된 재료': '닭가슴살, 치킨스톡P, 스크램블드에그P, 마늘풍미유',\n",
       "  '카테고리': '냉동밥'},\n",
       " 'ANSWER': '굴소스, 당근, 마늘, 맛내기양념, 쌀, 애호박, 양배추, 양조간장, 양파, 옥수수유, 정백당, 정제염, 참기름, 청피망, 콩발효맛내기진, 풍미베이스-SP, 핵산IG, 홍파프리카',\n",
       " '__index_level_0__': 109}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['test'][40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음에 나열된 대체육 재료들 외에, 추가로 어떤 재료를 넣으면 좋을지 추천해줄래? 이 때, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 추천해주길 부탁해.', '제공된 재료': '식물성간장소스', '카테고리': '대체육'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스-P, 아미노베이스-S, 아미노베이스-T, 아미노베이스-XP, 아미노베이스-XT, 아미노베이스-XTL, 아미노베이스-XTM, 아미노베이스-XTS, 아미노베이스-XTT, 아미노베이스-XTU, 아미노베이스-XTV, 아미노베이스-XTW, "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 18\u001b[0m\n\u001b[1;32m      5\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[1;32m      6\u001b[0m     [\n\u001b[1;32m      7\u001b[0m         alpaca_prompt\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m text_streamer \u001b[38;5;241m=\u001b[39m TextStreamer(tokenizer)\n\u001b[0;32m---> 18\u001b[0m _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[1;32m     20\u001b[0m     streamer\u001b[38;5;241m=\u001b[39mtext_streamer,\n\u001b[1;32m     21\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4096\u001b[39m,  \u001b[38;5;66;03m# 최대 생성 토큰 수를 설정합니다.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     stopping_criteria\u001b[38;5;241m=\u001b[39mstopping_criteria  \u001b[38;5;66;03m# 생성을 멈출 기준을 설정합니다.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/alpaca/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/alpaca/lib/python3.12/site-packages/unsloth/models/llama.py:1215\u001b[0m, in \u001b[0;36m_wrap_fast_inference.<locals>._fast_generate\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;66;03m# Set pad token\u001b[39;00m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;66;03m# old_pad_token_id = getattr(model.config, \"pad_token_id\", None)\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;66;03m# old_eos_token_id = getattr(model.config, \"eos_token_id\", None)\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;66;03m# model.config.pad_token_id = old_eos_token_id\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m \n\u001b[1;32m   1213\u001b[0m \u001b[38;5;66;03m# Autocasted\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(device_type \u001b[38;5;241m=\u001b[39m device_type, dtype \u001b[38;5;241m=\u001b[39m dtype):\n\u001b[0;32m-> 1215\u001b[0m     output \u001b[38;5;241m=\u001b[39m generate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;66;03m# Revert\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;66;03m# model.config.pad_token_id = old_pad_token_id\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \n\u001b[1;32m   1221\u001b[0m \u001b[38;5;66;03m# Unset a flag for generation!\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/alpaca/lib/python3.12/site-packages/peft/peft_model.py:1638\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1636\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1637\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1638\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1639\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1640\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/alpaca/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/alpaca/lib/python3.12/site-packages/transformers/generation/utils.py:2024\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2016\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2017\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2018\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2019\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2020\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2021\u001b[0m     )\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2024\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[1;32m   2025\u001b[0m         input_ids,\n\u001b[1;32m   2026\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[1;32m   2027\u001b[0m         logits_warper\u001b[38;5;241m=\u001b[39mprepared_logits_warper,\n\u001b[1;32m   2028\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[1;32m   2029\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[1;32m   2030\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[1;32m   2031\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[1;32m   2032\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2033\u001b[0m     )\n\u001b[1;32m   2035\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2036\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   2037\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2038\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2039\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   2040\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/alpaca/lib/python3.12/site-packages/transformers/generation/utils.py:2982\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2979\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   2981\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2982\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2985\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/alpaca/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/alpaca/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/alpaca/lib/python3.12/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/anaconda3/envs/alpaca/lib/python3.12/site-packages/unsloth/models/llama.py:879\u001b[0m, in \u001b[0;36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_CausalLM_fast_forward\u001b[39m(\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    864\u001b[0m     input_ids: torch\u001b[38;5;241m.\u001b[39mLongTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    876\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tuple, CausalLMOutputWithPast]:\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m fast_forward_inference(\n\u001b[1;32m    880\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    881\u001b[0m             input_ids,\n\u001b[1;32m    882\u001b[0m             past_key_values,\n\u001b[1;32m    883\u001b[0m             position_ids \u001b[38;5;241m=\u001b[39m position_ids,\n\u001b[1;32m    884\u001b[0m             attention_mask \u001b[38;5;241m=\u001b[39m attention_mask,\n\u001b[1;32m    885\u001b[0m         )\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    887\u001b[0m         causal_mask \u001b[38;5;241m=\u001b[39m xformers\u001b[38;5;241m.\u001b[39mattn_bias\u001b[38;5;241m.\u001b[39mLowerTriangularMask()\n",
      "File \u001b[0;32m~/anaconda3/envs/alpaca/lib/python3.12/site-packages/unsloth/models/llama.py:833\u001b[0m, in \u001b[0;36mLlamaModel_fast_forward_inference\u001b[0;34m(self, input_ids, past_key_values, position_ids, attention_mask)\u001b[0m\n\u001b[1;32m    831\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    832\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m fast_rms_layernorm_inference(decoder_layer\u001b[38;5;241m.\u001b[39minput_layernorm, hidden_states)\n\u001b[0;32m--> 833\u001b[0m hidden_states, present_key_value \u001b[38;5;241m=\u001b[39m LlamaAttention_fast_forward_inference(\n\u001b[1;32m    834\u001b[0m     decoder_layer\u001b[38;5;241m.\u001b[39mself_attn,\n\u001b[1;32m    835\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states,\n\u001b[1;32m    836\u001b[0m     past_key_value \u001b[38;5;241m=\u001b[39m past_key_values[idx],\n\u001b[1;32m    837\u001b[0m     position_ids \u001b[38;5;241m=\u001b[39m position_ids,\n\u001b[1;32m    838\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m attention_mask,\n\u001b[1;32m    839\u001b[0m     do_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(decoder_layer\u001b[38;5;241m.\u001b[39mself_attn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaged_attention\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    840\u001b[0m )\n\u001b[1;32m    841\u001b[0m hidden_states \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m residual\n\u001b[1;32m    843\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/anaconda3/envs/alpaca/lib/python3.12/site-packages/unsloth/models/llama.py:182\u001b[0m, in \u001b[0;36mLlamaAttention_fast_forward_inference\u001b[0;34m(self, hidden_states, past_key_value, position_ids, do_prefill, attention_mask)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    181\u001b[0m Qn \u001b[38;5;241m=\u001b[39m fast_linear_forward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj, Xn, out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemp_QA[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 182\u001b[0m Kn \u001b[38;5;241m=\u001b[39m fast_linear_forward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj, Xn, out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemp_KV[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    183\u001b[0m Vn \u001b[38;5;241m=\u001b[39m fast_linear_forward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj, Xn, out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemp_KV[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    184\u001b[0m Qn \u001b[38;5;241m=\u001b[39m Qn\u001b[38;5;241m.\u001b[39mview(bsz, \u001b[38;5;241m1\u001b[39m, n_heads,    head_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/alpaca/lib/python3.12/site-packages/unsloth/kernels/utils.py:252\u001b[0m, in \u001b[0;36mfast_linear_forward\u001b[0;34m(proj, X, temp_lora, out)\u001b[0m\n\u001b[1;32m    250\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mview(out_dim)\n\u001b[1;32m    251\u001b[0m     temp_lora \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmv(lora_A\u001b[38;5;241m.\u001b[39m_fast_lora, X\u001b[38;5;241m.\u001b[39mravel(), out \u001b[38;5;241m=\u001b[39m temp_lora)\n\u001b[0;32m--> 252\u001b[0m     out\u001b[38;5;241m.\u001b[39maddmv_(lora_B\u001b[38;5;241m.\u001b[39m_fast_lora, temp_lora, alpha \u001b[38;5;241m=\u001b[39m lora_S)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mview(bsz, out_dim)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "# FastLanguageModel을 이용하여 추론 속도를 2배 빠르게 설정합니다.\n",
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "    [\n",
    "        alpaca_prompt.format(\n",
    "            dataset_dict['test'][100]['QUESTION'],\n",
    "\n",
    "           # {'instruction': '이 두부를 만들 때 사용할 몇 가지 재료가 이미 정해졌어. 여기에 어울릴 만한 다른 재료를 제안해줄 수 있니?', '제공된 재료': '대두', '카테고리': '두부'}, # 지시사항\n",
    "            \"\",  # 출력 - 생성을 위해 이 부분을 비워둡니다!\n",
    "        )\n",
    "    ],\n",
    "    return_tensors=\"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(\n",
    "    **inputs,\n",
    "    streamer=text_streamer,\n",
    "    max_new_tokens=4096,  # 최대 생성 토큰 수를 설정합니다.\n",
    "    stopping_criteria=stopping_criteria  # 생성을 멈출 기준을 설정합니다.\n",
    ")\n",
    "\n",
    "# output_list = tokenizer.batch_decode(_, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QUESTION': {'instruction': '아래에 소스류에 들어갈 몇 가지 재료가 나열되어 있어. 이 소스류에 추가로 사용될 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료가 뭐가 있을까?',\n",
       "  '제공된 재료': '백설탕, 발효농축액, 재래된장, 바지락소스, 멀티롬파우더',\n",
       "  '카테고리': '소스류'},\n",
       " 'ANSWER': \"5'-리보뉴클레오티드나트륨, PA-1, 건표고버섯, 고춧가루(냉홍초), 냉동다이스양파, 냉동대파, 돼지고기, 마늘추출농축액-P, 막사보와이비페이스트, 멸치추출농축액, 사골엑기스, 새우젓분말, 쇠고기추출분말P, 슬라이스 조각두부 마파/탕수용, 아미노베이스-P, 야채엑기스분말MX1, 옥수수유, 정제수, 정제염, 찰옥수수전분, 참맛고추장, 청국장, 포크엑기스P\",\n",
       " '__index_level_0__': 1061}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['test'][70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['QUESTION', 'ANSWER', '__index_level_0__'],\n",
       "    num_rows: 850\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음은 수산물에 사용될 일부 재료야. 이 수산물에 들어갈 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료들을 추천해줄래?', '제공된 재료': '대두유, 정제염', '카테고리': None}\n",
      "\n",
      "### Response:\n",
      "고추씨기름, 대두단백, 대파, 마늘, 밀가루, 백설탕, 양배추, 양조간장, 정제수, 정제소금, 참기름, 참깨, 참치액, 참치액분말, 참\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음에 나열된 소스류 재료들 외에, 추가로 어떤 재료를 넣으면 좋을지 추천해줄래? 이 때, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 추천해주길 부탁해.', '제공된 재료': '얼큰탕베이스, 설탕, 양꼬치시즈닝, 칠리오일R, 산초고농축액-P', '카테고리': '소스류'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스-P, 아미노베이스-SP, 아미노베이스-SS, 아미노베이스-SS-P, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '이 면, 만두를 만들 때 사용할 몇 가지 재료가 이미 정해졌어. 여기에 어울릴 만한, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 제안해줄 수 있니?', '제공된 재료': '깻잎, 양파, 부추, 팩두부, 후추가루', '카테고리': '면, 만두'}\n",
      "\n",
      "### Response:\n",
      "고추씨기름, 대두유, 마늘, 밀가루, 백설탕, 양조간장, 정제소금, 정제수, 참기름, 찹쌀가루, 찹쌀전분, 파프리카추출색소, 효소처리스테비아<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음은 떡류에 사용될 일부 재료야. 이 떡류에 들어갈 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료들을 추천해줄래?', '제공된 재료': '설타나', '카테고리': None}\n",
      "\n",
      "### Response:\n",
      "과일농축액, 백설탕, 대두단백, 대두유, 정제소금, 정제수, 정제수, 정제수, 정\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음에 나열된 소스류 재료들 외에, 추가로 어떤 재료를 넣으면 좋을지 추천해줄래? 이 때, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 추천해주길 부탁해.', '제공된 재료': \"숙성비빔베이스, 양조식초, 막사버 와이비 페이스트, 5'리보뉴클레오티드이나트륨, 하이물엿82\", '카테고리': '소스류'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 양조식초, 양파, 정제수, 정제염, 정제수, 정제소금, 정\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음에 나열된 농산물 재료들 외에, 추가로 어떤 재료를 넣으면 좋을지 추천해줄래? 이 때, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 추천해주길 부탁해.', '제공된 재료': '탄산수소나트륨', '카테고리': '농산물'}\n",
      "\n",
      "### Response:\n",
      "아베베, 아미노베이스-P, 아미노베이스-S, 아미노베이스-SP, 아미노베이스-SS, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '아래에 수산물에 들어갈 몇 가지 재료가 나열되어 있어. 이 수산물에 추가로 사용될 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료가 뭐가 있을까?', '제공된 재료': '냉동연육(이또요리ka), 우엉', '카테고리': '수산물'}\n",
      "\n",
      "### Response:\n",
      "고추씨기름, 대두유, 돼지고기, 마늘, 밀가루, 백설탕, 양배추, 양조간장, 정제소금, 정제수, 참기름, 참깨, 참치액, 참치액분말, 참\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '아래에 농산물에 들어갈 몇 가지 재료가 나열되어 있어. 이 농산물에 추가로 사용될 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료가 뭐가 있을까?', '제공된 재료': '비타민C', '카테고리': '농산물'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 5'-리보뉴클레오티드칼륨, 5'-리보뉴클레오티드칼슘, 5'-리보뉴클레오�\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음에 나열된 떡류 재료들 외에, 추가로 어떤 재료를 넣으면 좋을지 추천해줄래? 이 때, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 추천해주길 부탁해.', '제공된 재료': '찰옥수수전분', '카테고리': '떡류'}\n",
      "\n",
      "### Response:\n",
      "고구마, 대두단백, 대두유, 마늘, 밀가루, 백설탕, 정제소금, 정제수, 정제수, 정제염, 정\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음은 소스류에 사용될 일부 재료야. 이 소스류에 들어갈 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료들을 추천해줄래?', '제공된 재료': '화이트트러플올리브오일, 정제소금, 정백당', '카테고리': None}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스-P, 아미노베이스-S, 아미노베이스-T, 아미노베이스-XP, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음에 나열된 두부 재료들 외에, 추가로 어떤 재료를 넣으면 좋을지 추천해줄래? 이 때, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 추천해주길 부탁해.', '제공된 재료': '순두부, 달걀', '카테고리': '두부'}\n",
      "\n",
      "### Response:\n",
      "고추씨기름, 대두유, 마늘, 밀가루, 백설탕, 양조간장, 정제소금, 정제수, 참기름, 후춧가루<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음은 수산물에 사용될 일부 재료야. 이 수산물에 들어갈 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료들을 추천해줄래?', '제공된 재료': '갈치연육, 명태 RA', '카테고리': None}\n",
      "\n",
      "### Response:\n",
      "고추씨기름, 대두유, 마늘, 밀가루, 백설탕, 양조간장, 양파, 정제소금, 정제수, 참기름, 참깨유, 후춧가루<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '아래에 수산물에 들어갈 몇 가지 재료가 나열되어 있어. 이 수산물에 추가로 사용될 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료가 뭐가 있을까?', '제공된 재료': '체다스트링치즈, 대두유', '카테고리': '수산물'}\n",
      "\n",
      "### Response:\n",
      "고추씨기름, 대두단백, 돼지고기, 마늘, 밀가루, 백설탕, 양배추, 양조간장, 정제소금, 정제수, 참기름, 참깨, 참치액, 참치조미액, 후추가루, 흑후추분말<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '이 소스류를 만들 때 사용할 몇 가지 재료가 이미 정해졌어. 여기에 어울릴 만한, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 제안해줄 수 있니?', '제공된 재료': '토마토분말-p, 토마토페이스트, 양파', '카테고리': '소스류'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스-P, 아미노베이스-S, 아미노베이스-T, 아미노베이스-XP, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '이 떡류를 만들 때 사용할 몇 가지 재료가 이미 정해졌어. 여기에 어울릴 만한, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 제안해줄 수 있니?', '제공된 재료': '진편가루', '카테고리': '떡류'}\n",
      "\n",
      "### Response:\n",
      "고구마, 대두단백, 대두유, 마요네즈, 밀가루, 백설탕, 정제소금, 정제수, 흑설탕<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '이 소스류를 만들 때 사용할 몇 가지 재료가 이미 정해졌어. 여기에 어울릴 만한, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 제안해줄 수 있니?', '제공된 재료': '핫소스베이스, 닭육수베이스', '카테고리': '소스류'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스-P, 아미노베이스-S, 아미노베이스-T, 아미노베이스-XP, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '이 냉동밥를 만들 때 사용할 몇 가지 재료가 이미 정해졌어. 여기에 어울릴 만한, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 제안해줄 수 있니?', '제공된 재료': '쌀, 정제소금, 로스티드치킨엑기스', '카테고리': '냉동밥'}\n",
      "\n",
      "### Response:\n",
      "고추씨기름, 대두유, 마늘, 맛내기양념, 백설탕, 양조간장, 양파, 정제수, 정제소금, 참기름, 후추가루<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '아래에 면, 만두에 들어갈 몇 가지 재료가 나열되어 있어. 이 면, 만두에 추가로 사용될 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료가 뭐가 있을까?', '제공된 재료': '맛내기양념, 고추씨맛기름, 백설탕, 두부, 콩발효맛내기진', '카테고리': '면, 만두'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스-P, 아미노베이스-S, 아미노베이스-T, 아미노베이스-W, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음은 냉동밥에 사용될 일부 재료야. 이 냉동밥에 들어갈 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료들을 추천해줄래?', '제공된 재료': '볶음김치향미유, 양파, 옥수수유', '카테고리': None}\n",
      "\n",
      "### Response:\n",
      "고추씨기름, 대두유, 마늘, 밀가루, 백설탕, 양배추, 양조간장, 정제소금, 정제수, 참기름, 찹쌀, 찹쌀가루, 찹쌀전분, 찹쌀엿, �\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '이 소스류를 만들 때 사용할 몇 가지 재료가 이미 정해졌어. 여기에 어울릴 만한, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 제안해줄 수 있니?', '제공된 재료': '한식간장원액, 양조간장, 맛있는 요리애', '카테고리': '소스류'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스-P, 아미노베이스-S, 아미노베이스-T, 아미노베이스-XP, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '이 수산물를 만들 때 사용할 몇 가지 재료가 이미 정해졌어. 여기에 어울릴 만한, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 제안해줄 수 있니?', '제공된 재료': '돌김', '카테고리': '수산물'}\n",
      "\n",
      "### Response:\n",
      "고추씨기름, 대두유, 마늘, 밀가루, 백설탕, 양조간장, 정제소금, 정제수, 참기름, 참기름-1, 참기름-2, 참기름-3, 참\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '아래에 소스류에 들어갈 몇 가지 재료가 나열되어 있어. 이 소스류에 추가로 사용될 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료가 뭐가 있을까?', '제공된 재료': '팔마산슈레드, 알라버터, 노베이션루미나600', '카테고리': '소스류'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스-P, 아미노베이스-S, 아미노베이스-T, 아미노베이스-XP, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '아래에 소스류에 들어갈 몇 가지 재료가 나열되어 있어. 이 소스류에 추가로 사용될 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료가 뭐가 있을까?', '제공된 재료': '고추기름-1, 양파, 홍고추, 감자전분, 돼지고기', '카테고리': '소스류'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스-P, 아미노베이스-S, 아미노베이스-T, 아미노베이스-XP, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '아래에 소스류에 들어갈 몇 가지 재료가 나열되어 있어. 이 소스류에 추가로 사용될 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료가 뭐가 있을까?', '제공된 재료': '재래된장, 더 고소하고 단단한두부, 쇠고기추출분말P, 감자전분', '카테고리': '소스류'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스P, 아미노베이스S, 아미노베이스T, 아미노베이스X, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음에 나열된 두부 재료들 외에, 추가로 어떤 재료를 넣으면 좋을지 추천해줄래? 이 때, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 추천해주길 부탁해.', '제공된 재료': '전분두부', '카테고리': '두부'}\n",
      "\n",
      "### Response:\n",
      "고추씨기름, 대두유, 마늘, 맛내기양념, 밀분해추출물, 백설탕, 양조간장, 정제소금, 정제수, 정제수, 참기름, 참기름, 후추가루, 흑후추분말<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '아래에 수산물에 들어갈 몇 가지 재료가 나열되어 있어. 이 수산물에 추가로 사용될 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료가 뭐가 있을까?', '제공된 재료': '당근, 양파', '카테고리': '수산물'}\n",
      "\n",
      "### Response:\n",
      "고추, 대두유, 마늘, 밀가루, 백설탕, 양배추, 양조간장, 정제소금, 정제수, 참기름, 참깨, 참치액, 참치엑기스, 후추가루<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '아래에 수산물에 들어갈 몇 가지 재료가 나열되어 있어. 이 수산물에 추가로 사용될 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료가 뭐가 있을까?', '제공된 재료': '모짜렐라슬라이스치즈', '카테고리': '수산물'}\n",
      "\n",
      "### Response:\n",
      "고추씨기름, 대두유, 돼지고기, 마늘, 밀가루, 백설탕, 양배추, 양조간장, 정제소금, 정제수, 참기름, 참깨, 참치액, 참치조미액, 후추가루<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '아래에 소스류에 들어갈 몇 가지 재료가 나열되어 있어. 이 소스류에 추가로 사용될 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료가 뭐가 있을까?', '제공된 재료': '감자전분, 포크엑기스P, 참맛고추장골드, 재래된장', '카테고리': '소스류'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스P, 아미노베이스S, 아미노베이스T, 아미노베이스X, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음은 소스류에 사용될 일부 재료야. 이 소스류에 들어갈 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료들을 추천해줄래?', '제공된 재료': '사골엑기스, 다시마엑기스1호', '카테고리': None}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스-P, 아미노베이스-S, 아미노베이스-T, 아미노베이스-XP, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음에 나열된 소스류 재료들 외에, 추가로 어떤 재료를 넣으면 좋을지 추천해줄래? 이 때, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 추천해주길 부탁해.', '제공된 재료': '라볶이지미베이스, 떡볶이지미베이스, 우동지미인헨서', '카테고리': '소스류'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스-P, 아미노베이스-S, 아미노베이스-T, 아미노베이스-XP, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음에 나열된 떡류 재료들 외에, 추가로 어떤 재료를 넣으면 좋을지 추천해줄래? 이 때, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 추천해주길 부탁해.', '제공된 재료': '쌀미강추출물', '카테고리': '떡류'}\n",
      "\n",
      "### Response:\n",
      "고구마, 대두단백, 당면, 당근, 대두유, 마늘, 밀가루, 백설탕, 정제소금, 정제수, 정제수, 정제염, 정\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음은 수산물에 사용될 일부 재료야. 이 수산물에 들어갈 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료들을 추천해줄래?', '제공된 재료': '연육 명태 A, 연육/명태 AA', '카테고리': None}\n",
      "\n",
      "### Response:\n",
      "고추씨기름, 대두유, 돼지고기, 마늘, 밀가루, 백설탕, 양배추, 양조간장, 정제소금, 정제수, 참기름, 참깨, 참치액, 참치엑기스, 후추가루<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음은 두부에 사용될 일부 재료야. 이 두부에 들어갈 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료들을 추천해줄래?', '제공된 재료': '두유액', '카테고리': None}\n",
      "\n",
      "### Response:\n",
      "고소한마늘, 고추씨기름, 대두단백, 대두유, 마늘, 밀분해추출물, 밀분해추출물혼합분말, 백설탕, 정제소금, 정제수, 정제수혼합액, 정제수혼합분말, 정\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음에 나열된 농산물 재료들 외에, 추가로 어떤 재료를 넣으면 좋을지 추천해줄래? 이 때, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 추천해주길 부탁해.', '제공된 재료': '양파, 건조링홍고추', '카테고리': '농산물'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스-P, 아미노베이스-S, 아미노베이스-T, 아미노베이스-XP, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음에 나열된 두부 재료들 외에, 추가로 어떤 재료를 넣으면 좋을지 추천해줄래? 이 때, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 추천해주길 부탁해.', '제공된 재료': '대두유', '카테고리': '두부'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스-P, 아미노베이스-S, 아미노베이스-T, 아미노베이스-XP, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '이 면, 만두를 만들 때 사용할 몇 가지 재료가 이미 정해졌어. 여기에 어울릴 만한, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 제안해줄 수 있니?', '제공된 재료': '부추, 양송이슬라이스, 굴소스-P, 고추맛기름', '카테고리': '면, 만두'}\n",
      "\n",
      "### Response:\n",
      "고추씨기름, 대두단백, 돼지고기, 마늘, 밀가루, 백설탕, 양배추, 양조간장, 정제소금, 정제수, 참기름, 참깨, 찹쌀가루, 흑후추분말<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음은 소스류에 사용될 일부 재료야. 이 소스류에 들어갈 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료들을 추천해줄래?', '제공된 재료': '청양고추엑기스, 홍청양고추청페이스트60', '카테고리': None}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스-P, 아미노베이스-S, 아미노베이스-T, 아미노베이스-XP, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음에 나열된 수산물 재료들 외에, 추가로 어떤 재료를 넣으면 좋을지 추천해줄래? 이 때, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 추천해주길 부탁해.', '제공된 재료': '어묵용조미액, 밀떡볶이떡, 연육, 유부주머니', '카테고리': '수산물'}\n",
      "\n",
      "### Response:\n",
      "고추씨기름, 대두유, 돼지고기, 마늘, 밀가루, 백설탕, 양조간장, 양파, 정제소금, 참기름, 참깨, 참치액, 후추가루<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '이 소스류를 만들 때 사용할 몇 가지 재료가 이미 정해졌어. 여기에 어울릴 만한, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 제안해줄 수 있니?', '제공된 재료': '참맛고추장골드, 한식메주된장, 베트남고추가루', '카테고리': '소스류'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스-P, 아미노베이스-S, 아미노베이스-T, 아미노베이스-XP, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '이 대체육를 만들 때 사용할 몇 가지 재료가 이미 정해졌어. 여기에 어울릴 만한, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 제안해줄 수 있니?', '제공된 재료': '대두단백, 해피부스터, 백설탕', '카테고리': '대체육'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스-P, 아미노베이스-S, 아미노베이스-T, 아미노베이스-XP, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음은 농산물에 사용될 일부 재료야. 이 농산물에 들어갈 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료들을 추천해줄래?', '제공된 재료': '숙주나물', '카테고리': None}\n",
      "\n",
      "### Response:\n",
      "고추씨기름, 대두유, 마늘, 밀가루, 백설탕, 양배추, 양조간장, 정제소금, 정제수, 정제수, 참기름, 참기름, 참기름, 참기름, 참\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '아래에 소스류에 들어갈 몇 가지 재료가 나열되어 있어. 이 소스류에 추가로 사용될 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료가 뭐가 있을까?', '제공된 재료': '양조간장, 정백당', '카테고리': '소스류'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스-P, 아미노베이스-S, 아미노베이스-T, 아미노베이스-XP, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '이 수산물를 만들 때 사용할 몇 가지 재료가 이미 정해졌어. 여기에 어울릴 만한, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 제안해줄 수 있니?', '제공된 재료': '대두유, 양파', '카테고리': '수산물'}\n",
      "\n",
      "### Response:\n",
      "고추씨기름, 냉동연육, 냉동연육-1, 냉동연육-2, 냉동연육-3, �\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '아래에 소스류에 들어갈 몇 가지 재료가 나열되어 있어. 이 소스류에 추가로 사용될 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료가 뭐가 있을까?', '제공된 재료': 'YT25카라멜색소, 사과농축액(크리어), 하얀설탕, 볶음참깨', '카테고리': '소스류'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스-P, 아미노베이스-S, 아미노베이스-T, 아미노베이스-XP, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '아래에 소스류에 들어갈 몇 가지 재료가 나열되어 있어. 이 소스류에 추가로 사용될 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료가 뭐가 있을까?', '제공된 재료': '구연산, 사과산, DL-사과산, 향긋한 사과식초, 옥수수유', '카테고리': '소스류'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스-P, 아미노베이스-S, 아미노베이스-T, 아미노베이스-XP, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '아래에 수산물에 들어갈 몇 가지 재료가 나열되어 있어. 이 수산물에 추가로 사용될 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료가 뭐가 있을까?', '제공된 재료': '고추, 연육/명태 AA, 연육 명태 A', '카테고리': '수산물'}\n",
      "\n",
      "### Response:\n",
      "고추씨기름, 대두유, 마늘, 맛내기양념, 맛내기양념(2), 맛내기양념(3), 맛내기양념(4), 맛\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음은 농산물에 사용될 일부 재료야. 이 농산물에 들어갈 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료들을 추천해줄래?', '제공된 재료': '양파, 숙주', '카테고리': None}\n",
      "\n",
      "### Response:\n",
      "고추, 마늘, 밀가루, 백설탕, 비프엑기스, 양배추, 양조간장, 정제소금, 정제수, 참기름, 파프리카, 파프리카추출색소, 효모추출물<|end_of_text|>\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '아래에 소스류에 들어갈 몇 가지 재료가 나열되어 있어. 이 소스류에 추가로 사용될 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료가 뭐가 있을까?', '제공된 재료': '가쓰오부시엑기스 1호, 진한가쓰오조미액, 우동지미인헨서', '카테고리': '소스류'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스-P, 아미노베이스-S, 아미노베이스-T, 아미노베이스-XP, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '이 소스류를 만들 때 사용할 몇 가지 재료가 이미 정해졌어. 여기에 어울릴 만한, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료를 제안해줄 수 있니?', '제공된 재료': '참맛고추장골드, 고추가루, 백설탕', '카테고리': '소스류'}\n",
      "\n",
      "### Response:\n",
      "5'-리보뉴클레오티드이나트륨, 아미노베이스-P, 아미노베이스-S, 아미노베이스-T, 아미노베이스-XP, 아\n",
      "<|begin_of_text|>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "{'instruction': '다음은 떡류에 사용될 일부 재료야. 이 떡류에 들어갈 수 있는, 많은 식품에서 공통적으로 등장하는 공통 재료 외에도 독특하고 특화된 다른 식재료들을 추천해줄래?', '제공된 재료': '정제수', '카테고리': None}\n",
      "\n",
      "### Response:\n",
      "과당, 백설탕, 대두유, 대두단백, 마요네즈, 밀가루, 밀분해추출물, 밀전분, 밀전분-1, 밀\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from transformers import TextStreamer\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "length = 50 # length of random list\n",
    "random_list = [random.randint(0, len(dataset_dict['test'])) for _ in range(length)]\n",
    "\n",
    "q_list = []; a_list = []; output_list = []\n",
    "for n in random_list:\n",
    "    q = dataset_dict['test'][n]['QUESTION']\n",
    "    a = dataset_dict['test'][n]['ANSWER']\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        [\n",
    "            alpaca_prompt.format(\n",
    "                q,  # 지시사항\n",
    "                \"\",  # 출력 - 생성을 위해 이 부분을 비워둡니다!\n",
    "            )\n",
    "        ],\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    text_streamer = TextStreamer(tokenizer)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        streamer=text_streamer,\n",
    "        max_new_tokens=4096,  # 최대 생성 토큰 수를 설정합니다.\n",
    "        stopping_criteria=stopping_criteria  # 생성을 멈출 기준을 설정합니다.\n",
    "    )\n",
    "\n",
    "    q_list.append(q)\n",
    "    a_list.append(a)\n",
    "    output_tmp = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    output_list.append(output_tmp[0].split('\\n')[-1].split(', '))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12352446260384746\n"
     ]
    }
   ],
   "source": [
    "# [answer (a_list) 와 pred (output_list) 의 교집합 / answer (a_list) 의 길이]\n",
    "score_list = []\n",
    "for a, p in zip(a_list, output_list):\n",
    "    a = a.split(', ')\n",
    "    cnt = 0\n",
    "    for pp in p:\n",
    "        if pp in a:\n",
    "            cnt += 1\n",
    "    score_list.append(cnt/len(a))\n",
    "\n",
    "print(sum(score_list)/len(score_list)) # mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantization 방식 설정\n",
    "quantization_method = \"q8_0\"  # \"f16\" \"q8_0\" \"q4_k_m\" \"q5_k_m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Entering directory '/home/jaesung/pulmuone/alpaca_rec_turning/completion/modeling/llama.cpp'\n",
      "I ccache not found. Consider installing it for faster compilation.\n",
      "I llama.cpp build info: \n",
      "I UNAME_S:   Linux\n",
      "I UNAME_P:   x86_64\n",
      "I UNAME_M:   x86_64\n",
      "I CFLAGS:    -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion \n",
      "I CXXFLAGS:  -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE \n",
      "I NVCCFLAGS: -std=c++11 -O3 -g \n",
      "I LDFLAGS:    \n",
      "I CC:        cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "I CXX:       c++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "\n",
      "rm -vrf *.dot libllava.a llama-baby-llama llama-batched llama-batched-bench llama-bench llama-benchmark-matmult llama-cli llama-convert-llama2c-to-ggml llama-embedding llama-eval-callback llama-export-lora llama-gbnf-validator llama-gguf llama-gguf-hash llama-gguf-split llama-gritlm llama-imatrix llama-infill llama-llava-cli llama-minicpmv-cli llama-lookahead llama-lookup llama-lookup-create llama-lookup-merge llama-lookup-stats llama-parallel llama-passkey llama-perplexity llama-q8dot llama-quantize llama-quantize-stats llama-retrieval llama-save-load-state llama-server llama-simple llama-speculative llama-tokenize llama-vdot llama-cvector-generator tests/test-c.o tests/test-autorelease tests/test-backend-ops tests/test-chat-template tests/test-double-float tests/test-grad0 tests/test-grammar-integration tests/test-grammar-parser tests/test-json-schema-to-grammar tests/test-llama-grammar tests/test-model-load-cancel tests/test-opt tests/test-quantize-fns tests/test-quantize-perf tests/test-rope tests/test-sampling tests/test-tokenizer-0 tests/test-tokenizer-1-bpe tests/test-tokenizer-1-spm\n",
      "rm -rvf src/*.o\n",
      "rm -rvf tests/*.o\n",
      "rm -rvf examples/*.o\n",
      "rm -rvf common/*.o\n",
      "rm -rvf *.a\n",
      "rm -rvf *.dll\n",
      "rm -rvf *.so\n",
      "rm -rvf *.dot\n",
      "rm -rvf ggml/*.a\n",
      "rm -rvf ggml/*.dll\n",
      "rm -rvf ggml/*.so\n",
      "rm -vrf ggml/src/*.o\n",
      "rm -rvf ggml/src/llamafile/*.o\n",
      "rm -rvf common/build-info.cpp\n",
      "rm -vrf ggml/src/ggml-metal-embed.metal\n",
      "rm -vrf ggml/src/ggml-cuda/*.o\n",
      "rm -vrf ggml/src/ggml-cuda/template-instances/*.o\n",
      "rm -rvf libllava.a llama-baby-llama llama-batched llama-batched-bench llama-bench llama-benchmark-matmult llama-cli llama-convert-llama2c-to-ggml llama-embedding llama-eval-callback llama-export-lora llama-gbnf-validator llama-gguf llama-gguf-hash llama-gguf-split llama-gritlm llama-imatrix llama-infill llama-llava-cli llama-minicpmv-cli llama-lookahead llama-lookup llama-lookup-create llama-lookup-merge llama-lookup-stats llama-parallel llama-passkey llama-perplexity llama-q8dot llama-quantize llama-quantize-stats llama-retrieval llama-save-load-state llama-server llama-simple llama-speculative llama-tokenize llama-vdot llama-cvector-generator tests/test-c.o\n",
      "rm -rvf tests/test-autorelease tests/test-backend-ops tests/test-chat-template tests/test-double-float tests/test-grad0 tests/test-grammar-integration tests/test-grammar-parser tests/test-json-schema-to-grammar tests/test-llama-grammar tests/test-model-load-cancel tests/test-opt tests/test-quantize-fns tests/test-quantize-perf tests/test-rope tests/test-sampling tests/test-tokenizer-0 tests/test-tokenizer-1-bpe tests/test-tokenizer-1-spm\n",
      "rm -f vulkan-shaders-gen ggml/src/ggml-vulkan-shaders.hpp ggml/src/ggml-vulkan-shaders.cpp\n",
      "rm -rvf main quantize quantize-stats perplexity imatrix embedding vdot q8dot convert-llama2c-to-ggml simple batched batched-bench save-load-state server gguf gguf-split eval-callback llama-bench libllava.a llava-cli baby-llama retrieval speculative infill tokenize benchmark-matmult parallel export-lora lookahead lookup passkey gritlm\n",
      "find examples pocs -type f -name \"*.o\" -delete\n",
      "make: Leaving directory '/home/jaesung/pulmuone/alpaca_rec_turning/completion/modeling/llama.cpp'\n",
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 413.31 out of 503.13 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:02<00:00, 14.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Converting llama model. Can use fast conversion = False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
      "   \\\\   /|    [0] Installing llama.cpp will take 3 minutes.\n",
      "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits will take 3 minutes.\n",
      "\\        /    [2] Converting GGUF 16bits to ['q8_0'] will take 10 minutes each.\n",
      " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
      "\n",
      "Unsloth: [0] Installing llama.cpp. This will take 3 minutes...\n",
      "Unsloth: [1] Converting model at Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v4-30-gguf into q8_0 GGUF format.\n",
      "The output location will be ./Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v4-30-gguf/unsloth.Q8_0.gguf\n",
      "This will take 3 minutes...\n",
      "INFO:hf-to-gguf:Loading model: Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v4-30-gguf\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:token_embd.weight,           torch.bfloat16 --> Q8_0, shape = {4096, 128256}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00004-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:output.weight,               torch.bfloat16 --> Q8_0, shape = {4096, 128256}\n",
      "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:output_norm.weight,          torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:gguf: context length = 8192\n",
      "INFO:hf-to-gguf:gguf: embedding length = 4096\n",
      "INFO:hf-to-gguf:gguf: feed forward length = 14336\n",
      "INFO:hf-to-gguf:gguf: head count = 32\n",
      "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
      "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
      "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
      "INFO:hf-to-gguf:gguf: file type = 7\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "INFO:gguf.vocab:Adding 280147 merge(s).\n",
      "INFO:gguf.vocab:Setting special token type bos to 128000\n",
      "INFO:gguf.vocab:Setting special token type eos to 128001\n",
      "INFO:gguf.vocab:Setting special token type pad to 128255\n",
      "INFO:gguf.vocab:Setting chat_template to {% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
      "\n",
      "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "' }}{% endif %}\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v4-30-gguf/unsloth.Q8_0.gguf: n_tensors = 291, total_size = 8.5G\n",
      "Writing: 100%|██████████| 8.53G/8.53G [01:27<00:00, 97.8Mbyte/s]\n",
      "INFO:hf-to-gguf:Model successfully exported to Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v4-30-gguf/unsloth.Q8_0.gguf\n",
      "Unsloth: Conversion completed! Output location: ./Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v4-30-gguf/unsloth.Q8_0.gguf\n",
      "Unsloth: Uploading GGUF to Huggingface Hub...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unsloth.Q8_0.gguf: 100%|██████████| 8.54G/8.54G [04:51<00:00, 29.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GGUF to https://huggingface.co/passionMan/Llama-3-Open-Ko-8B-Instruct-previe-PM1-completion-v4-30-gguf\n"
     ]
    }
   ],
   "source": [
    "# Hub 에 GGUF 업로드\n",
    "model.push_to_hub_gguf(\n",
    "    huggingface_repo + \"-gguf\",\n",
    "    tokenizer,\n",
    "    quantization_method=quantization_method,\n",
    "    token=huggingface_token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpaca_kernel",
   "language": "python",
   "name": "alpaca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
